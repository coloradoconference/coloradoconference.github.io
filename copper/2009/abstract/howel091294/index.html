<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 3.2 Final//EN">

<!--Converted with LaTeX2HTML 2002-2-1 (1.70)
original version by:  Nikos Drakos, CBLU, University of Leeds
* revised and updated by:  Marcus Hennecke, Ross Moore, Herb Swan
* with significant contributions from:
  Jens Lippmann, Marek Rouchal, Martin Wilck and others -->
<HTML>
<HEAD>
<TITLE>howel091294</TITLE>
<META NAME="description" CONTENT="howel091294">
<META NAME="keywords" CONTENT="howel091294">
<META NAME="resource-type" CONTENT="document">
<META NAME="distribution" CONTENT="global">

<META NAME="Generator" CONTENT="LaTeX2HTML v2002-2-1">
<META HTTP-EQUIV="Content-Style-Type" CONTENT="text/css">

<LINK REL="STYLESHEET" HREF="howel091294.css">

<LINK REL="next" HREF="node1.html">
</HEAD>

<BODY >
<!--Navigation Panel-->
<A NAME="tex2html2"
  HREF="node1.html">
<IMG WIDTH="37" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="next"
 SRC="file:/usr/share/latex2html/icons/next.png"></A> 
<IMG WIDTH="26" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="up"
 SRC="file:/usr/share/latex2html/icons/up_g.png"> 
<IMG WIDTH="63" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="previous"
 SRC="file:/usr/share/latex2html/icons/prev_g.png">   
<BR>
<B> Next:</B> <A NAME="tex2html3"
  HREF="node1.html">About this document ...</A>
<BR>
<BR>
<!--End of Navigation Panel-->
<DIV ALIGN="CENTER">
  <FONT SIZE="+1">Gary W. Howell 
<BR><B>BLAS-3 Sparse <!-- MATH
 $U B_{K+1} V$
 -->
<IMG
 WIDTH="70" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="img1.png"
 ALT="$ U B_{K+1} V$"> Decomposition </B></FONT>
</DIV>
<P>
<DIV ALIGN="CENTER">512 Farmington Woods Dr 
<BR>
Cary 
<BR>
NC 27511

<BR><TT>gary_howell@ncsu.edu</TT>
</DIV>

<P>
<BR>
A matrix <IMG
 WIDTH="16" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img2.png"
 ALT="$ A$"> can be reduced to upper triangular banded form
by BLAS-3 block Housholder transformations. Deferring matrix updates, the
algorithm accesses <IMG
 WIDTH="16" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img2.png"
 ALT="$ A$"> only to extract blocks and to perform
multiplications <IMG
 WIDTH="31" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img3.png"
 ALT="$ AX$">, <IMG
 WIDTH="39" HEIGHT="16" ALIGN="BOTTOM" BORDER="0"
 SRC="img4.png"
 ALT="$ AY^T$">, where if <IMG
 WIDTH="19" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img5.png"
 ALT="$ X$"> and <IMG
 WIDTH="17" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img6.png"
 ALT="$ Y$"> have <IMG
 WIDTH="19" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img7.png"
 ALT="$ K$"> columns than
the bandwidth of upper triangular <IMG
 WIDTH="45" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="img8.png"
 ALT="$ B_{K+1}$"> is <IMG
 WIDTH="47" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="img9.png"
 ALT="$ K+1$">. When <IMG
 WIDTH="16" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img2.png"
 ALT="$ A$"> is sparse,
block Householder eliminations provide a BLAS-3 method to contruct a <!-- MATH
 $U
B_{K+1}V$
 -->
<IMG
 WIDTH="70" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="img1.png"
 ALT="$ U B_{K+1} V$"> approximation, with <IMG
 WIDTH="17" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img10.png"
 ALT="$ U$"> and <IMG
 WIDTH="17" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img11.png"
 ALT="$ V$"> orthogonal, <IMG
 WIDTH="17" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img10.png"
 ALT="$ U$"> (<!-- MATH
 $m \times l$
 -->
<IMG
 WIDTH="43" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="img12.png"
 ALT="$ m \times l$">),
<IMG
 WIDTH="17" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img11.png"
 ALT="$ V$"> (<!-- MATH
 $n \times l$
 -->
<IMG
 WIDTH="39" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="img13.png"
 ALT="$ n \times l$">), <IMG
 WIDTH="42" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="img14.png"
 ALT="$ B_{K+!}$"> <!-- MATH
 $l \times l$
 -->
<IMG
 WIDTH="34" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="img15.png"
 ALT="$ l \times l$">, with the size of <IMG
 WIDTH="10" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img16.png"
 ALT="$ l$">
constrained by available RAM.

<P>
The decomposition is stable, is efficient in terms
of cache utilization, and should scale well in distributed parallel computation.

<P>
The <!-- MATH
 $U B_{K+1} V$
 -->
<IMG
 WIDTH="70" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="img1.png"
 ALT="$ U B_{K+1} V$"> approximate (truncated) decomposition can be used to
provide some matrix singular values, to solve linear systems and least
squares problems, and to provide an approximate inverse preconditioner.
Multi-grid applications may be parallel iterations with the full matrix,
as a preconditioner, or in solution of a coarsened problem. Each of these
applications is discussed.

<P>
A primary advantage of the block reduction to a banded upper triangular
form is that the underlying sparse matrix is accessed only for
multiplications by blocks of matrices (sparse matrix dense matrix
multiplications). Serial SPMD multiplications run at a significant
fraction of peak speed on cache based processors, and should also run
well in parallel. Stability of block Householder transformations aids in
scalability.

<P>
Numerically, the truncated <!-- MATH
 $U B_{K+1} V$
 -->
<IMG
 WIDTH="70" HEIGHT="30" ALIGN="MIDDLE" BORDER="0"
 SRC="img1.png"
 ALT="$ U B_{K+1} V$"> decomposition is seen to be
particularly efficient in approximating low rank matrices or low rank
matrices added to a matrix with a known factorization.

<P>
Some unresolved questions are how to best prepermute <IMG
 WIDTH="16" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img2.png"
 ALT="$ A$">, how to best pad
<IMG
 WIDTH="16" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img2.png"
 ALT="$ A$"> (thick start), and considered as a Krylov method the best restart
strategies (thick restart?, repermutation of <IMG
 WIDTH="16" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img2.png"
 ALT="$ A$">?).

<P>
The remainder of the abstract discusses why multiplication of <IMG
 WIDTH="31" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img3.png"
 ALT="$ AX$"> is
likely to be faster than computing <IMG
 WIDTH="26" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img17.png"
 ALT="$ Ax$">, assuming <IMG
 WIDTH="16" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img2.png"
 ALT="$ A$"> sparse, <IMG
 WIDTH="14" HEIGHT="13" ALIGN="BOTTOM" BORDER="0"
 SRC="img18.png"
 ALT="$ x$"> a dense
vector <IMG
 WIDTH="19" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img5.png"
 ALT="$ X$"> a dense matrix with relatively few columns. Assume <IMG
 WIDTH="16" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img2.png"
 ALT="$ A$"> is too
large to fit in cache memory. <IMG
 WIDTH="16" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img2.png"
 ALT="$ A$"> is typically stored so that it can be
pulled in a stream from RAM.
If <IMG
 WIDTH="14" HEIGHT="13" ALIGN="BOTTOM" BORDER="0"
 SRC="img18.png"
 ALT="$ x$"> fits in cache, then as each element of <IMG
 WIDTH="16" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img2.png"
 ALT="$ A$"> appears in the CPU it
can be matched by the appropriate element of <IMG
 WIDTH="14" HEIGHT="13" ALIGN="BOTTOM" BORDER="0"
 SRC="img18.png"
 ALT="$ x$">. If indexing operations
do not take too long the main cost is then the fetch of <IMG
 WIDTH="16" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img2.png"
 ALT="$ A$"> from RAM.
Since the fetch of <IMG
 WIDTH="16" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img2.png"
 ALT="$ A$"> is streamed, elements of <IMG
 WIDTH="16" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img2.png"
 ALT="$ A$"> arrive more or less
at the peak speed of the data bus.

<P>
On Intel Xeons, sparse <IMG
 WIDTH="26" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img17.png"
 ALT="$ Ax$"> can attain up to about ten per cent of the
advertised peak flop rate. When <IMG
 WIDTH="14" HEIGHT="13" ALIGN="BOTTOM" BORDER="0"
 SRC="img18.png"
 ALT="$ x$"> becomes too large to fit in cache,
and if <IMG
 WIDTH="14" HEIGHT="13" ALIGN="BOTTOM" BORDER="0"
 SRC="img18.png"
 ALT="$ x$"> is accessed randomly, then the
computation is dominated by cache misses and slows dramatically. In some
experiments with Intel Xeons, <IMG
 WIDTH="26" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img17.png"
 ALT="$ Ax$"> compted at less than one per cent of
peak processor speed. When multiplying by <IMG
 WIDTH="19" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img5.png"
 ALT="$ X$"> with <IMG
 WIDTH="19" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img7.png"
 ALT="$ K$"> columns as opposed
to <IMG
 WIDTH="14" HEIGHT="13" ALIGN="BOTTOM" BORDER="0"
 SRC="img18.png"
 ALT="$ x$">, each access of an element of <IMG
 WIDTH="16" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img2.png"
 ALT="$ A$"> allows <IMG
 WIDTH="19" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img7.png"
 ALT="$ K$"> multiplications.
Storage of <IMG
 WIDTH="19" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img5.png"
 ALT="$ X$"> should be arranged so that when a given element of <IMG
 WIDTH="16" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img2.png"
 ALT="$ A$"> is
accessed, the next required elements of <IMG
 WIDTH="19" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img5.png"
 ALT="$ X$"> are accessed. In Fortran, <IMG
 WIDTH="19" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img5.png"
 ALT="$ X$">
for <IMG
 WIDTH="31" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img3.png"
 ALT="$ AX$"> is stored as <IMG
 WIDTH="29" HEIGHT="16" ALIGN="BOTTOM" BORDER="0"
 SRC="img19.png"
 ALT="$ X^T$"> so that each row of <IMG
 WIDTH="19" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img5.png"
 ALT="$ X$"> is sequentially
stored as a column of <IMG
 WIDTH="29" HEIGHT="16" ALIGN="BOTTOM" BORDER="0"
 SRC="img19.png"
 ALT="$ X^T$">.

<P>
In experiments summarized here, we also blocked <IMG
 WIDTH="16" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img2.png"
 ALT="$ A$"> (column blocks) to
further minimize cache misses. The blocked SPMD <IMG
 WIDTH="31" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img3.png"
 ALT="$ AX$"> can execute at a
flop rate several orders of magnitude faster than non-blocked <IMG
 WIDTH="26" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img17.png"
 ALT="$ Ax$">. The
marked speedup of BLAS 3 over BLAS 2 motivates the algorithm development
described in the presentation.

<P>
<BR><HR>
<!--Table of Child-Links-->
<A NAME="CHILD_LINKS"></A>

<UL>
<LI><A NAME="tex2html4"
  HREF="node1.html">About this document ...</A>
</UL>
<!--End of Table of Child-Links-->
<HR>
<!--Navigation Panel-->
<A NAME="tex2html2"
  HREF="node1.html">
<IMG WIDTH="37" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="next"
 SRC="file:/usr/share/latex2html/icons/next.png"></A> 
<IMG WIDTH="26" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="up"
 SRC="file:/usr/share/latex2html/icons/up_g.png"> 
<IMG WIDTH="63" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="previous"
 SRC="file:/usr/share/latex2html/icons/prev_g.png">   
<BR>
<B> Next:</B> <A NAME="tex2html3"
  HREF="node1.html">About this document ...</A>
<!--End of Navigation Panel-->
<ADDRESS>
Marian
2009-02-04
</ADDRESS>
</BODY>
</HTML>
