\documentclass[twosided]{report}
\usepackage{amsmath,amssymb,graphicx}

% \usepackage[pdftex,%		%%% hyper-references for pdflatex
% bookmarks=true,%		%%% generate bookmarks ...
% bookmarksnumbered=true,%	%%% ... with numbers
% hypertexnames=false,%		%%% needed for correct links to figures !!!
% breaklinks=true,%		%%% break links if exceeding a single line
% linkbordercolor={1 1 1}]%	%%% blue frames around links
% {hyperref}			%%% pdfborder={0 0 1} is the default
% 
% \hypersetup{
% pdfauthor="Bruce Fast",
% pdftitle="CMCIM10abstracts",
% pdfsubject  = {Abstracts},
% pdfkeywords = {iterative methods,copper mountain}
% }


\setlength{\parindent}{0mm}
\setlength{\parskip}{1em}

\setlength{\textwidth}{175mm}
\setlength{\evensidemargin}{-7mm}
\setlength{\oddsidemargin}{-3mm}

\setlength{\textheight}{230mm}
\setlength{\topmargin}{-18mm}

% \def\mathbi#1{\textbf{\em #1}}
% \def\BA{\bf{A}}
% \def\BB{\bf{B}}
% \def\bn{\bf{n}}
% \def\CP{\mathcal{P}}
% \def\CV{\mathcal{V}}
% \def\CI{\mathcal{I}}
% \newcommand{\gradt}{\nabla\cdot}

\newcommand{\Reals}{\mathbb{R}}
\newcommand{\Cplex}{\mathbb{C}}

\newcommand{\TwoVec}[2]{ \left(
	\begin{array}{c}
	#1 \\ #2
	\end{array}
	\right) }

\newcommand{\TwoMatrx}[4]{ \left(
	\begin{array}{cc}
	#1 & #2 \\
	#3 & #4
	\end{array}
	\right) }

\newcommand{\calB}{{\mathcal B}}
\newcommand{\calBB}{{\mathcal B}^{\Box}}
\newcommand{\calK}{\mathcal{K}}
\newcommand{\bfA}{{\mathbf A}}
\newcommand{\bfb}{{\mathbf b}}
\newcommand{\bfr}{{\mathbf r}}
\newcommand{\bfx}{{\mathbf x}}
\newcommand{\bfxex}{{\mathbf x}_{\mbox{\scriptsize $\star$}}}
\newcommand{\Dim}{\mathop{\mathrm{dim\ }}}


\begin{document}

\begin{center}
	{\Large \bf
	Eleventh Copper Mountain Conference \\
	{\large on} \\
	Iterative Methods \par
	April 6 -- April 11, 2008
	}
\end{center}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	${}^{}$\par	% listing the 2 workshops first
	% \pdfbookmark[0]{Workshops}{workshops}
	\begin{center} {\LARGE {\bf 1. Workshops}} \end{center}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

	$\bullet$
	Monday 3 April,
	{\bf Simulation Based Optimization},
	George Biros and Eldad Haber

Simulation is a powerful tool in science and engineering for
predicting the behavior of physical systems, particularly
those that are governed by partial differential equations.
Moreover, progress in algorithms and computational hardware
has been responsible for improvements in simulation.

Using today's simulation tools it has now become practical
to consider complex design problems, where we wish to
determine parameters of large systems that maximizes a
certain objective, and inverse problems where we wish to
determine parameters whose behavior matches measured data.
Examples of design problems include structural optimization,
antenna design and process optimization. Geophysical
imaging, biomedical imaging, weather data assimilations are
just a few examples of inverse problems where the physics is
governed by partial differential equations.

While these types of problems are naturally posed as
optimization problems, they offer new challenges because of
their large size, inexact derivatives (when available), and
ill-posedness. Current software cannot be used because
matrices of constraint gradients cannot be factored, and
computing with null space bases can be exceedingly
expensive. The goal of this workshop is to review methods
for PDE-optimization problems and to expose researches to
some open problems in the field.

	$\bullet$
	Wednesday 5 April,
	{\bf Dynamic Data Driven Liquid Flows},
	Craig Douglas

This workshop will be strictly hands on. It will introduce
DDDAS techniques (see http://www.dddas.org) including
dynamic modeling, errors, sensor operation, and the
symbiotic relations between the sensors and the application.

We will simulate the level of a liquid in media that is
porous in one boundary edge only and design from scratch an
algorithm to maintain it at a fixed level on average even
though the liquid is disappearing through the open boundary
using a random step function.

We will develop convergence results initially using a
semi-direct method, but some of the participants may end up
with a random walk by the end of the workshop. We will
iterate on the liquid problem until we develop a fast
iterative (and convergent) algorithm that we have thoroughly
tested. We will use the data from experiments to drive the
entire methodology and the algorithms will drive how and
when data is collected.

This workshop will be held in one of the local watering
holes, not in the conference center. Sensor oversight and
correction will be provided at the tables.


\newpage
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	${}^{}$\par	% now the abstracts
	% \pdfbookmark[0]{Abstracts}{abstracts}
	\begin{center} {\LARGE
		% \hypertarget{index}
		{\bf 2. Presentations}} \\
		Abstracts are presented in alphabetical order by
		speaker's surname.
	\end{center}


% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \begin{center}
% \begin{tabular}{llll}
% \hyperlink{Adams}{Brian M. Adams}   &
% \hyperlink{Fischer}{Ranier Fischer}   &
% \hyperlink{Lashuk}{Ilya Lashuk}   &
% \hyperlink{Schenk}{Olaf Schenk}    \\
% \hyperlink{Alber}{David Alber}   &
% \hyperlink{Freund}{Roland W. Freund}   &
% \hyperlink{Lee11}{Eun-Joo Lee}   &
% \hyperlink{Schmidt}{Jens G. Schmidt}    \\
% \hyperlink{Anderson}{Matthew Anderson}   &
% \hyperlink{Fritzsche}{David Fritzsche}   &
% \hyperlink{Lee21}{Barry Lee}   &
% \hyperlink{Sheehan}{Brendan Sheehan}    \\
% \hyperlink{Argentati}{Merico E. Argentati}   &
% \hyperlink{Furnival}{Darran Furnival}   &
% \hyperlink{Leyffer}{Sven Leyffer}   &
% \hyperlink{Shen}{Jie Shen}    \\
% \hyperlink{Austin}{Travis M Austin}   &
% \hyperlink{Gallopoulos}{Efstratios Gallopoulos}   &
% \hyperlink{Liao}{Ben-Shan Liao}   &
% \hyperlink{Shi}{Peter L. Shi}    \\
% \hyperlink{Baird}{John Baird}   &
% \hyperlink{Gray}{Genetha Gray}   &
% \hyperlink{Limon}{Alfonso Limon}   &
% \hyperlink{Shuttleworth}{Robert Shuttleworth}    \\
% \hyperlink{Beardmore}{Robert E Beardmore}   &
% \hyperlink{Greif}{Chen Greif}   &
% \hyperlink{Liu}{Jia Liu}   &
% \hyperlink{Silvester}{David Silvester}    \\
% \hyperlink{Beattie}{Christopher Beattie}   &
% \hyperlink{Griffin}{Josh D Griffin}   &
% \hyperlink{Livshits}{Ira Livshits}   &
% \hyperlink{Simonis}{Joseph Simonis}    \\
% \hyperlink{Benzi}{Michele Benzi}   &
% \hyperlink{Gryazin}{Yuriy Gryazin}   &
% \hyperlink{Li}{Xiaoye S. Li}   &
% \hyperlink{Smirnova}{Alexandra Smirnova}    \\
% \hyperlink{Berlyand}{Leonid Berlyand}   &
% \hyperlink{Gugercin}{Serkan Gugercin}   &
% \hyperlink{Loisel}{S\'ebastien Loisel}   &
% \hyperlink{Sosonkina}{Masha Sosonkina}    \\
% \hyperlink{Boyle}{Jonathan W Boyle}   &
% \hyperlink{Gutknecht}{Martin H. Gutknecht}   &
% \hyperlink{MacLachlan}{Scott MacLachlan}   &
% \hyperlink{Stathopoulos}{Andreas Stathopoulos}    \\
% \hyperlink{Brannick}{James Brannick}   &
% \hyperlink{Haber}{Eldad Haber}   &
% \hyperlink{Mandel}{Jan Mandel}   &
% \hyperlink{Sturler}{Eric de Sturler}    \\
% \hyperlink{Bru}{Rafael Bru}   &
% \hyperlink{Hanson}{Lauren Hanson}   &
% \hyperlink{Marques}{Osni Marques}   &
% \hyperlink{Szyld}{Daniel B Szyld}    \\
% \hyperlink{Butler}{Jeff Butler}   &
% \hyperlink{Heldman}{Stefan Heldman}   &
% \hyperlink{Mavriplis}{Dimitri Mavriplis}   &
% \hyperlink{Tang}{Jok M. Tang}    \\
% \hyperlink{Canning}{Andrew Canning}   &
% \hyperlink{Heroux}{Michael A Heroux}   &
% \hyperlink{Mckenzie}{Ryan Mckenzie}   &
% \hyperlink{Thornquist}{Heidi K. Thornquist}    \\
% \hyperlink{Chacon}{Luis Chacon}   &
% \hyperlink{Heys}{Jeff Heys}   &
% \hyperlink{Morgan}{Ron Morgan}   &
% \hyperlink{Toivanen}{Jari Toivanen}    \\
% \hyperlink{Chan}{Lung-Chak Chan}   &
% \hyperlink{Howell}{Jason S. Howell}   &
% \hyperlink{Newman}{Christopher K Newman}   &
% \hyperlink{Ucar}{Bora Ucar}    \\
% \hyperlink{Conn}{Andrew R. Conn}   &
% \hyperlink{Howle}{Victoria Howle}   &
% \hyperlink{Nolting}{Josh Nolting}   &
% \hyperlink{Vandereycken}{Bart Vandereycken}    \\
% \hyperlink{Dickson}{Kelly I. Dickson}   &
% \hyperlink{Huhtanen}{Marko Huhtanen}   &
% \hyperlink{Olson}{Luke Olson}   &
% \hyperlink{Verhoeven}{Arie A. Verhoeven}    \\
% \hyperlink{Dohrmann}{Clark R. Dohrmann}   &
% \hyperlink{Hu}{Jonathan Hu}   &
% \hyperlink{Overton}{Michael Overton}   &
% \hyperlink{Virnick}{Elena Virnick}    \\
% \hyperlink{Dollar}{Sue Dollar}   &
% \hyperlink{Jiang}{Lianjun Jiang}   &
% \hyperlink{Ovtchinnikov}{Serguei Ovtchinnikov}   &
% \hyperlink{Vuik}{Kees Vuik}    \\
% \hyperlink{Donatelli}{Marco Donatelli}   &
% \hyperlink{Jin}{Chao Jin}   &
% \hyperlink{Pan}{Victor Pan}   &
% \hyperlink{Wachter}{Andreas W\"achter}    \\
% \hyperlink{Doucet}{Cedric Doucet}   &
% \hyperlink{Jordan}{Kirk E. Jordan}   &
% \hyperlink{Pautasso}{Gavino Pautasso}   &
% \hyperlink{Waisman}{Haim Waisman}    \\
% \hyperlink{Douglas}{Craig C. Douglas}   &
% \hyperlink{Karampataki}{Marian Karampataki}   &
% \hyperlink{Pettitt}{B. Montgomery Pettitt}   &
% \hyperlink{Walker}{Homer Walker}    \\
% \hyperlink{Draganescu}{Andrei Dr{\u a}g{\u a}nescu}   &
% \hyperlink{Kelley}{C. T. Kelley}   &
% \hyperlink{Philip}{Bobby Philip}   &
% \hyperlink{Wathen11}{Andy Wathen (2)}    \\
% \hyperlink{Duff}{Iain S Duff}   &
% \hyperlink{Kilmer}{Misha Kilmer}   &
% \hyperlink{Phipps}{Eric T Phipps}   &
% \hyperlink{Westphal}{Chad Westphal}    \\
% \hyperlink{Dunlavy}{Daniel Dunlavy}   &
% \hyperlink{Klie}{Hector Klie}   &
% \hyperlink{Quian}{Haifeng Qian}   &
% \hyperlink{Wong}{Chao-Jen Wong}    \\
% \hyperlink{Duraiswami}{Ramani Duraiswami}   &
% \hyperlink{Knepper}{Sarah M. Knepper}   &
% \hyperlink{Reese}{Jill Reese}   &
% \hyperlink{Xue}{Guangio Xue}    \\
% \hyperlink{Du}{Xiuhong Du}   &
% \hyperlink{Knyazev}{Andrew Knyazev}   &
% \hyperlink{Rees}{Timothy Rees}   &
% \hyperlink{Xu}{Jinchao Xu}    \\
% \hyperlink{Dyadechko}{Vadim Dyadechko}   &
% \hyperlink{Kolev}{Tzanio V. Kolev}   &
% \hyperlink{Renaut}{Rosemary Renaut}   &
% \hyperlink{Yang11}{Chao Yang}    \\
% \hyperlink{Echeverria}{David Echeverr\'{i}a}   &
% \hyperlink{Kostic}{Vladimir Kostic}   &
% \hyperlink{Rodriguez}{Adolfo Rodriguez}   &
% \hyperlink{Yang21}{Ulrike Meier Yang}    \\
% \hyperlink{Elman}{Howard C Elman}   &
% \hyperlink{Langdon}{Stephen Langdon}   &
% \hyperlink{Rommes}{Joost Rommes}   &
% \hyperlink{Yavneh}{Irad Yavneh}    \\
% \hyperlink{Evans}{Katherine J. Evans}   &
% \hyperlink{Langou}{Julien Langou}   &
% \hyperlink{Salinger}{Andrew Salinger}   &
% \hyperlink{Zaslavsky}{Mikhail Zaslavsky}    \\
% \hyperlink{Fattebert}{J.-L. Fattebert}   &
% \hyperlink{Lapenta}{Giovanni Lapenta}   &
% \hyperlink{Sanders}{Geoffrey Sanders}   &
% \hyperlink{Zikatanov}{Ludmil Zikatanov}    \\
% \end{tabular}
% \end{center}
% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \newpage


	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\begin{center} \rule{6in}{1pt} \end{center}
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


% \pdfbookmark[1]{A-B}{a-b}
\begin{center}
{\large			% \hypertarget{Adams}
{\bf Uncertainty and reliability analysis-based design \\
optimization capabilities in the DAKOTA toolkit }}

	Brian M.~Adams \\
	Sandia National Laboratories, P.O.~Box 5800 \\
	MS 0370, Albuquerque NM 87185-0370 \\
	{\tt briadam@sandia.gov} \\
			% \hspace*{9mm}\hfill
	Michael S.~Eldred, Laura P.~Swiler
			% \hfill \hyperlink{index}{\small {\em index}} \\
\end{center}
When using computational models to design devices or systems,
appropriate modeling of uncertainties is crucial to ensure robust and
reliable designs.  This talk offers a survey of uncertainty
quantification and reliability analysis techniques and demonstrates
how they can be tightly integrated with optimization algorithms to
determine designs that meet reliability and robustness constraints in
addition to optimality criteria.  Such optimization under uncertainty
(OUU) capabilities, developed and implemented in Sandia National
Laboratories' DAKOTA toolkit, will be surveyed.  Novel problem
formulations for reliability-based design optimization in realistic
physical applications will be presented and examples of how advanced
reliability methods can provide more accurate estimates of output
uncertainty given.



	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\begin{center} \rule{6in}{1pt} \end{center}
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\begin{center}
{\large			% \hypertarget{Alber}
{\bf Parallel coarse grid selection strategies}}

	David Alber \\
	Siebel Center for Computer Science \\
	University of Illinois at Urbana-Champaign \\
	201 North Goodwin Avenue, Urbana IL 61801 \\
	{\tt alber@uiuc.edu} \\
			% \hspace*{9mm}\hfill
	Luke Olson
			% \hfill \hyperlink{index}{\small {\em index}} \\
\end{center}
Traditional coarse grid selection algorithms for algebraic
multigrid use a strength of connection measure to select
coarse degrees of freedom. The strength of connection is a
heuristic used to determine the influences between degrees
of freedom in M-matrices. Coarsening algorithms using a
strength of connection are known to select ineffective
coarse grids for some cases where the operator is not an
M-matrix. Additionally, these methods do not consider other
information such as the smoother to be used in the solve
phase. Alternatively, compatible relaxation selects coarse
grids without explicitly using a strength of connection
measure. Instead, a smoother is applied to identify degrees
of freedom where the smooth error is large. This information
is then used to select the coarse grid. Recent work on
compatible relaxation has produced viable serial
implementations and useful theoretical results. The goal of
this work is to produce effective and efficient parallel
compatible relaxation methods. In this talk, parallel
compatible relaxation implementations will be introduced and
discussed, along with results from experiments on both
structured and unstructured problems.



	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\begin{center} \rule{6in}{1pt} \end{center}
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{center}
{\large			% \hypertarget{Anderson}
{\bf An additive Schwarz parallel approach to space-time \\
finite elements for hyperbolic equations}}

	Matthew Anderson \\
	Louisiana State University Dept.~of Physics \& Astronomy \\
	202 Nicholson Hall Tower Drive,  Baton Rouge LA 70803-4001 \\
	{\tt matt@phys.lsu.edu} \\
			% \hspace*{9mm}\hfill
	Jung-Han Kimn
			% \hfill \hyperlink{index}{\small {\em index}} \\
\end{center}
We study a time parallel space-time finite element approach
for the nonhomogeneous wave equation using a continuous time
Galerkin method and a time decomposition strategy for
preconditioning. Space-time finite elements provide some
natural advantages for numerical relativity in black hole
simulations. With space-time elements, time-varying
computational domains are straightforward, higher-order
approaches are easily formulated, and both time and spatial
domains can be discretized using a more general mesh. We
present fully implicit examples in $1+1$, $2+1$, and $3+1$
dimensions using linear quadrilateral, hexahedral, and
tesseractic elements. Krylov solvers with additive Schwarz
preconditioning are used for solving the linear system. We
introduce a time decomposition strategy in preconditioning
which significantly improves performance when compared with
unpreconditioned cases. Parallel performance results are
also given.




	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\begin{center} \rule{6in}{1pt} \end{center}
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{center}
{\large			% \hypertarget{Argentati}
{\bf A priori error bounds for eigenvalues approximated by the Ritz values}}

	Merico E.~Argentati \\
	Dept.~of Mathematical Sciences \\
	 University of Colorado at Denver and Health Sciences Center \\
	 P.O.~Box 173364, Campus Box 170, Denver CO 80217-3364 \\
	{\tt rargenta@math.cudenver.edu} \\
			% \hspace*{9mm}\hfill
	Andrew V.~Knyazev
			% \hfill \hyperlink{index}{\small {\em index}} \\
\end{center}
The Rayleigh-Ritz method finds the stationary values of the
Rayleigh quotient, called Ritz values, on a given trial
subspace as optimal, in some sense, approximations to
eigenvalues of a Hermitian operator $A$. When a trial subspace
is invariant with respect to $A$, the Ritz values are some of
the eigenvalues of $A$. Given two finite dimensional subspaces
$X$ and $Y$ of the same dimension, such that $X$ is an invariant
subspace of $A$, the absolute changes in the Ritz values of $A$
with respect to $X$ compared to the Ritz values with respect
to $Y$ represent the absolute eigenvalue approximation error.

We estimate the error in terms of the principal angles
between $X$ and $Y$. There are several known results of this
kind, e.g., for the largest (or the smallest) eigenvalues of
$A$, the maximal error is bounded by a constant times the sine
squared of the largest principal angle between $X$ and $Y$. The
constant is the difference between the largest and the
smallest eigenvalues of $A$, called the spread of the spectrum
of $A$.

We prove that the absolute eigenvalue error is
majorized by a constant times the squares of the sines of
the principal angles between the subspaces $X$ and $Y$, where
the constant is proportional to the spread of the spectrum
of $A$, e.g., for Ritz values that are the largest or smallest
contiguous set of eigenvalues of $A$, we show that the
proportionality factor is simply one. Our majorization
results imply a very general set of inequalities, and some
of the known error bounds follow as special cases.
Majorization results of this kind are not apparently known
in the literature and can be used, e.g., to derive novel
convergence rate estimates of the block Lanczos method.




	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\begin{center} \rule{6in}{1pt} \end{center}
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\newpage

\begin{center}
{\large			% \hypertarget{Austin}
{\bf Multilevel homogenization techniques for the cardiac bidomain equations}}

	Travis M Austin \\
	Bioengineering Institute University of Auckland \\
	Private Bag 92019, \quad Auckland, New Zealand \\
	{\tt t.austin@auckland.ac.nz} \\
			% \hspace*{9mm}\hfill
	Mark L Trew, Andrew J Pullan
			% \hfill \hyperlink{index}{\small {\em index}} \\
\end{center}
The cardiac bidomain equations are a set of nonlinear
partial differential equations that are used to model the
flow of current within cardiac tissue by treating
intracellular and extracellular space as two
interpenetrating domains. In the past 10 years research
groups around the world have been using the bidomain
equations in a variety of sophisticated ways, from modeling
fibrillation in the human heart to understanding how plunge
electrodes affect potential fields during in vitro
experiments on cardiac tissue. The Bioengineering Institute
at the University of Auckland has been a world leader in
imaging cardiac tissue at a microscale resolution, and
discovering specialized features that can be incorporated
into the bidomain model.

In this talk, I will briefly
introduce the Bioengineering Institute's imaging work, and
then focus on how we are using these imaging results in our
modeling framework. This discussion will focus on how we
are using Black Box Multigrid to generate homogenized models
that take into account the discontinuities found at the
mezoscale. Such models allow the effect of the discontinuous
cardiac structures to be seen in the potential fields at a
reduced cost. This work is founded upon the multilevel
upscaling approach of MacLachlan and Moulton (Water
Resources Research, 2005), and begins exploring their ideas
in three-dimensions and in a time-dependent framework.



	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\begin{center} \rule{6in}{1pt} \end{center}
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{center}
{\large			% \hypertarget{Baird}
{\bf The representer method for data assimilation
of two phase flow in porous media}}

	John Baird \\
	Institute for Computational Engineering and Sciences \\
	The University of Texas at Austin \\
	1 Texas Longhorns, \#C0200, \quad  Austin TX 78712 \\
	{\tt jbaird@ices.utexas.edu} \\
			% \hspace*{9mm}\hfill
	Clint Dawson
			% \hfill \hyperlink{index}{\small {\em index}} \\
\end{center}
Advances in instrumenting and imaging the subsurface are
yielding large data sets, making data assimilation vital to
modeling flow through porous media. We derive and implement
the representer method applied to the oil/water model for
reservoirs, a nonlinear model. The representer method, like
the Kalman filter, solves the Euler-Lagrange (E-L) system
for the minimizer of a least-squares functional of the
misfit between the model and measurements. Because the
representer method uses the superposition principle, a
nonlinear model requires linearization of the E-L system. A
key concern is finding a linearization that converges
appropriately. We show that convergence is strongly affected
by the choice of weights in the least-squares functional. We
also compare the effects of linearization and the
computational costs of the representer method with the
ensemble Kalman filter.



	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\begin{center} \rule{6in}{1pt} \end{center}
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\newpage

\begin{center}
{\large			% \hypertarget{Beardmore}
{\bf A numerical bifurcation analysis of the Ornstein-Zernike equation}}

	Robert E Beardmore \\
	Dept.~of Mathematics, Imperial College London \\
	South Kensington Campus,  London SW7 2AZ UK \\
	{\tt r.beardmore@ic.ac.uk} \\
			% \hspace*{9mm}\hfill
	A Peplow, F Bresme
			% \hfill \hyperlink{index}{\small {\em index}} \\
\end{center}
The isotropic Ornstein-Zernike (OZ) equation
$$
\qquad
\qquad
\qquad
h(r) = c(r) + \rho \int_{\mathbb{R}^{3}}
h(\|{\bf x}-{\bf y}\|)c(\|{\bf y}\|)d{\bf y},
\qquad
\qquad
\qquad
(1)
$$
that is the subject of this
paper was presented almost a century ago to model the
molecular structure of a fluid at varying densities. In
order to form a well-posed mathematical system of equations
from (1) that can be solved, at least in
principle, we assume the existence of a closure
relationship. This is an algebraic equation that augments
(1) with a pointwise constraint that is deemed to
hold throughout the fluid and it forces a relationship
between the total and direct correlation functions ($h$ and
$c$ respectively).

Some closures have a mathematically
appealing structure in the sense that the total correlation
function is posed as a perturbation of the {\em Mayer
f-function} given by \[ f(r)=-1+e^{-\beta u(r)}.\] This
perturbation depends on the potential $u$, temperature
(essentially $1/\beta$) and the indirect correlation
function through a nonlinear function that we denote $G$:
$$
\qquad
\qquad
\qquad
h = f(r) + e^{-\beta u(r)}G(h-c),
\qquad
(G(0)= 0),
\qquad
\qquad
\qquad
(2)
$$
so that (1-2) are solved together with $\beta$
and $\rho$ as bifurcation parameters. There are many
closures in use and if we write $\exp_1(z) = -1+e^z$ then
the hyper-netted chain (HNC) closure
$$
\qquad
\qquad
\qquad
\qquad
\qquad
G(\gamma) = \exp_1(\gamma)
\qquad
\qquad
\qquad
\qquad
\qquad
(3)
$$
has the form of
(2) and is popular in the physics and chemistry
literature.

The purpose of the talk is show that {\em any
reasonable} discretisation method applied to
(1-2) suffers from an inherent defect if
the HNC closure is used that can be summarised as follows:
phase transitions lead to fold bifurcations. The existence
of a phase transition is characterised by the existence of a
bifurcation at infinity with respect to $h$ in an $L^1$ norm
at a certain density, such that boundedness of $h$ is
maintained in a certain $L^p$ norm. This behaviour is
difficult to mimic computationally by projecting onto a
space of fixed and finite dimension and, as a result,
projections of (1-2) can be shown to
undergo at least one fold bifurcation if such a bifurcation
at infinity is present. However, other popular closure
relations do not necessarily suffer from the same defect.



	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\begin{center} \rule{6in}{1pt} \end{center}
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\newpage

\begin{center}
{\large			% \hypertarget{Beattie}
{\bf Model reduction of large scale second-order systems with modal damping}}

	Christopher Beattie \\
	Dept.~of Mathematics,
	Virginia Polytechnic Institute \& State University \\
	Blacksburg VA 24061 \\
	{\tt beattie@vt.edu} \\
			% \hspace*{9mm}\hfill
	Serkan Gugercin
			% \hfill \hyperlink{index}{\small {\em index}} \\
\end{center}
An approach is described for model reduction of second-order
systems with types of normal mode damping that include the
most common varieties: proportional damping and square-root
damping. We show that unlike the general case that requires
usage of a second-order Krylov subspace structure, one can
build up instead approximating subspaces satisfying all
required conditions much more cheaply as direct sums of
standard rational Krylov subspaces within much smaller
component subspaces.

We give a detailed analysis of the
distribution of system poles, and then, through descriptive
bounds that carry the flavor of classical approximation
theory, we are able to exploit the structure of these poles
to obtain asymptotically optimal shift selection strategies.
Numerical examples are provided to illustrate and support
the analysis.


	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\begin{center} \rule{6in}{1pt} \end{center}
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{center}
{\large			% \hypertarget{Benzi}
{\bf An augmented Lagrangian approach for the Oseen problem}}

	Michele Benzi \\
	Dept.~of Mathematics and Computer Science \\
	Emory University, 400 Dowman Drive, Atlanta GA 30322 \\
	{\tt benzi@mathcs.emory.edu} \\
			% \hspace*{9mm}\hfill
	Maxim A.~Olshanskii
			% \hfill \hyperlink{index}{\small {\em index}} \\
\end{center}
We describe an effective solver for the discrete Oseen
problem based on an augmented Lagrangian formulation of the
corresponding saddle point system. The proposed method is a
block triangular preconditioner used with a Krylov subspace
iteration (BiCGStab). The crucial ingredient is a novel
multigrid approach for the (1,1) block, which extends a
technique introduced by Sch\"oberl for elasticity problems
to nonsymmetric problems. Our analysis indicates that this
approach results in fast convergence, independent of the
mesh size and largely insensitive to the viscosity. We
present experimental evidence for both isoP2-P0 and isoP2-P1
finite elements in support of our conclusions. We also show
results of a comparison with a state-of-the-art coupled
multigrid solver, showing the competitiveness of our
approach.




	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\begin{center} \rule{6in}{1pt} \end{center}
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{center}
{\large			% \hypertarget{Berlyand}
{\bf Discrete network approximation for singular behavior of \\
the effective viscosity of concentrated suspensions}}

	Leonid Berlyand \\
	Mathematics Department, Penn State University \\
	University Park  PA 16801  \\
	{\tt berlyand@math.psu.edu} \\
			% \hspace*{9mm}\hfill
	Yuliya Gorb, Alexei Novikov
			% \hfill \hyperlink{index}{\small {\em index}} \\
\end{center}
We present a new approach for calculation of effective
properties of high contrast random composites and illustrate
it by considering highly packed suspensions of rigid
particles in a Newtonian fluid.

The main idea of this
approach is a reduction of the original continuum problem,
which is described by PDE with rough coefficients, to a
discrete random network. This reduction is done in two steps
which constitute the ``fictitious fluid'' approach. In Step 1
we introduce a ``fictitious fluid'' continuum problem when
fluid flows only in narrow channels between closely spaced
particles, which reflects physical fact that the dominant
contribution to the dissipation rate comes from these
channels. In Step 2 we derive a discrete network
approximation for the latter continuum problem.

Next we
use this approach to calculate the effective viscous
dissipation rate in a 2D model of a suspension. We show that
under certain boundary conditions the model exhibits an
anomalously strong rate of blow up when the concentration of
particles tends to maximal. We explore physical ramification
of this phenomenon.

We will also discuss how an
iterative procedure of the network construction which may be
used in the study of dynamics of highly packed suspensions.



	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\begin{center} \rule{6in}{1pt} \end{center}
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{center}
{\large			% \hypertarget{Boyle}
{\bf Algebraic multigrid and convection diffusion problems}}

	Jonathan W Boyle \\
	School of Mathematics, The University of Manchester \\
	Sackville Street, Manchester M60 1QD UK \\
	{\tt j.boyle@manchester.ac.uk} \\
			% \hspace*{9mm}\hfill
	David J Silvester
			% \hfill \hyperlink{index}{\small {\em index}} \\
\end{center}
The talk discusses the use of algebraic multigrid (AMG) when
solving discrete convection diffusion problems. For
practical applications, e.g. modeling incompressible fluid
flow, the interest is in using AMG as a preconditioning
component within a Krylov subspace solver like GMRES. To be
effective in this role, the AMG method should be 'black
box', i.e. require no user tuning, and be effective in the
sense that if applied as a solver for a convection-diffusion
subproblem then iteration counts are independent of mesh
size and other problem parameters.

When designing AMG for
convection diffusion, it is necessary to consider the
interplay between wind direction and AMG smoothing scheme.
Numerical test data is presented showing performance for AMG
applied to streamline diffusion stabilized finite element
discretizations of model problems. The results demonstrate
the crucial importance of choosing an appropriate smoothing
scheme. The performance of a ``well-chosen'' AMG method in the
context of pressure-convection diffusion preconditioning of
the Navier-Stokes equations will also be discussed.

This is ongoing work.
It is funded by EPSRC grant EP/C000528/1.


	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\begin{center} \rule{6in}{1pt} \end{center}
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{center}
{\large			% \hypertarget{Brannick}
{\bf Compatible relaxation and coarsening in algebraic multigrid}}

	James Brannick \\
	Institute for Scientific Computing Research \\
	Lawrence Livermore National Laboratory \\
	Box 808, L551, Livermore CA 94551 \\
	{\tt brannick@colorado.edu} \\
	Steve McCormick, Marian Brezina,
			% \hspace*{9mm}\hfill
	Rob Falgout, Tom Manteuffel, John Ruge, Ludmil Zikatanov
			% \hfill \hyperlink{index}{\small {\em index}} \\
\end{center}
Algebraic multigrid (AMG) has been shown to be an efficient
iterative solver for many of the large and sparse linear
systems arising from the discretization of partial
differential equations. There remain, however, many classes
of problems for which conventional AMG setup algorithms,
based on the properties of M-matrices, are inappropriate. In
this talk, we consider the use of compatible relaxation (CR)
as a tool for extending the applicability of AMG. A CR-based
coarsening algorithm is presented along with numerical
results demonstrating that the variational multigrid solver
resulting from the proposed approach maintains
multigrid-like optimality, without the need for parameter
tuning, for some problems where current algorithms exhibit
degraded performance.



	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\begin{center} \rule{6in}{1pt} \end{center}
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{center}
{\large			% \hypertarget{Bru}
{\bf Quasi-Newton preconditioners for the iterative solution \\
	of nonlinear equation in porous media}}

	Rafael Bru \\
	Inst. Matematica Multidisciplinar, Dept. Matematica Aplicada \\
	Univ. Politecnica Cami de Vera s/n 46021, Valencia, Spain \\
	{\tt rbru@mat.upv.es} \\
	Luca Bergamaschi, Andrea Comerlati,
			% \hspace*{9mm}\hfill
	Angeles Mart\'{\i}nez and Mario Putti
			% \hfill \hyperlink{index}{\small {\em index}} \\
\end{center}
In this work preconditioners for solving the linear systems
of the Newton method in each nonlinear iteration are
studied. The preconditioners are defined by means of a
Broyden-type rank-one update at each nonlinear iteration, as
described in [1]. We report numerical results of the
application of this approach for the solution of the
nonlinear system of algebraic equations arising from the
finite element discretization of two-phase flow model in
porous media. Sequential and parallel results show that the
efficiency of the proposed method. The parallel version of
the algorithm uses the FSAI approximate inverse as initial
preconditioner [2]. The obtained performances show that the
high cost of the FSAI evaluation is amortized by the
efficiency of the subsequent Broyden updates.

[1]
L.~Bergamaschi, R.~Bru, A.~Martinez and M.~Putti,
{\em Quasi-Newton Preconditioners for the Inexact Newton
Method}, to appear in Electr. Trans. on Num. Analysis,
2006.

[2] L.~Yu. Kolotilina and A.~Yu.~Yeremin,
{\em Factorized sparse approximate inverse preconditionings.
I. Theory},
SIAM J.~Matrix Anal. Appl., {\bf 14} (1993) 45--58.


	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\begin{center} \rule{6in}{1pt} \end{center}
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{center}
{\large			% \hypertarget{Butler}
{\bf Improving coarsening and interpolation for algebraic multigrid}}

	Jeff Butler \\
	Dept.~of Applied Mathematics, University of Waterloo \\
	Waterloo, Ontario, Canada N2L 3G1 \\
	{\tt jsbutler@math.uwaterloo.ca} \\
			% \hspace*{9mm}\hfill
	Hans De Sterck
			% \hfill \hyperlink{index}{\small {\em index}} \\
\end{center}
Algebraic multigrid (AMG) is one of the most efficient
algorithms for solving large sparse linear systems on
unstructured grids. Classical coarsening schemes such as the
standard Ruge-Steuben method [1] can lead to adverse effects
on computation time and memory usage that affect
scalability. Memory and execution time complexity growth is
remedied for various large three-dimensional (3D) problems
using the parallel modified independent set (PMIS)
coarsening strategy developed by De Sterck, Yang, and Heys
[2]. However, this coarsening strategy often leads to
erratic grids without a regular structure that diminish
convergence. This talk looks at a modification of the PMIS
algorithm that consistently produces more uniform
coarsenings, and significantly improves convergence
properties over the original PMIS algorithm. Improvements of
existing interpolation schemes and application of the
resulting methods to several problems are also examined.

[1] J.~Ruge, K.~Stueben, {\em Algebraic multigrid (AMG)},
Multigrid Methods v.3, Frontiers in Applied Mathematics,
S.~McCormick, ed., SIAM (1987) 73--130.

[2] H.~De Sterck, U.~M.~Yang, and J.~J.~Heys,
{\em Reducing Complexity in Parallel Algebraic
Multigrid Preconditioners}, to appear in
SIAM J.~Matr. An. and Applications, 2006.



	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\begin{center} \rule{6in}{1pt} \end{center}
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% \pdfbookmark[1]{C-D}{c-d}
\begin{center}
{\large			% \hypertarget{Canning}
{\bf New iterative eigensolvers and preconditioners for electronic structure calculations in nano and materials science}}

	Andrew Canning \\
	LBNL MS-50F, One Cyclotron Road, Berkeley CA 94720 \\
	{\tt acanning@lbl.gov} \\
	Julien Langou, Christof Voemel, Osni Marques \\
			% \hspace*{9mm}\hfill
	Stanimire Tomov, Gabriel Bester, Lin-Wang Wang
			% \hfill \hyperlink{index}{\small {\em index}} \\
\end{center}
Density functional based electronic structure calculations
have become the most heavily used approach in materials
science to calculate materials properties with the accuracy
of a full quantum mechanical treatment of the electrons.
This approach results in a single particle form of the
Schr\"{o}dinger equation which is a non-linear eigenfunction
problem. The standard self-consistent solution of this
problem involves solving for the lowest eigenpairs
corresponding to the electrons in the system. In
non-self-consistent formulations the problem becomes one of
determining the interior eigenpairs corresponding to the
electrons of interest which are typically around the gap in
the eigenvalue spectrum for non-metallic systems.

In this
talk I will present results for new iterative eigensolvers
based on conjugate gradients (the LOBPCG method) in the
context of plane wave electronic structure calculations.
This new method gives significant speedup over existing
conjugate gradient methods used in electronic structure
calculations.
I will also present results for a new
preconditioner based on first solving the bulk structure
corresponding to a given nanosystem and then using that as a
preconditioner to solve the nanosystem.

This new
preconditioner gives significant speedup compared to
previously used preconditioners based on the diagonal of the
matrix. These new methods will be demonstrated for CdSe
quantum dots as well as quantum wires constructed from
layers of InP and InAs.  This work was supported by the
Director, Office of Advanced Scientific Computing Research,
Division of Mathematical, Information and Computational
Sciences of the U.S. Dept.~of Energy and the Laboratory
Directed Research and Development Program of Lawrence
Berkeley National Laboratory under contract number
DE-AC03-76SF00098.



	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\begin{center} \rule{6in}{1pt} \end{center}
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{center}
{\large			% \hypertarget{Chacon}
{\bf A fully implicit extended 3D MHD solver}}

	Luis Chacon \\
	MS K717, Los Alamos National Laboratory, Los Alamos NM 87545 \\
	{\tt chacon@lanl.gov} \\
			% \hspace*{9mm}\hfill
	Dana A.~Knoll
			% \hfill \hyperlink{index}{\small {\em index}} \\
\end{center}
We present results from our research on Jacobian-free
Newton-Krylov (JFNK) methods applied to the time-dependent,
primitive-variable, 3D extended magnetohydrodynamics (MHD)
equations. MHD is a fluid description of the plasma state.
While plasma is made up of independent (but coupled) ion and
electron species, the standard MHD description of a plasma
only includes ion time and length scales (one-fluid model).
Extended MHD (XMHD) includes nonideal effects such as
nonlinear, anisotropic transport and two-fluid (Hall and
diamagnetic) effects. XMHD supports so-called dispersive
waves (whistler, ion acoustic), which feature a quadratic
dispersion relation $\omega \sim k^{2}$. In explicit time
integration methods, this results in a stringent CFL limit
$\Delta t_{CFL}\propto \Delta x^{2}$, which severely limits
their applicability to the study of long-frequency phenomena
in XMHD.

A fully implicit implementation promises
efficiency (by removing the CFL constraint) without
sacrificing numerical accuracy [1].
However, the nonlinear
nature of the XMHD system and the numerical stiffness of its
fast waves make this endeavor very difficult. Newton-Krylov
methods can meet the challenge provided suitable
preconditioning is available.

We propose a successful
preconditioning strategy for the 3D primitive-variable XMHD
formalism. It is based on ``physics-based'' ideas [2,3],
in which a hyperbolic system of
equations (which is diagonally submissive for $\Delta
t>\Delta t_{CFL}$) is {}``parabolized'' to arrive to a
diagonally dominant approximation of the original system,
which is multigrid-friendly. The use of approximate
multigrid (MG) techniques to invert the {}``parabolized''
operator is a crucial step in the effectiveness of the
preconditioner and the scalability of the overall algorithm.
The parabolization procedure can be properly generalized
using the well-known Schur decomposition of a 2$\times $2
block matrix. In the context of XMHD, the resulting Schur
complement is a system of PDEs that couples the three
plasma velocity components, and needs to be inverted in a
coupled manner. Nevertheless, a system MG treatment is still
possible since, when properly discretized, the XMHD Schur
complement is block diagonally dominant by construction, and
block smoothing is effective.

In this presentation, we
will discuss the derivation and validity of the
physics-based preconditioner for resistive MHD and its
generalization to XMHD, the connection with Schur complement
analysis, and the system-MG treatment of the associated
systems. A novel second-order, cell-centered, conservative
finite-volume discretization has been recently developed [4]
for the XMHD system above, and will be used
in this work. It is suitable for general curvilinear
geometries, solenoidal in $\mathbf{B}$ and $\mathbf{J}$,
numerically non-dissipative, and linearly and nonlinearly
stable. We will demonstrate the algorithm using the GEM
challenge configuration [5].
Grid convergence
studies will demonstrate that CPU time scales scale
optimally as $\mathcal{O}(N)$, where $N$ is the number of
unknowns, and that the number of Krylov iterations scales as
$\mathcal{O}(N^{0})$. Time convergence studies will
demonstrate a favorable scaling with time step
$\mathcal{O}(\Delta t^{\alpha })$, with $\alpha <1.0$.

[1] D.~A.~Knoll, L.~Chac\'{o}n, L.~G.~Margolin, and V.~A.~Mousseau,
J.~Comput. Phys. \textbf{185} (2003) 583.

[2] L.~Chac\'{o}n, D.~A.~Knoll, and J.~M.~Finn,
J.~Comput. Phys., \textbf{178} (2002) 15.

[3] L.~Chac\'{o}n and D.~A.~Knoll, J.~Comput. Phys.,
\textbf{188} (2003) 573.

[4] L.~Chac\'{o}n, Comp. Phys. Comm., \textbf{163} (2004) 143.

[5] J.~Birn et al.,
J.~Geophys. Res., \textbf{106} (2001) 3715.


	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\begin{center} \rule{6in}{1pt} \end{center}
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{center}
{\large			% \hypertarget{Chan}
{\bf Preconditioning analysis for weighted
Toeplitz regularized least squares problems}}

	Lung-Chak Chan \\
	Dept. of Mathematics, The University of Hong Kong \\
	Pokfulam Road, Hong Kong \\
			% \hspace*{9mm}\hfill
	{\tt lungchak@graduate.hku.hk}
			% \hfill \hyperlink{index}{\small {\em index}} \\
\end{center}
We consider preconditioners for weighted Toeplitz
regularized least squares (WTRLS) problems 
$$ 
\min_z \| A z - b \|_2^2
$$
where the rectangular coefficient matrix $A$ and the
right-hand side vector $b$ are of the form:
$$ 
A =
\left [
\begin{array}{c}
W_1 H \\
\mu W_2 L \\
\end{array}
\right ] \in \Reals^{(m_{1}+m_{2}) \times m_{1}} \quad {\rm and}\quad  b =
\left [
\begin{array}{c}
W_1 f \\
 0 \\
\end{array}
\right ] \in \Reals^{m_{1}+m_{2}} \,.
$$
Here $H \in \Reals^{m_{1} \times m_{1}}$ is a Toeplitz matrix, $L
\in \Reals^{m_{2} \times m_{1}}$ is the first-order or second-order
difference matrix, $W_1 \in \Reals^{m_{1} \times m_{1}}$ and $W_2
\in \Reals^{m_{2} \times m_{2}}$ are non-scalar diagonal matrices
with real positive entries, $f \in \Reals^{m_{1}}$ is a given
right-hand side vector and $\mu >0$ is a regularization parameter.

Iterative methods using circulant preconditioners has been proposed 
since 1980s. 
The efficiency of solving systems are
greatly enhanced by these indirect methods.  Since then,
preconditioners based on circulant matrices were suggested for
solving the WTRLS problems.  However, most of them do not perform
satisfactorily and the results of convergence rates can be disappointing.

Benzi and Ng 
considered the above system
where $W_{2}L$ is replaced by $I$, and proposed a new approach to
solve it which is based on an augmented system formulation. We now
adopt a similar approach that transforms the problem into a
$3 \times 3$ block linear system.

The WTRLS problems turn out to be a quadratic minimization
problem, which is equivalent to solving the linear system
$$ 
(H^{T}W_{1}^{-2}H + \mu^{2} L^{T}W_{2}^{-2}L)z
= H^{T} W_{1}^{-2} f~.
$$

The above linear system can overall be rewritten as
the following $3 \times 3$ block system:
$$ 
\left[ \begin{array}{ccc} W_{1}^{-2} & 0 & H \\
0 & W_{2}^{-2} & \mu L \\
H^{T} & \mu L^{T} & 0 \end{array} \right]
\left[ \begin{array}{c} x \\ y \\ z \end{array} \right]
= \left[ \begin{array}{c} 0 \\ 0 \\
-H^{T} W_{1}^{2} f \end{array} \right]~.
$$

There are not any particular results discussing how
to solve a general $3 \times 3$ system effectively.  
The four upper left blocks are considered as one single
block and the corresponding two upper right blocks
$[H^{T} \ \mu L^{T}]^{T}$ together
still attain full rank, so we treat this system
as a $2 \times 2$ block case 
and consider methods developed for solving indefinite systems.  
Here we shall adopt constraint preconditioner 
and Hermitian skew-Hermitian splitting (HSS)
preconditioner and investigate them in details.

The formulation and actual preconditioning settings for
WTRLS problems will be discussed.
A test problem is performed to demonstrate the convergence behaviour
using these iterative methods.  We shall see that the number of iterations
mainly depend on the condition numbers of $W_{1}$ and $W_{2}$ as
well as some factors related to each preconditioners. 
In particular, this effect is more significant in
the case of using HSS preconditioner.  The iteration results and
the weaknesses for both preconditioners can be explained
with some analyses on the spectra for them.



	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\begin{center} \rule{6in}{1pt} \end{center}
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{center}
{\large			% \hypertarget{Conn}
{\bf Some new results in derivative free optimization}}

	Andrew R.~Conn \\
	IBM T.J.~Watson Research Center, Mathematical Sciences \\
	32-206 1101 Kitchawan Rd., Yorktown Heights NY 10598 \\
	{\tt arconn@us.ibm.com} \\
			% \hspace*{9mm}\hfill
	Luis Vicente, Katya Scheinberg
			% \hfill \hyperlink{index}{\small {\em index}} \\
\end{center}
Some new results on derivative free methods will be
presented. These have broader implications for, for example,
second-order trust-region methods.



	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\begin{center} \rule{6in}{1pt} \end{center}
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{center}
{\large			% \hypertarget{Dickson}
{\bf Uniformly well-conditioned pseudo-arclength continuation}}

	Kelly I.~Dickson \\
	243 Harrelson Hall, Campus Box 8205 \\
	North Carolina State University, Raleigh NC 27695 \\
	{\tt kidickso@unity.ncsu.edu} \\
			% \hspace*{9mm}\hfill
	C.T.~Kelley, I.~C.~F.~Ipsen, I.~G.~Kevrekidis
			% \hfill \hyperlink{index}{\small {\em index}} \\
\end{center}
Numerical continuation is the process of solving nonlinear
equations of the form \[G(x,\lambda)=0\] for various real
number parameter values, $\lambda$. The obvious approach,
called natural parameterization, is to perturb $\lambda$
with each continuation step and find the corresponding
solution $x$ via a nonlinear solver (Newton's method). While
this approach is reasonable for paths containing only
regular points (points $(x,\lambda)$ where the Jacobian
matrix of $G$ is nonsingular), the approach breaks down at
simple fold points where the Jacobian matrix of $G$ becomes
singular and Newton's method fails.

In order to remedy this,
one may implement pseudoarclength continuation (PAC) which
introduces a new parameter based on the arclength $s$ of the
solution path. In order to implement PAC, one converts the
old problem $G(x,\lambda)=0$ to a new problem
\[F(x(s),\lambda(s))=0.\]
Using PAC on the new problem
requires the Jacobian matrix of $F$, $F'$, which ought to be
nonsingular at both regular points and simple folds if we
have indeed bypassed the problem that natural
parameterization presents.

While the nonsingularity of $F'$
at regular points and simple folds is a known fact, we
present a theorem that gives conditions under which $F'$ is
uniformly nonsingular for a path containing simple folds. We
do this by bounding the smallest singular value of $F'$ from
below. The theorem justifies the use of PAC in a practical
way for solution curves containing nothing ``worse'' than a
simple fold.



	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\begin{center} \rule{6in}{1pt} \end{center}
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{center}
{\large			% \hypertarget{Dohrmann}
{\bf Interpolation operators for algebraic multigrid by local optimization}}

	Clark R.~Dohrmann \\
	Sandia National Laboratories, Mail Stop 0847 \\
	Albuquerque NM 87185-0847 \\
			% \hspace*{9mm}\hfill
	{\tt crdohrm@sandia.gov}
			% \hfill \hyperlink{index}{\small {\em index}} \\
\end{center}
An approach is presented to construct the interpolation
operators of algebraic multigrid (AMG) based on solving a
series of local optimization problems. Given a set of coarse
nodes, the approach first attempts to maximize the support
of these nodes without introducing additional nonzeros in
the stiffness matrix of the next coarser level. By doing so,
it is possible to reduce the energy of coarse interpolations
without increasing operator complexity.

The local
optimization problems are formulated in such a way that the
problem null space can be represented exactly at each
multigrid level. In addition, a condition ensuring
nonsingularity of a local matrix highlights the need for
special considerations when the null space dimension exceeds
the number of unknowns for each node. Numerical examples for
the Poisson equation and linear elasticity demonstrate the
effectiveness of the approach and the optimal performance of
an ensuing AMG preconditioner. Connections with element-free
AMGe are also described.



	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\begin{center} \rule{6in}{1pt} \end{center}
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{center}
{\large			% \hypertarget{Dollar}
{\bf Constraint-style preconditioners for regularized saddle point problems}}

	Sue Dollar \\
	Dept.~of Mathematics, University of Reading \\
	Whiteknights, P.O.Box 220, Reading, Berkshire, RG6 6AX, UK
			% \hspace*{9mm}\hfill
	\\ {\tt h.s.dollar@reading.ac.uk}
			% \hfill \hyperlink{index}{\small {\em index}} \\
\end{center}
The problem of finding good preconditioners for the numerical
solution of a certain important class of indefinite linear
systems is considered. These systems are of a saddle point
structure
$$ \TwoMatrx{A}{B^T}{B}{-C} \TwoVec{x}{y} = \TwoVec{c}{d}, $$
where $A\in\Reals^{n\times n}$,
$C\in\Reals^{m\times m}$ are symmetric,
and $B\in\Reals^{m\times n}$ has full rank.

In {\em
Constraint preconditioning for indefinite linear systems},
SIAM J.~Matrix Anal. Appl. {\bf 21} (2000),
Keller, Gould and Wathen analyzed the idea of
using constraint preconditioners that have a
specific 2 by 2 block structure for the case of
$C$ being zero. We
shall extend this idea by allowing the (2,2) block to be
non-zero. Results concerning the spectrum and form of the
eigenvectors are presented, as are numerical results to validate
our conclusions.
We will also introduce the idea of
implicit-factorization constraint preconditioners which allow us
to efficiently carry out the required preconditioning steps.



	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\begin{center} \rule{6in}{1pt} \end{center}
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{center}
{\large			% \hypertarget{Donatelli}
{\bf Filter factor analysis of an iterative multilevel regularizing method}}

	Marco Donatelli \\
	Dipartimento de Fisica e Matematica,
	Universit\`a dell'Insubria \\
	Sede di Como, Via Valleggio 11, 22100 Como, Italy \\
			% \hspace*{9mm}\hfill
	{\tt marco.donatelli@uninsubria.it}
			% \hfill \hyperlink{index}{\small {\em index}} \\
\end{center}
Recent results have shown that iterative methods of multigrid
type are very effective for regularizing purposes.
In short, the reconstruction quality is of the same level
or slightly better than that related to well-known
regularizing procedures such as Landweber or conjugate
gradient (CG) for normal equations, but the associated
computational cost is highly reduced.

Here we analyze the filter features of one of these
multigrid techniques in order to provide a theoretical
motivation for the excellent regularizing characteristics
experimentally observed in the discussed methods.


	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\begin{center} \rule{6in}{1pt} \end{center}
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{center}
{\large			% \hypertarget{Doucet}
{\bf Scaling models and data for solving large sparse \\
linear systems: a comparison of methods}}

	Cedric Doucet \\
	Cedrat SA 15, Chemin de Malacher 38240 Meylan \\
	{\tt cedric.doucet@cedrat.com} \\
			% \hspace*{9mm}\hfill
	I.~Charpentier, J.-L.~Coulomb, C.~Guerin
			% \hfill \hyperlink{index}{\small {\em index}} \\
\end{center}
As industrial problems may involve different kinds of
physical parameters and different types of coupled
equations, ill-conditioned sparse linear systems may arise
from the discretization method. Let $Au=f$ be a nonsingular
sparse linear system where $A\in \mathbb{C}^{n\times n}$,
and $u,f\in \mathbb{C}^n$. If the spectral condition number
$\kappa(A)$ is too far from one, direct solvers can lack of
accuracy and iterative methods can fail to converge. An
economical way of avoiding these difficulties is to find two
diagonal matrices $D_r$ and $D_c$ such that
$\kappa(D_rAD_c) \approx
% \underset{D_1,D_2}{min}{\kappa(D_1A,D_2)}$.
\min_{D_1,D_2} \kappa(D_1A,D_2)$.
Then,
the solving process becomes \begin{enumerate} \item compute
$\hat{u}$ such that $\hat{A}\hat{u}=\hat{f}$ \item compute
$u = D_c\hat{u}$ \end{enumerate} where $\hat{A}= D_rAD_c$
and $\hat{f}=D_rf$.
Numerical properties of $\hat{A}$ differ
according to the scaling method; it can have normalized
rows/columns [2] or it can be approximately doubly
stochastic [3]. Other methods make the matrix have arbitrary
row/column sums [1]. In this paper, we propose to make clear
the interests of scaling corrections for supernodal and
multifrontal direct solvers and for preconditioned iterative
methods on industrial applications based on Maxwell
equations (coupled problems, nonlinear materials, moving
structures, transient problems) and discretized by means of
nodal or edge finite elements.

[1] N.~Linial, A.~Samorodnitsky,
A.~Wigderson, {\em A deterministic strongly polynomial
algorithm for matrix scaling and approximate permanents},
Combinatorica {\bf 20} (200) 531--544.

[2] O.~E.~Livine, G.~H.~Golub,
{\em Scaling by Binormalization}.

[3] D.~Ruiz, {\em A Scaling Algorithm to Equilibrate
Both Rows and Columns Norms in Matrices}, RAL-TR-2001-034.



	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\begin{center} \rule{6in}{1pt} \end{center}
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{center}
{\large			% \hypertarget{Douglas}
{\bf Actually doing dynamic data-driven application simulations (in 4 parts)}}

	Craig C.~Douglas \\
	Computer Science Department, 773 Anderson Hall \\
	University of Kentucky, Lexington KY 40506-0046 \\
	and Computer Science Department, P.O.~Box 208285 \\
	Yale University,  New Haven CT 06520-8285 \\
	{\tt douglas-craig@cs.yale.edu}

	Chris R.~Johnson and Steven G.~Parker, University of Utah \\
	Janice Coen, National Center for Atmospheric Research \\
			% \hspace*{9mm}\hfill
	Jan Mandel and Jonathan Beezley, Univ.~of Colorado at Denver
			% \hfill \hyperlink{index}{\small {\em index}} \\
\end{center}
This is a four part talk to introduce DDDAS concepts before
the Wednesday night workshop.

{\bf Part I:} Introduction to DDDAS and Its Impact on High
Performance Computing Environments \\
Craig Douglas

DDDAS is a paradigm whereby an application (or simulation)
and measurements become a symbiotic feedback control system.
DDDAS entails the ability to dynamically incorporate
additional data into an executing application, and in
reverse, the ability of an application to dynamically steer
the measurement process.  Such capabilities promise more
accurate analysis and prediction, more precise controls, an
d more reliable outcomes.  The ability of an application to
control and guide the measurement process and determine
when, where, and how it is best to gather additional data
has itself the potential of enabling more effective
measurement methodologies.  Furthermore, the incorporation
of dynamic inputs into an executing application invokes new
system modalities and helps create application software
systems that can more accurately describe real world,
complex systems.  This enables the development of
applications that intelligently adapt to evolving conditions
and that infer new knowledge in ways that are not
predetermined by the initialization parameters and initial
static data.

DDDAS creates a rich set of new challenges for applications,
algorithms, systems software, and measurement methods.
DDDAS research typically requires strong, systematic
collaborations between applications domain researchers and
mathematics, statistics, and computer sciences researchers,
as well as researchers involved in the design and
implementation of measurement methods and instruments.
Consequently, most DDDAS projects involve multidisciplinary
teams of researchers.

In addition, DDDAS enabled applications run in a different
manner than many traditional applications.  They place
different strains on high performance systems and centers.
In this talk, we will also categorize some of these
differences.

{\bf Part 2:} Problem Solving Environments for DDDAS
\\
Chris R.~Johnson and Steven G.~Parker

One of the significant challenges for DDDAS is to create
software infrastructure and tools that help DDDAS
researchers tackle the multidisciplinary, often large-scale,
dynamically coupled problems described in the previous
presentation.

DDDAS problems often require using multiple software
frameworks and packages, which leads to the significant
software architecture challenge of integrating and providing
interoperability of different software frameworks, packages,
and libraries.  Our approach to this challenge is  to create
software ``bridges'' using a meta-component model that allows
the user to easily connect one software framework or package
to another.

The new system (currently called SCIRun2, but that will
change very soon) support the entire life cycle of
scientific applications by allowing scientific programmers
to quickly and easily develop new techniques, debug new
implementations, and apply known algorithms to solve novel
problems.  SCIRun2 also contain many powerful visualization
algorithms for scalar,  vector, and tensor field
visualization, as well as image processing tools.

In this presentation, we will provide examples of DDDAS
software integration.

{\bf Part 3:} The Impact of DDDAS on Wildland Fire Modeling and
Fire Front Tracking
\\
Janice Coen and Jan Mandel

In this talk, we will describe an application to which DDDAS
concepts are being applied.  Wildland fire modeling involves
a numerical weather prediction model that is two-way coupled
to a fire behavior model, so that the fire can create its
own weather.  This is an extremely challenging computational
problem with limited predictability because of the
uncertainty in fire behavior in addition to uncertainties in
weather modeling.  It is also difficult to obtain
observations near a wildfire.  Thus, DDDAS concepts have
great potential in advancing this area.  In this work, we
will describe techniques we have been applying to introduce
DDDAS concepts into what was a traditional modeling
approach.  We define a novel partial differential equation
based model for wildland fires instead of the usual
stochastic based model.  We will show where a DDDAS approach
can provide a breakthrough in fire front tracking that can
be transmitted to the people on the mountainsides through
both computational science and high tech advances.

{\bf Part 4:} Out of Time Order Kalman Filtering for DDDAS Data
Assimilation
\\
Jan Mandel and Jonathan Beezley

We present the basic principles of data assimilation by
ensemble filtering.  These methods run a collection of
randomly perturbed simulations, called an ensemble.  From
time to time, the ensemble is modified by creating linear
combinations found by solving a least squares problem to
match the data.  We describe new developments needed to
accommodate strongly nonlinear wildfire models and sparse
data.  The new methods include Tikhonov-like regularization
in a Bayesian probabilistic framework and new hybrid
deterministic/stochastic ensemble methods for non-Gaussian
distributions, based on the theory of probability measures
on Sobolev spaces.  We also discuss a space-time ensemble
approach to assimilate data arriving out of order.

{\bf Wednesday night, April 5},
Workshop on Dynamic Data Driven Liquid Flows
\\ Douglas, Johnson, Coen, Mandel

This workshop will be strictly hands on.  It will introduce
DDDAS techniques (see http://www.dddas.org) including
dynamic modeling, errors, sensor operation, and the
symbiotic relations between the sensors and the application.

We will simulate the level of a liquid in media that is
porous in one boundary edge only and design from scratch an
algorithm to maintain it at a fixed level on average even
though the liquid is disappearing through the open boundary
using a random step function.

We will develop convergence results initially using a
semi-direct method, but some of the participants may end up
with a random walk by the end of the workshop.  We will
iterate on the liquid problem until we develop a fast
iterative (and convergent) algorithm that we have thoroughly
tested.  We will use the data from experiments to drive the
entire methodology and the algorithms will drive how and
when data is collected.

This workshop will be held in one of the local watering
holes, not in the conference center.  Sensor oversight and
correction will be provided at the tables.



	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\begin{center} \rule{6in}{1pt} \end{center}
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{center}
{\large			% \hypertarget{Draganescu}
{\bf An abstract method for extending two-level preconditioners \\
to multilevel preconditioners of comparable quality}}

	Andrei Dr{\u a}g{\u a}nescu \\
	Sandia National Laboratories,
	Optimization/Uncertainty Estimation Department \\
	P.O. Box 5800, MS. 1110, Albuquerque NM 87185-1110 \\
			% \hspace*{9mm}\hfill
	{\tt aidraga@sandia.gov}
			% \hfill \hyperlink{index}{\small {\em index}} \\
\end{center}
We present an abstract method for designing a multilevel
preconditioner given a two-level preconditioner for an
operator with positive definite symmetric part.

If we denote by $A_{\mathrm{fine}}$ and
$A_{\mathrm{coarse}}$ two discrete versions of a continuous
operator, then a two-level preconditioner
$T_{\mathrm{fine}}$ for $A_{\mathrm{fine}}$ can be
described in general by a function
$T_{\mathrm{fine}} = {\mathcal F}(A_{\mathrm{coarse}}^{-1}$,
$A_{\mathrm{fine}})$,
where it is assumed that the evaluation of ${\mathcal F}$
requires a level-independent  number of applications of
$A_{\mathrm{fine}}$ and $k$  applications of
$A_{\mathrm{coarse}}^{-1}$  ($k=1$ or $2$).  The natural
extension to a multilevel preconditioner, consisting in
replacing in $T_{\mathrm{fine}}$ the call to
$A_{\mathrm{coarse}}^{-1}$ with a recursive call to
${\mathcal F}$, is known to sometimes produce multilevel
preconditioners of lower quality (e.g., for certain types
of inverse problems).  Based on the idea that inverting
$A_{\mathrm{fine}}$ essentially means to solve the
nonlinear  equation \mbox{$X^{-1} - A_{\mathrm{fine}}= 0$},
we define our multigrid preconditioner to be the first
Newton iterate of the map $X\mapsto X^{-1} -
A_{\mathrm{fine}}$ starting at the ``natural'' multilevel
preconditioner.  For $k=1$, the resulting algorithm has a
W-cycle structure, and differs only slightly from the
textbook version of the W-cycle.  Moreover, the method
guarantees that the resulting preconditioner maintains the
approximation quality of the initial two-level
preconditioner.  The quality of approximation is measured
using a certain distance function, which determines the
degree to which two operators with positive definite
symmetric parts are spectrally equivalent.  We apply this
method to designing and analyzing a multigrid
preconditioner for a linear advection-diffusion-reaction
equation.

{\small Sandia is a multiprogram laboratory operated by
Sandia Corporation, a Lockheed-Martin Company, for the
United States Department of Energy under
Contract DE-AC04-94AL85000.}



	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\begin{center} \rule{6in}{1pt} \end{center}
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{center}
{\large			% \hypertarget{Du}
{\bf On the convergence of additive Schwarz preconditioned GMRES}}

	Xiuhong Du \\
	Dept.~of Mathematics College of Science and Technology \\
	Temple University, Philadelphia PA 19122 \\
	{\tt dxhdxh@temple.edu} \\
			% \hspace*{9mm}\hfill
	Daniel B.~Szyld
			% \hfill \hyperlink{index}{\small {\em index}} \\
\end{center}
Additive Schwarz preconditioners, when a coarse grid
correction is added, are said to be optimal for certain
discretized PDE problems, in the sense that bounds on the
convergence of iterative methods are independent on the mesh
size. Cai and Zou [1]
showed with an
example that in the absence of a coarse grid correction the
usual GMRES bound has a factor of the order of $1/\sqrt h$.
In this paper we consider the same one-dimensional example
(as well as a two-dimensional counterpart) and show that the
behavior of the method is not well represented by the above
mentioned bound. We use a different bound for GMRES from
Simoncini and Szyld [2]
and show that the relevant factor is
bounded by $c-O(h)$, so that as $h\rightarrow 0$, it
approximates a constant. Furthermore, for a sequence of
meshes the convergence curves are almost identical and the
number of GMRES iterations needed for convergence has a very
slow growth.

[1] Numer. Linear Algebra Appl. {\bf 9} (2002) 379--397.

[2] SIAM Rev. {\bf 47} (2005) 247--272.


	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\begin{center} \rule{6in}{1pt} \end{center}
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{center}
{\large			% \hypertarget{Duff}
{\bf A note on GMRES preconditioned by a perturbed \\
$LDL^T$ decomposition with static pivoting}}

	Iain S Duff \\
	Rutherford Appleton Laboratory, Chilton, Didcot \\
	Oxfordshire, OX11 0QX, UK \\
	{\tt i.s.duff@rl.ac.uk} \\
			% \hspace*{9mm}\hfill
	Mario Arioli, Serge Gratton, Pralet, St\'ephane
			% \hfill \hyperlink{index}{\small {\em index}} \\
\end{center}
This paper is concerned with solving the set of linear
equations $A x = b$ (1)
where the coefficient matrix $A$ is a
symmetric indefinite sparse matrix. Our hope is to solve
this system using a direct method that uses an accurate
factorization of $A$ but sometimes the cost of doing this is
too high in terms of time or memory. We have therefore
looked at the possibility of using static pivoting to avoid
these problems which are particularly acute if the matrix is
highly indefinite as for example can happen for saddle-point
problems.

As our direct method we will use a multifrontal
approach. In this approach we first determine an order for
choosing pivots based on the sparsity structure of $A$
(called the analysis step), and we then accommodate further
pivoting for numerical stability during the subsequent
numerical factorization phase. The problem when the matrix
is highly indefinite is that the resulting pivot sequence
used in the numerical factorization can differ substantially
from that predicted by the analysis step. In the
multifrontal context, the factorization can be represented
by a tree at each node of which elimination operations are
performed on a partially summed frontal matrix
$\TwoMatrx{F_{11}}{F_{12}}{F_{12}^T}{F_{22}}$ (2)
and pivots at that stage can only
be chosen from within the fully summed block $F_{11}$. The
problem occurs when it is impossible or numerically suicidal
to eliminate all of $F_{11}$ resulting in more work and
storage (sometimes dramatically more) than forecast. A
simple way to avoid this problem is to force the elimination
of all of $F_{11}$ through static pivoting.

We thus
assume that the matrix $A$ has been factorized using the HSL
package {\tt MA57} with the option of using static pivoting
[1]. The static pivoting strategy will set the
diagonal entry to $\pm\tau$ when it is impossible to find a
suitable pivot in the fully summed blocks. It is common to
choose $\tau \approx \sqrt{{{\bf \varepsilon }\,}} ||A||$
(${{\bf \varepsilon }\,}$ machine precision).

Therefore, the computed factors $\hat{L}$ and
$\hat{D}$ are, in exact arithmetic, the exact factorization
of the perturbed problem
$A + E = \hat{L} \hat{D} \hat{L}^T$ (3),
where the matrix
$|E| \le \tau I$ is a diagonal matrix of rank equal to the
number of static pivots used during the factorization. The
nonzero diagonal entries in $E$ correspond to the positions
at which static pivoting was performed and they are all
equal to $\tau$ in modulus. Note that if $\tau$ is chosen
too small then the factorization could be very unstable
whereas if it is chosen too large, the factorization will be
stable but will not be an accurate factorization of the
original matrix (that is, $|E|$ will be large).

Equation (3)
gives a splitting of $A$ in terms of
$M = \hat{L} \hat{D} \hat{L}^T$ and $E$,
$A = M - E$,
and the solution of (1) can be expressed as the
solution of the equivalent system
$(I - M^{-1} E) x = M^{-1}b$ (4).
If the spectral radius of the matrix
$I - M^{-1} E $
is less than one, the system (4) can be
solved using iterative refinement. This has been used by
many authors, including [1] and is successful
over a wide range of matrices although is somewhat sensitive
to the value of $\tau$. If, however, the spectral radius is
greater or equal to one (or $\approx 1$), it is necessary to
switch to a more powerful method like GMRES. Although the
matrix is symmetric, we choose GMRES since it gives us much
more freedom to work with a wide range of preprocessors and
preconditionings.

We have found experimentally that using
the factorization (3) as a preconditioning for
GMRES works in most cases and is, as expected much more
robust than iterative refinement. Indeed GMRES gives
normwise backward stability in most cases, which is not the
case for iterative refinement. However, there are cases
where we do not get convergence to a scaled residual at
machine precision.

We have, however, found that restarted
GMRES performs better and that using FGMRES, even though our
preconditioner remains constant, does even better.

We
illustrate this through numerical experiment and then show
theoretically that, under reasonable assumptions, FGMRES
preconditioned by our static pivoting factorization is
backward stable so that a small scaled residual can be
achieved. Our analysis also holds for the case of restarted
FGMRES that we advocate as a measure to control the memory
requirement while still achieving the desired accuracy.
Indeed we give theoretical arguments why the restarting
often greatly improves the convergence.


[1] I.~S.~Duff and S.~Pralet, {\em Towards a stable static
pivoting strategy for the sequential and parallel solution
of sparse symmetric indefinite systems},
{T}echnical {R}eport TR/PA/05/26, CERFACS,
Toulouse, France, 2005. (Also available as RAL Report
RAL-TR-2005-007 and IRIT Report RT/TLSE/05/04.)



	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\begin{center} \rule{6in}{1pt} \end{center}
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{center}
{\large			% \hypertarget{Dunlavy}
{\bf Global optimization: for some problems, there's HOPE}}

	Daniel Dunlavy \\
	Sandia National Laboratories \\
	P.O.~Box 5800 M/S 1110, Albuquerque NM 87185-1110 \\
	{\tt dmdunla@sandia.gov} \\
			% \hspace*{9mm}\hfill
	Dianne O'Leary
			% \hfill \hyperlink{index}{\small {\em index}} \\
\end{center}
We present a new method for solving unconstrained
minimization problems---Homotopy Optimization with
Perturbations and Ensembles (HOPE). HOPE is a homotopy
optimization method that finds a sequence of minimizers of a
homotopy function mapping a template function to the target
function, the objective function of our minimization
problem. To increase the likelihood of finding a global
minimizer, points in the sequence are perturbed and used as
starting points to find other minimizers. Points in the
resulting ensemble of minimizers are used as starting points
to find minimizers of the homotopy function as it deforms
the template function into the target function.

We show
that certain choices of the parameters used in HOPE lead to
instances of existing methods: probability-one homotopy
methods, stochastic search methods, and simulated annealing.
We use these relations and further analysis to demonstrate
the convergence properties of HOPE.

The development of
HOPE was motivated by the protein folding problem, the
problem of predicting the structure of a protein as it
exists in nature, given its amino acid sequence. However, we
demonstrate that HOPE is also successful as a general
purpose minimization method for nonconvex functions.


Numerical experiments performed to test HOPE include solving
several standard test problems and the protein folding
problem using two different protein models. In most of these
experiments, standard homotopy functions are used in HOPE.
Additionally, several new homotopy functions are introduced
for solving the protein folding problems to demonstrate how
HOPE can be used to exploit the properties or structure of
particular problems.

Results of experiments demonstrate
that HOPE outperforms several methods often used for solving
unconstrained minimization problems---a quasi-Newton method
with BFGS Hessian update, a globally convergent variant of
Newton's method, and ensemble-based simulated annealing.



	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\begin{center} \rule{6in}{1pt} \end{center}
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{center}
{\large			% \hypertarget{Duraiswami}
{\bf Iterative methods for use with the fast multipole method}}

	Ramani Duraiswami \\
	Computer Science and UMIACS, Room 3365 A.V.~Williams \\
	Building 115, University of Maryland, College Park MD 20742 \\
	{\tt ramani@umiacs.umd.edu} \\
			% \hspace*{9mm}\hfill
	Nail A.~Gumerov
			% \hfill \hyperlink{index}{\small {\em index}} \\
\end{center}
For many dense linear systems of size $N\times N$ the
availability of an algorithm based on the fast multipole
method (FMM) provides a matrix vector product with
$O(N \log N)$
time and memory complexity. This reduces the cost of the
matrix-vector product step in the iterative solution of
linear systems, and for an iteration requiring $N_{iter}$
steps, a complexity of of $O(N_{iter}NlogN)$ can be
expected. To bound $N_{iter}$ appropriate pre-conditioning
strategies must be used. However, many conventional
pre-conditioning strategies rely on sparsity in the matrix,
and applying them to these dense matrices requires
computations that have a formal time or memory complexity of
$O(N^2)$, which negates the advantage of the FMM.

We
explore the application of two preconditioning strategies to
the FMM. In the first, which was applied to the FMM solution
of a multiple scattering problem for the Helmholtz equation
in three dimensions, the system was solved using the
flexible GMRES algorithm. The choice of the (right)
preconditioning matrix was based on GMRES solution of a
linear system with an approximation to the matrix that is
based on a partitioning that is performed in the FMM itself.
We describe details of this iterative technique and its
performance on some large multiple scattering problems.


In the second iterative solution, we consider an iterative
algorithm of Faul et al. [1] for the solution of the
radial basis function (RBF) interpolation problem. In this
problem the goal is to construct an interpolating function
for a set of scattered data points, with the interpolating
function expressed as a sum of RBFs centered at the data
points. The iterative algorithm of Faul et al. can be
accelerated by the use of the FMM for the matrix vector
product required at each step. There however is a
precomputation stage that requires the construction of
approximate cardinal function interpolants centered at each
data point and $q$ of its neighbors $(q\ll N)$, that are
carefully selected. These interpolants are used to provide a
Krylov basis for the iteration. The complexity of these
preliminary calculations in Faul et al. is $O(N^2)$.
We provide a modification to this set-up stage and reduce
its complexity to linear order. Results will be presented
for the interpolation of large data sets in two and three
dimensions using multiquadric and polyharmonic radial basis
functions.

[1] A.~C.~Faul, G.~Goodsell, M.~J.~D.~Powell,
{\em A Krylov subspace algorithm for multiquadric interpolation
in many dimensions}, IMA Journal of Numerical Analysis
{\bf 25} (2005) 1--24.



	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\begin{center} \rule{6in}{1pt} \end{center}
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{center}
{\large			% \hypertarget{Dyadechko}
{\bf Moment-of-fluid interface reconstruction}}

	Vadim Dyadechko \\
	MS B284 Los Alamos National Laboratory \\
	Los Alamos, NM 87545 \\
	{\tt vdyadechko@lanl.gov} \\
			% \hspace*{9mm}\hfill
	Mikhail Shashkov
			% \hfill \hyperlink{index}{\small {\em index}} \\
\end{center}
Volume-of-fluid~(VoF) methods [2] are widely used in
Eulerian simulations of multi-phase flows with mutable
interface topology. The popularity of VoF methods is
explained by their unique ability to preserves the mass of
each fluid component on the discrete level. The strategy of
VoF methods consists in calculating the interface location
at each discrete moment of time from the volumes of the cell
fractions occupied by different materials. Most VoF methods
use a single linear interface to divide two materials in a
mixed cell ~(Piecewise-Linear Interface Calculation~(PLIC))
[3,4,5]. Once the direction of the interface normal is know,
the location of the interface is uniquely identified by the
volumes of the cells fraction. Unfortunately the interface
normal can not be evaluated without the volume fraction data
from the surrounding cells, which prohibits the resulting
approximation to resolve any interface details smaller than
a characteristic size of the cell cluster involved in
evaluation of the normal.

To overcome this limitation, we
designed a new \emph{mass-conservative} interface
reconstruction method [1], which calculates the interface
based on both \emph{volumes and centroids} of the cell
fractions. This choice of the input data allows to evaluate
the interface normal in a mixed cell \emph{even without the
information from the adjacent elements}. The location of the
linear interface in each mixed cell is determined by
\emph{fitting the centroid of the cell fraction behind the
interface to the reference one}, which leads to
($d\!-\!1$)-variate optimization problem in $\Reals^d$. The
technique proposed, called Moment-of-Fluid~(MoF) interface
reconstruction, results in a \emph{second order accurate}
interface approximation~ (linear interfaces are
reconstructed exactly), has higher resolution, and is shown
to be \emph{more accurate than VoF-PLIC methods}.

We
present a detailed description of MoF interface
reconstruction algorithm in 2D, which includes iterative
procedure for centroid fitting and a new algorithm for
cutting appropriate volume fractions from polygonal cells.


[1] V.~Dyadechko and M.~Shashkov, {\em
Moment-of-fluid interface reconstruction},
Technical Report LA-UR-05-7571, Los Alamos
National Laboratory, Los Alamos, NM, Oct 2005.
{\tt http://math.lanl.gov/~vdyadechko/doc/2005-mof.pdf}

[2] C.~W.~Hirt and B.~D.~Nichols, {\em Volume of
fluid (VOF) method for the dynamics of free boundaries},
J.~Comp. Physics {\bf 39}(1) (1981) 201--25.

[3] J.~E.~Pilliod and E.~G.~Puckett, {\em Second-order
accurate volume-of-fluid algorithms for tracking
material interfaces}, J.~Comp. Physics {\bf 199}(2)
(2004) 465--502.

[4] B.~Swartz, {\em The second-order sharpening
of blurred smooth borders}, Mathematics of Computation,
{\bf 52}(186) (1989) 675--714

[5] D.~L.~Youngs, {\em An interface tracking method for a
3D Eulerian hydrodynamics code}, Technical Report
AWRE/44/92/35, Atomic Weapon Research Establishment,
Aldermaston, Berkshire, UK, Apr 1987.


	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\begin{center} \rule{6in}{1pt} \end{center}
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% \pdfbookmark[1]{E-G}{e-g}
\begin{center}
{\large			% \hypertarget{Echeverria}
{\bf On the manifold-mapping optimization technique}}

	David Echeverr\'{i}a \\
	Centre for Mathematics and Computer Science (CWI)\\
	Kruislaan 413, NL-1098 SJ Amsterdam, The Netherlands \\
	{\tt d.echeverria@cwi.nl} \\
			% \hspace*{9mm}\hfill
	Pieter W.~Hemker, {\tt p.w.hemker@cwi.nl}
			% \hfill \hyperlink{index}{\small {\em index}} \\
\end{center}
Optimization problems in practice
often need cost-function evaluations that are very expensive
to compute. Examples are, e.g., optimal design problems
based on complex finite element simulations. As a
consequence, many optimizations may require very long
computing times. The space-mapping (SM) technique
[1,2] was developed as an alternative
in these situations.

In SM terminology, the accurate but
expensive-to-evaluate models are called {\it fine} models,
${\mathbf f}:X \subset \Reals^n \to \Reals^m$.
The SM method also
needs a second, simpler and cheaper and computationally
faster model, the {\it coarse} model,
${\mathbf c}:Z \subset \Reals^n \to \Reals^m$,
in order to speed-up the optimization
process. The key element in this technique is a
right-preconditioning for the coarse model, known as the
{\it SM function}
${\mathbf p}:X \to Z$, that aligns the two
model responses.
The function ${\mathbf c}({\mathbf p}({\mathbf x}))$
corrects the coarse model and
can be used as a surrogate for the fine
model in the accurate optimization. In most cases the SM
function is much simpler than the fine model, in the sense
that it is easier to approximate. This fact endows the SM
technique with its well-reported efficiency. However, it
does not always converge to the right solution.


Defect-correct theory [3] helps to see that, in order
to achieve the accurate optimum, the SM function is
generally insufficient and also left-preconditioning is
needed.  In [4] we introduce the mapping
${\mathbf s}:{\mathbf c}(Z) \to {\mathbf f}(X)$
and the associated
manifold-mapping (MM) algorithm. MM employs
${\mathbf s}({\mathbf c}({\bar{{\mathbf p}}}({\mathbf x})))$
as the fine model surrogate. Here, the
function ${\bar{{\mathbf p}}}:X \to Z$
is not the above SM function but an
arbitrary simple bijection, often the identity.
The MM algorithm is as efficient as SM but converges
to the accurate optimal solution [4,5].

In the first part of the presentation the MM algorithm will
be briefly introduced and a proof of convergence will be
given. The use of more than two models (multi-level
approach) and the possibility of having a coarse model with
a different dimension than the fine one
($X \subset \Reals^{n_{\mathbf f}}$
and $Z \subset \Reals^{n_{\mathbf c}}$ with
$n_{\mathbf f} \neq n_{\mathbf c}$)
will be the issues dealt with in the second part of
the talk.

[1]
J.~W.~Bandler, R.~M.~Biernacki,
C.~H.~Chen, P.~A.~Grobelny and R.~H.~Hemmers,
{\em Space
Mapping Technique for Electromagnetic Optimization},
IEEE Trans. on Microwave Theory and Techniques,
{\bf 42}(12) (1994) 2536--2544.

[2]
J.~W.~Bandler, Q.~S.~Cheng, S.~A.~Dakroury, A.~S.~Mohamed,
M.~H.~Bakr, K.~Madsen and J.~S{\o}ndergaard,
{\em Space Mapping: The State of the Art},
IEEE Trans. on
Microwave Theory and Techniques 52({\bf 1}) (2004)
337--361.

[3]
K.~B{\"o}hmer and P.~W.~Hemker and H.~J.~Stetter,
{\em Defect Correction Methods: Theory and
Applications}, The defect correction approach,
Computing Suppl. {\bf 5} 1--32,
K.~B{\"o}hmer and H.~J.~Stetter ed.,
Springer-Verlag, Berlin, Heidelberg, New York, Tokyo, 1984.

[4]
D.~Echeverr\'{\i}a, and P.~W.~Hemker,
{\em Space mapping and defect correction},
Comp. Methods in Appl. Math. {\bf 5}(2) (2005) 107--136.

[5]
D.~Echeverr\'{i}a, D.~Lahaye, L.~Encica,
E.~A.~Lomonova, P.~W.~Hemker and A.~J.~A.~Vandenput,
{\em Manifold-Mapping Optimization Applied to Linear
Actuator Design},
accepted for publication,
IEEE Transactions on Magnetics, 2006.



	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\begin{center} \rule{6in}{1pt} \end{center}
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\newpage

\begin{center}
{\large			% \hypertarget{Elman}
{\bf IFSS: a MATLAB toolbox for modeling incompressible flow}}

	Howard C Elman \\
	Dept.~of Computer Science \\
	University of Maryland, College Park MD 20742 \\
	{\tt elman@cs.umd.edu} \\
			% \hspace*{9mm}\hfill
	Alison Ramage, David J Silvester
			% \hfill \hyperlink{index}{\small {\em index}} \\
\end{center}
We give an overview of the IFISS ({\em Incompressible Flow
Iterative Solution Software}) Package, a graphical MATLAB
package for the interactive numerical study of
incompressible flow problems. It includes algorithms for
discretization by mixed finite element methods and a
posteriori error estimation of the computed solutions. The
package can also be used as a computational laboratory for
experimenting with state-of-the-art preconditioned iterative
solvers for the discrete linear equation systems that arise
in the modeling of incompressible flow. A unique feature of
the package is its comprehensive nature; for each problem
addressed, it enables the study of both discretization and
iterative solution algorithms as well as the interaction
between the two and the resulting effect on overall
efficiency.



	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\begin{center} \rule{6in}{1pt} \end{center}
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{center}
{\large			% \hypertarget{Evans}
{\bf Development of a 2-D model to simulate convection and \\
	phase transition efficiently}}

	Katherine J.~Evans \\
	MS B216, PO Box 1663 \\
	Los Alamos National Laboratory, Los Alamos NM 87545 \\
	{\tt kevans@lanl.gov} \\
			% \hspace*{9mm}\hfill
	D.~A.~Knoll, Michael Pernice
			% \hfill \hyperlink{index}{\small {\em index}} \\
\end{center}
We present a two-dimensional convection phase change model
using the incompressible Navier-Stokes equation set and
enthalpy as the energy conservation variable. Significant
algorithmic challenges are posed for problems of phase
change interfaces within convective flow regimes. The
equation set is solved with the Jacobian-Free Newton-Krylov
(JFNK) nonlinear inexact Newton's method. SIMPLE, a
pressure-correction algorithm, is used as a physics-based
preconditioner. This algorithm is compared to solutions
using SIMPLE as the main solver.

Algorithm performance is
assessed for a benchmark problem, phase change convection
within a square cavity of a solid pure material cooled below
the melting temperature. A time step convergence analysis
demonstrates that the JFNK model with second order
discretization is second order accurate in time. A Gallium
melting simulation is also performed and evaluated; in this
configuration multiple roll cells develop in the melted
region at early times when the aspect ratio is high. The
JFNK-SIMPLE method is shown to be more efficient per time
step and more robust at larger time steps when compared to
SIMPLE as the main solution algorithm. Overall CPU savings
of more than an order of magnitude are realized.

As a
further analysis of JFNK-SIMPLE, multigrid is wrapped around
SIMPLE, so SIMPLE acts as the smoother within a multigrid
preconditioner to JFNK. For phase change conduction,
additional gains in efficiency can be accomplished. When
SIMPLE is incorporated as a preconditioner and smoother
within JFNK, the ability to model more complex and realistic
phase change convection problems with increased robustness
and efficiency is achieved.



	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\begin{center} \rule{6in}{1pt} \end{center}
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\newpage

\begin{center}
{\large			% \hypertarget{Fattebert}
{\bf Iterative solver for density functional theory calculations \\
	on composite meshes by quadratic finite elements}}

	J.-L.~Fattebert \\
	PO Box 808, L-561, Center for Applied Scientific Computing \\
	Lawrence Livermore National Laboratory, Livermore CA 94551 \\
	{\tt fattebert1@llnl.gov} \\
			% \hspace*{9mm}\hfill
	R.~Hornung, A.~Wissink
			% \hfill \hyperlink{index}{\small {\em index}} \\
\end{center}
Density Functional Theory (DFT) is a simplified quantum
model that has proved very successful in real applications.
It introduces an independent particles description of the
electronic structure of molecules or materials which is much
simpler to treat that the original Schr\"{o}dinger equations.
Simulating realistic physical systems by DFT however is
still computationally very demanding. More efficient
numerical algorithms to reduce computer time and enable
larger simulations are always in demand by chemists and
physicists who are studying phenomenon at the molecular
level.

The finite element (FE) method, a very popular
approach to solve partial differential equations, has only
recently started being used for solving the Kohn-Sham
equations of Density Functional Theory for realistic 3D
applications. Traditionally, the pseudo-spectral approach
has been the most popular in the field under the
denomination Plane Waves method. The regular usage of
periodic boundary conditions with simple geometries explains
this preference. However with the increase in computer power
and the growing interest in studying larger and more diverse
systems, more flexible real-space discretizations by finite
difference or finite elements have recently attracted more
interest.

In this work we focus on FE discretizations
with local mesh refinement for the Kohn-Sham equations, and
propose an efficient iterative solver and preconditioner for
this problem. We present a hierarchical quadratic Finite
Elements approach to discretize the equations on structured
non-uniform meshes. A multigrid FAC preconditioner is
proposed to iteratively minimize the energy functional
associated to the Kohn-Sham equations. It is based on an
accelerated steepest descent-based scheme. The method has
been implemented using SAMRAI, a parallel software
infrastructure for general AMR applications. Numerical
results of electronic structure calculations on small atomic
clusters show in particular a mesh-independent convergence
rate for the iterative solver.



	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\begin{center} \rule{6in}{1pt} \end{center}
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{center}
{\large			% \hypertarget{Fischer}
{\bf Structured matrices, multigrid methods, and the Helmholtz equation}}

	Ranier Fischer \\
	Technical University of Munich \\
	Boltzmannstr. 3, 85748 Garching, Germany \\
	{\tt rainer.fischer@mytum.de} \\
			% \hspace*{9mm}\hfill
	Thomas Huckle
			% \hfill \hyperlink{index}{\small {\em index}} \\
\end{center}
We wish to present a different approach to the multigrid
solution of the Helmholtz equation with constant
coefficients. It is primarily based on certain classes of
structured matrices and their strong correspondence to
generating functions. Discretization of the Helmholtz
equation with certain boundary conditions results in
structured linear systems which are associated with
generating functions. Depending on the kind of boundary
conditions, the discretized Helmholtz equation is a linear
system of Toeplitz, tau, circulant, or DCT-III type. By
solving these systems with normal equations, we have the
advantage that the corresponding generating functions are
nonnegative, although they have a whole curve of zeros.


The multigrid methods we develop are especially designed for
structured matrix classes, making heavy use of the
associated generating functions. Over the last ten years, a
specific theory of multigrid methods has been developed for
structured matrices whose generating functions have isolated
zeros. It is based on the AMG approach and the convergence
theory of Ruge and St\"uben. In this work, we extend some of
these theoretical results to the case of generating
functions with whole zero curves, and apply these modified
multigrid methods to the solution of the Helmholtz equation.
We propose two different strategies how this can be done.
\begin{itemize}
\item The first strategy is based on the
idea of representing the whole zero curve on all grids. For
a multigrid method based on the Galerkin approach, we can
prove optimal two-grid convergence, but such a method is
computationally too expensive. Therefore we propose a
rediscretization technique where the zero curve is
approximated on each grid. This results in fast convergence
and in coarse grid matrices with the same banded structure
as the given matrix. The only disadvantage of this approach
is that zero curves become larger on coarser levels, and
therefore the number of grids is limited.
\item The second
strategy consists of splitting the original problem into a
fixed number of coarse grid problems. Corresponding to a
generating function with isolated zeros, each of these
problems locally represents one part of the zero curve. Each
coarse grid problem is solved with a standard multigrid
method. We combine this splitting technique with the first
strategy to construct a faster and more robust multigrid
solver.
\end{itemize}
We wish to discuss the use of our
multigrid strategies not only as a solver, but also as a
preconditioner for Krylov subspace methods. Moreover, the
methods can also be applied to anisotropic linear systems
whose generating functions have a whole zero curve.



	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\begin{center} \rule{6in}{1pt} \end{center}
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{center}
{\large			% \hypertarget{Freund}
{\bf A flexible conjugate gradient method and its \\
application in power grid analysis of VLSI circuits}}

	Roland W.~Freund \\
	Dept.~of Mathematics, University of California \\
	Davis One Shields Avenue, Davis CA 95616 \\
			% \hspace*{9mm}\hfill
	{\tt freund@math.ucdavis.edu}
			% \hfill \hyperlink{index}{\small {\em index}} \\
\end{center}
The design and verification of today's very large-scale
integrated (VLSI) circuits involve some extremely
challenging numerical problems. One of the truly large-scale
problems in this area is power grid analysis. Power grids
are modeled as networks with up to 10 millions nodes.
Steady-state analysis of power grids requires the solution
of correspondingly large sparse symmetric positive definite
linear systems. The coefficient matrices of these systems
have the structure of weighted Laplacians on
three-dimensional grids, but with `boundary' conditions
given on a subset of the interior grid points.
Strongly-varying weights and the interior boundary
conditions have the effect that solutions of these linear
systems are often very localized, with components of the
solution being near zero in large parts of the grid.

In this
talk, we present a flexible conjugate gradient method that
is tailored to the solution of the truly large-scale linear
systems arising in VLSI power grid analysis. The algorithm
allows changing preconditioners and sparsification of the
search directions at each iteration. These are the key
features to exploit the local nature of the solutions. We
also discuss the problem of constructing efficient
preconditioners for the linear systems in VLSI power grid
analysis, and we present results of numerical experiments.


	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\begin{center} \rule{6in}{1pt} \end{center}
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{center}
{\large			% \hypertarget{Fritzsche}
{\bf Extensions of certain graph-based algorithms for preconditioning}}

	David Fritzsche \\
	Dept.~of Mathematics, Temple University \\
	Philadelphia PA 19122-6094 \\
	{\tt david.fritzsche@math.temple.edu} \\
			% \hspace*{9mm}\hfill
	Andreas Frommer, Daniel B.~Szyld
			% \hfill \hyperlink{index}{\small {\em index}} \\
\end{center}
The original TPABLO algorithms are a collection of algorithms
which compute a symmetric permutation of a linear system such
that the permuted system has a relatively full block
diagonal with relatively large nonzero entries. This block
diagonal can then be used as a preconditioner.
We propose and analyze three extensions of this approach: we
incorporate a nonsymmetric
permutation to obtain a large diagonal, we use a more general
parametrization for TPABLO, and we
use a block Gauss-Seidel preconditioner which can be implemented
to have the same execution time
as the corresponding block Jacobi preconditioner. Since our
approach allows for efficient use of level 3
BLAS operations, it outperforms direct solvers and rivals
standard ILU preconditioners on many test
problems on a single processor system, while having good
potential for efficient parallelization.


	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\begin{center} \rule{6in}{1pt} \end{center}
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{center}
{\large			% \hypertarget{Furnival}
{\bf Solving the stochastic steady-state diffusion problem using multigrid}}

	Darran Furnival \\
	University of Maryland, A.V.~Williams Bldg. 115 \\
	College Park MD 20742 \\
	{\tt furnival@cs.umd.edu} \\
			% \hspace*{9mm}\hfill
	Howard Elman
			% \hfill \hyperlink{index}{\small {\em index}} \\
\end{center}
We study multigrid for solving the stochastic steady-state
diffusion problem. We operate under the mild assumption that
the diffusion coefficient takes the form of a finite
Karhunen-Lo\'eve expansion. The problem is discretized using
a finite element methodology using the polynomial chaos
method to discretize the stochastic part of the problem. We
apply a multigrid algorithm to the stochastic problem in
which the spatial discretization is varied from grid to grid
while the stochastic discretization is held constant. We
then show, theoretically and experimentally, that the
convergence rate is independent of the spatial
discretization, as in the deterministic case.



	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\begin{center} \rule{6in}{1pt} \end{center}
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{center}
{\large			% \hypertarget{Gallopoulos}
{\bf Can information retrieval aid iterative methods?}}

	Efstratios Gallopoulos \\
	Computer Engineering and Informatics \\
	University of Patras, 26500 Patras, Greece \\
	{\tt stratis@ceid.upatras.gr} \\
			% \hspace*{9mm}\hfill
	Spyros Hatzimihail
			% \hfill \hyperlink{index}{\small {\em index}} \\
\end{center}
Recently, Computational Linear Algebra techniques have
started playing an important role in Information Retrieval
(IR) research. Indeed, the Vector Space Model and its
derivatives, such as Latent Semantic Indexing, are heavily
used and investigated. In this presentation we consider the
problem in ``reverse mode'', namely using IR techniques to
help in linear algebra and iterative methods in particular.
The candidate problem is the solution of large linear
systems with multiple right hand sides. The efficiency of
solvers is known to depend on the amount of information
shared amongst the right hand sides. We specifically
investigate the combination of clustering algorithms and
schemes from the existing literature to solve such problems.

This research is supported in part by a University of
Patras KARATHEODORI grant.



	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\begin{center} \rule{6in}{1pt} \end{center}
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\newpage

\begin{center}
{\large			% \hypertarget{Gray}
{\bf The role of optimization in the validation \& verification, \\
calibration \& validation processes}}

	Genetha Gray \\
	Sandia National Labs, P.O.~Box 969, MS 9159 \\
	Livermore CA 94551-0969 \\
	{\tt gagray@sandia.gov} \\
			% \hspace*{9mm}\hfill
	Monica Martinez-Canales, Chuck Hembree
			% \hfill \hyperlink{index}{\small {\em index}} \\
\end{center}
A comprehensive study of many of the complex systems in
science and engineering may demand physical experimentation.
However, in many cases, physical experiments can be
prohibitively expensive or even impossible to perform.
Fortunately, the behavior of many of these systems can be
imitated by computer models, and thus, computer simulation
may be a viable alternative or augmentation.

 The
inclusion of computer simulations does introduce many new
challenges. For example, code verification should be used to
confirm that the underlying equations are being solved
correctly. Calibration or parameter estimation must be
incorporated to update the computational model in response
to experimental data. In addition, validation is an
important process that can answer questions of correctness
of the equations and models for the physics being modeled
and the application being studied. Moreover, validation
metrics must be carefully chosen in order to explicitly
compare experimental and computational results and quantify
the uncertainties in these comparisons. Overall, the
validation and verification verification, calibration, and
validation processes for computational experimentation can
provide the best estimates of what can happen and the
likelihood of it happening when uncertainties are taken into
account.

 In this talk, we will focus on the validation
calibration under uncertainty process. In particular, we
will focus on the problem of electrical simulations and
elucidate the role of optimization in the parameter
extraction problem. We will describe the process, an example
problem and our results, and how the inclusion of
sensitivity analysis can improve the optimization procedure.



	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\begin{center} \rule{6in}{1pt} \end{center}
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{center}
{\large			% \hypertarget{Greif}
{\bf Preconditioners for the discretized time-harmonic \\
Maxwell equations in mixed form}}

	Chen Greif \\
	University of British Columbia, 2366 Main Mall \\
	Vancouver B.C.  V6T 1Z4 Canada \\
	{\tt greif@cs.ubc.ca} \\
			% \hspace*{9mm}\hfill
	Dominik Sch\"otzau
			% \hfill \hyperlink{index}{\small {\em index}} \\
\end{center}
We introduce a new preconditioning technique for iteratively
solving linear systems arising from finite element
discretizations of the mixed formulation of the
time-harmonic Maxwell equations. The preconditioners are
block diagonal with positive definite blocks and are based
on discrete augmentation using the scalar Laplacian. They
are motivated by spectral equivalence properties of the
discrete operators. Specifically, we show that augmenting
the curl-curl operator by a discrete grad-div operator,
weighed by the scalar Laplacian, yields almost immediate
convergence when preconditioned MINRES is used. We also show
that if the augmented term is replaced by the vector mass
matrix we still obtain fast convergence. Similar
(operator-independent) algebraic principles can be applied
in general settings and give rise to preconditioners that
work effectively for saddle-point linear systems whose (1,1)
block is highly singular. Analytical observations and
numerical results demonstrate the scalability and the
convergence properties of the proposed approach.



	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\begin{center} \rule{6in}{1pt} \end{center}
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{center}
{\large			% \hypertarget{Griffin}
{\bf An asynchronous parallel derivative-free algorithm for \\
	handling general constraints}}

	Josh D Griffin \\
	P.O.~Box 969 MS 9159,  Livermore CA 94551 \\
	{\tt jgriffi@sandia.gov} \\
			% \hspace*{9mm}\hfill
	Tamara G Kolda
			% \hfill \hyperlink{index}{\small {\em index}} \\
\end{center}
We will discuss an asynchronous parallel implementation of a
derivative-free augmented Lagrangian algorithm for handling
general nonlinear constraints recently proposed by Kolda,
Lewis, and Torczon. The method solves a series of linearly
constrained subproblems, seeking to approximately minimize
the augmented Lagrangian which involves the nonlinear
constraints. Each subproblem is solved using a generating
set search algorithm capable of handling degenerate linear
constraints. We use APPSPACK to solve the
linearly-constrained subproblems, enabling the objective and
nonlinear constraint functions to be computed asynchronously
in parallel. A description and theoretical analysis of the
algorithm will be given followed by numerical results.



	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\begin{center} \rule{6in}{1pt} \end{center}
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{center}
{\large			% \hypertarget{Gryazin}
{\bf Cascadic multigrid algorithms for the solution of Helmholtz equations}}

	Yuriy Gryazin \\
	Dept.~of Mathematics, Campus Box 8085 \\
	Idaho State University, Pocatello ID 83209 \\
	{\tt gryazin@isu.edu} \\
			% \hspace*{9mm}\hfill
	Evgueni Gordienko
			% \hfill \hyperlink{index}{\small {\em index}} \\
\end{center}
In most scenarios, traditional multigrid methods fail to
converge in the case of the Helmholtz equation with
relatively large wave numbers. One approach for tackling
this problem is to use a Krylov type algorithm both as a
smoother and as an outer iteration method in the multigrid
cycles. In this presentation, we extend this methodology to
the iteration methods based on the cascadic principle. Such
algorithms are usually referred to as one-way multigrid
methods. We consider an adaptive control strategy for the
number of iterations on successive refinement levels and
present numerical results that illustrate the efficiency of
the proposed approach.



	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\begin{center} \rule{6in}{1pt} \end{center}
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{center}
{\large			% \hypertarget{Gugercin}
{\bf Inexact solves in Krylov-based model reduction of large-scale systems}}

	Serkan Gugercin \\
	Dept.~of Mathematics, Virginia Tech. \\
	460 McBryde Hall, Blacksburg VA 24061-0123 \\
			% \hspace*{9mm}\hfill
	{\tt gugercin@math.vt.edu}
			% \hfill \hyperlink{index}{\small {\em index}} \\
\end{center}
Dynamical systems are the basic framework for modeling and
control of an enormous variety of complex systems. Direct
numerical simulation of the associated models has been one
of the few available means when goals include accurate
prediction or control of complex physical phenomena.
However, the ever increasing need for improved accuracy
requires the inclusion of ever more detail in the modeling
stage, leading inevitably to ever larger-scale, ever more
complex dynamical systems.

Simulations in such
large-scale settings can be overwhelming and make
unmanageably large demands on computational resources, which
is the main motivation for model reduction. The goal of
model reduction is to produce a much lower dimensional
system having the same input/output characteristics as the
original. Recently, Krylov-based methods have emerged as
promising candidates for reduction of large-scale dynamical
systems.

The main cost in Krylov-based model reduction
is due to solving a set of linear systems of the form
$(s_o \mathbf{I}_n - \mathbf{A}) \mathbf{v} = \mathbf{b}$
where
$\mathbf{A}$ is an ${n \times n}$ matrix, $\mathbf{b}$ is an
$n$-dimensional vector, $s_0$ is a complex number called the
{\it interpolation point} and $\mathbf{I}_n$ is the identity
matrix of size $n$. Since the need for more detail and
accuracy in the modeling stage causes the system dimension,
$n$, to reach levels on the order of millions, direct
solvers for the linear system
$(s_o \mathbf{I}_n - \mathbf{A}) \mathbf{v} = \mathbf{b}$
are no longer feasible;
hence inexact solves need to be employed in Krylov-based
model reduction.

In this talk, we investigate the use of
inexact solves in a Krylov-based model reduction setting and
present the resulting perturbation effects on the underlying
model reduction problem. We show that for a \emph{good}
selection of interpolation points, Krylov-based model
reduction is robust with respect to the perturbations due to
inexact solves. On the other hand, when the interpolation
points are \emph{poorly} selected, these perturbations are
magnified through the model reduction process. We also
examine stopping criteria, effective preconditioning, and
restarting techniques in the particular context of model
reduction. Finally, we incorporate inexact solves for the
Krylov-based optimal ${\cal H}_2$ approximation. The result
is an effective optimal model reduction algorithm applicable
in realistic large-scale settings.



	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\begin{center} \rule{6in}{1pt} \end{center}
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{center}
{\large			% \hypertarget{Gutknecht}
{\bf The block grade of a block Krylov space}}

	Martin H.~Gutknecht \\
	Seminar for Applied Mathematics, ETH Zurich \\
	8092 Zurich, Switzerland \\
	{\tt mhg@math.ethz.ch} \\
			% \hspace*{9mm}\hfill
	Thomas Schmelzer
			% \hfill \hyperlink{index}{\small {\em index}} \\
\end{center}
The so-called grade of a
vector $b$ with respect to a nonsingular matrix $\bfA$ is
the dimension of the (largest) Krylov (sub)space generated
by $\bfA$ from $b$. It determines in particular, how many
iterations a Krylov space method with linearly independent
residuals requires for finding in exact arithmetic the
solution of $\bfA x=b$ (if the initial approximation $x_0$
is the zero vector). In this talk we generalize the grade
notion to block Krylov spaces and show that this and other
fundamental properties carry over to block Krylov space
methods for solving linear systems with multiple right-hand
sides.

We consider $s$ linear systems with the same
nonsingular coefficient matrix $\bfA$, but different
right-hand sides $b^{(i)}$, which we gather in a
\textit{block vector}
$\bfb := (b^{(1)},\dots,b^{(s)})$.
The $s$ systems are then written as
$$
\bfA \bfx = \bfb \qquad
\text{with} \quad \bfA \in \Cplex^{N\times N}\,,
\quad \bfb \in
\Cplex^{N\times s}\,,\quad
\bfx \in \Cplex^{N\times s}\,.
$$
Standard block Krylov space methods
construct in the $n$th iteration approximate solutions
gathered in a block vector $\bfx_n$ chosen such that
$$
\bfx_n - \bfx_0 \in \calBB_n
(\bfA, \bfr_0) \,,
$$
where $\bfx_0$
contains the $s$ initial approximations and $\bfr_0$ the
corresponding initial residuals, while
$\calBB_n$ is the
Cartesian product
$$
\calBB_n = \underbrace{\calB_n
\times \cdots \times
\calB_n}_{s\text{ times}}
$$
with
$$
\calB_n = \calK_n (\bfA,
r_0^{(1)}) + \cdots + \calK_n
(\bfA, r_0^{(s)}) \,.
$$
Here, $\calK_n (\bfA, r_0^{(i)})$
is the
usual $n$th Krylov (sub)space of the $i$th system. It is
important, that, in general, the sum in the last formula is
not a direct sum, that is, the Krylov spaces may have
nontrivial intersections.

The \textit{block grade of\/
$\bfr_0$ with respect to\/ $\bfA$} or, the
\textit{block grade of\/ $\bfA$
with respect to\/ $\bfr_0$}
is the positive integer
$\bar\nu := \bar\nu(\bfr_0,\bfA)$
defined by
$$
\bar\nu(\bfr_0,\bfA) = \min \left\{n \big\vert
\Dim
\calB_n(\bfA, \bfr_0) =
\Dim
\calB_{n+1}(\bfA, \bfr_0)
\right\}\,.
$$

Among the results we have
established for the block grade are the following ones.


{\sc Lemma 1} ~
For $n \geq \bar\nu(\bfr_0,\bfA)$,
$$
\calB_n(\bfA, \bfr_0) =
\calB_{n+1}(\bfA, \bfr_0)\,,\qquad
\calBB_n(\bfA, \bfr_0) =
\calBB_{n+1}(\bfA, \bfr_0)\,.
$$


{\sc Lemma 2} ~
The block grade of the
block Krylov space and the grades of the individual Krylov
spaces contained in it are related by
$$
\calB_{\bar\nu(\bfr_0,\bfA)}(\bfA, \bfr_0) =
\calK_{\bar\nu(r_0^{(1)},\bfA)}(\bfA, r_0^{(1)})
+ \dots +
\calK_{\bar\nu(r_0^{(s)},\bfA)}(\bfA, r_0^{(s)})\,.
$$

{\sc Lemma 3} ~
The block grade $\bar\nu(\bfr_0,\bfA)$ is characterized by
$$
\bar\nu(\bfr_0,\bfA)
= \min\left\{ n \big\vert \bfA^{-1} \bfr_0 \in
\calBB_n(\bfA, \bfr_0) \right\}.
$$


{\sc Theorem} ~
Let $\bfxex$ be the block
solution of $\bfA\bfx = \bfb$ and let $\bfx_0$ be any
initial block approximation of it and
$\bfr_0 := \bfb - \bfA \bfx_0$
the corresponding block residual. Then
$$
\bfxex \in \bfx_0 +
\calBB_{\bar\nu(\bfr_0,\bfA)}(\bfA,\bfr_0)
\,.
$$

We also discuss the effects of
the size of the block grade on the efficiency of a block
Krylov space method.



	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\begin{center} \rule{6in}{1pt} \end{center}
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% \pdfbookmark[1]{H}{h}
\begin{center}
{\large			% \hypertarget{Haber}
{\bf An octree multigrid method for quasi-static Maxwell's equations \\
	with highly discontinuous coefficients}}

	Eldad Haber \\
	Mathematics and Computer Science \\
	Emory University \\
	{\tt haber@mathcs.emory.edu}
			% \hspace*{9mm}\hfill
	\\ Stefan Heldmann
			% \hfill \hyperlink{index}{\small {\em index}} \\
\end{center}
In this work we develop an octree discretization for
Maxwells equations in the quasi-static regime.  We then use
this discretization in order to develop a multigrid method
for Maxwells equations with highly discontinuous
coefficients.  We show that our approach can be interpreted
as a semi-algebraic multigrid method with physical base for
coarse grid selection.  We test our algorithms and compare
it to other multilevel algorithms.


	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\begin{center} \rule{6in}{1pt} \end{center}
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{center}
{\large			% \hypertarget{Hanson}
{\bf Multilevel algorithms for large scale interior point methods \\
	in bound constrained optimization}}

	Lauren Hanson \\
	Emory University, Dept.~of Mathematics and Computer Science \\
	400 Dowman Drive, Atlanta GA 30322 \\
	{\tt lrhanso@mathcs.emory.edu} \\
			% \hspace*{9mm}\hfill
	Michele Benzi, Eldad Haber
			% \hfill \hyperlink{index}{\small {\em index}} \\
\end{center}
We develop and compare multilevel algorithms for solving
bound constrained nonlinear variational problems via
interior point methods. Several equivalent formulations of
the linear systems arising at each iteration of the interior
point method are compared from the point of view of
conditioning and iterative solution. Furthermore, we show
how a multilevel continuation strategy can be used to obtain
good initial guesses (``hot starts'') for each
nonlinear iteration. A minimal surface problem is used to
illustrate the various approaches.


	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\begin{center} \rule{6in}{1pt} \end{center}
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{center}
{\large			% \hypertarget{Heldman}
{\bf Multi-level optimization for image registration using \\
	local refinement on octrees}}

	Stefan Heldman \\
	Dept.~of Mathematics and Computer Science, Emory University \\
	400 Dowman Drive, Atlanta Georgia 30322 \\
	{\tt heldmann@mathcs.emory.edu}
			% \hspace*{9mm}\hfill
	\\ Eldad Haber, Jan Modersitzki
			% \hfill \hyperlink{index}{\small {\em index}} \\
\end{center}
We present a new multi-level approach for non-linear image
registration using local refinement techniques.

Standard multi-level approaches for this problem discretize
the domain starting with a regular coarse grid and refine
every cell from level to level. In our approach, we also
start with a regular coarse grid but its refinement for
higher levels is done locally. Using local refinement is
motivated by the observation that changes in the solution at
higher levels appear mainly locally and large areas stay
unchanged such that there is no need for a finer resolution.
The local refinement in our approach is done by subdividing
cells into four (2D) or eight (3D) resulting quad (2D) and
octree-grids (3D), respectively.

Compared with the standard multi-level approach, our method
requires substantially less memory and arithmetic
operations. Therefore, it is in particular well-suited for
large-scale problems.



	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\begin{center} \rule{6in}{1pt} \end{center}
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{center}
{\large			% \hypertarget{Heroux}
{\bf A multiscale perspective on density functional theory \\
for inhomogeneous fluids}}

	Michael A Heroux \\
	18125 Kreigle Lake Rd,  Avon MN 56310 \\
	{\tt maherou@sandia.gov} \\
			% \hspace*{9mm}\hfill
	Laura J D Frink, Andrew G Salinger
			% \hfill \hyperlink{index}{\small {\em index}} \\
\end{center}
Some modeling and simulations efforts have historically
encompassed multiscale phenomena without explicitly handling
multiscale features. One such area is density functional
theories for inhomogeneous fluids (Fluid-DFTs). In this
presentation we look at Fluid-DFTs from a fresh perspective,
calling out the fact that Fluid-DFTs incorporate multiple
length scales that are introduced in a way such that each
longer scale increases the fidelity of the model. By viewing
Fluid-DFTs from this perspective, we develop a mathematical
framework and a collection of solution algorithms that have
a dramatic impact on the robustness, performance and
scalability of the implicit equations generated by
Fluid-DFTs.

The basic
framework for all of our solver algorithms reflects the
importance of inter-physics coupling in the extended
variable formulation of the
Fluid-DFTs.
This physics coupling led
us to a physics-based block matrix formulation in order to
partition critical and nonlocal ancillary variables. The
idea is to partition the data into blocks that can be
optimally managed or solved. The general $2\times 2$ block
matrix is

$$
\left(
\begin{array}{ccc|ccc} A_{11}^{11} & \cdots & A_{11}^{1j} &
A_{12}^{1,j+1} & \cdots & A_{12}^{1k} \\ \vdots & \ddots &
\vdots & \vdots & \ddots & \vdots \\ A_{11}^{j1} & \cdots &
A_{11}^{jj} & A_{11}^{j1} & \cdots & A_{11}^{jj} \\\hline
A_{21}^{j+1,1} & \cdots & A_{21}^{j+1,j} & A_{22}^{j+1,j+1}
& \cdots & A_{22}^{j+1,k} \\ \vdots & \ddots & \vdots &
\vdots & \ddots & \vdots \\ A_{21}^{k1} & \cdots &
A_{21}^{kj} & A_{22}^{k,j+1} & \cdots & A_{22}^{kk} \\
\end{array} \right) \left( \begin{array}{c} x_1^1 \\ \vdots
\\ x_1^j \\\hline x_2^{j+1} \\ \vdots \\ x_2^k \\
\end{array} \right) = \left( \begin{array}{c} b_1^1 \\
\vdots \\ b_1^j \\\hline b_2^{j+1} \\ \vdots \\ b_2^k \\
\end{array} \right)
$$
where $k$ is the number of DOFs
tracked per node. The superscript $(p, q)$ denotes the block
of coefficients generated by DOF $p$ interactions with DOF
$q$. The subscripts and partition lines impose a coarser
partitioning of the matrix into a $2\times 2$
block system that
will be used with a Schur complement approach. We denote by
$A_{11}$, $A_{12}$, $A_{21}$ and $A_{22}$ the upper left,
upper right, lower left and lower right submatrix of the
coarse $2\times 2$ block matrix, respectively. Similarly $x_1$
and $x_2$, and $b_1$ and $b_2$ are the upper and lower parts
of $x$ and $b$, respectively.

Given this two-level
structure, the basic strategy for solving each global linear
system generated by Newton's method is as follows:
\begin{enumerate}
\item Identify and reorder DOFs $1$
through $j$ such that $A_{11}^{-1}$ (the inverse of
$A_{11}$) is easy to apply (in parallel).
\item Determine a
preconditioner $P$ for $S = A_{22} -
A_{21}A_{11}^{-1}A_{12}$,
the Schur complement of $A$ with
respect to $A_{22}$.
\item Solve $Sx_2 = (b_2 - A_{21}b_1)$
using a preconditioned Krylov method such as GMRES, with
preconditioner $P$. Note that $S$ may or may not be
explicitly formed, depending on other problem details.
\item
Finally, solve for $x_1 = A_{11}^{-1}(b_1 - A_{12}x_2)$.
\end{enumerate}

Given this basic framework, we will describe specific
solvers for special categories of Fluid-DFT problems,
including 2 and 3 dimensional hard-sphere problems and
polymer chains. We give results for several problem areas
including nanopore and lipid bi-layer models where this
Schur complement approach provides one to two orders of
magnitude improvement in performance and an order of
magnitude reduction in memory requirements.



	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\begin{center} \rule{6in}{1pt} \end{center}
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{center}
{\large			% \hypertarget{Heys}
{\bf Improving mass-conservation of least-squares finite element methods}}

	Jeff Heys \\
	Chemical and Materials Engineering, Arizona State University \\
	Box 876006, Tempe AZ 85287-6006 \\
	{\tt heys@asu.edu} \\
			% \hspace*{9mm}\hfill
	T.~A.~Manteuffel, S.~F.~McCormick, E.~Lee
			% \hfill \hyperlink{index}{\small {\em index}} \\
\end{center}
Interest in least-squares finite element methods continues
to grow due to at least two of its major strengths. First,
the linear systems obtained after discretization are SPD and
often $H^1$ elliptic so that they can be efficiently solved
(often with optimal scalability) using a number of iterative
methods, including conjugate gradients and multigrid.
Second, the least-squares functional provides a sharp
measure of the local error with negligible computational
costs. Despite these two major advantages, the methods have
not gained widespread use, largely because they are
perceived as not providing accurate approximations to the
true solution, especially with regards to conservation of
mass.
The least-squares finite element method is not
discretely conservative, but the approximate solutions given
by the method are the \emph{most accurate approximate
solutions possible in the functional norm for a given
finite-dimensional space}. The method converges to the
approximation that minimizes the functional, so it gives a
relatively accurate solution in the functional norm.

However, anyone would agree that an approximate solution to
the Navier-Stokes equations that has an inflow rate that is
100 times the outflow rate is not an acceptable
approximation, even if it is `accurate' in some norm.
Unfortunately, some combinations of common least-square
functionals and finite element spaces for the Navier-Stokes
equations generate solutions that lose 99\% of the mass
between the inflow and outflow boundaries for some
particular boundary conditions. Herein lies the challenge
for least-squares methods: how do we formulate a functional
and boundary conditions that better represents the type of
accuracy we desire?

In this talk, two new first-order
system reformulations of the Navier-Stokes equations are
presented that admit a wider range of mass conserving
boundary conditions. It is common with least-squares methods
to rewrite the Navier-Stokes equations as a system of
first-order equations using the velocity-vorticity form. The
two new first-order systems are based on the
velocity-vorticity form, but they include a new variable,
$\mathbf{r}$, representing the pressure gradient plus all
or part of the convective term. As we will demonstrate, the
resulting operator problem can be solved very efficiently
using a multigrid or an algebraic multigrid solver, and
excellent mass conservation is observed for multiple test
problems. A difficulty with the new formulations is
obtaining boundary conditions for the new variable,
$\mathbf{r}$, but we will demonstrate at least three
different methods for overcoming this difficulty.



	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\begin{center} \rule{6in}{1pt} \end{center}
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{center}
{\large			% \hypertarget{Howell}
{\bf Implementation and performance of a two-grid method for \\
	nonlinear reaction-diffusion equations}}

	Jason S.~Howell \\
	Dept.~of Mathematical Sciences \\
	O-106 Martin Hall, Box 340975, Clemson SC 29634-0975 \\
	{\tt jshowel@clemson.edu} \\
			% \hspace*{9mm}\hfill
	Carol S.~Woodward, Todd S.~Coffey
			% \hfill \hyperlink{index}{\small {\em index}} \\
\end{center}
Two-grid methods have been developed by Xu (SIAM J.~Num.
Anal., 1996) for application to linear and nonlinear PDEs. Of
particular interest are methods that can be applied to large
nonlinear problems that arise in the simulation of physical
processes, such as a method due to Dawson, Wheeler, and
Woodward (SIAM J.~Num. Anal., 1998). This scheme solves the
original nonlinear problem on a mesh coarser than originally
specified to capture the nonlinear behavior of the solution,
then utilizes a linearized version of the problem to correct
the coarse approximation on the original problem mesh.

The
two-grid method potentially reduces the overall
computational cost by requiring the solution of a smaller
nonlinear system and a large linear system in place of the
original large nonlinear problem. In this talk we
investigate the application of this method to nonlinear
reaction-diffusion equations. In particular, we discuss
issues that arise in the implementation of the algorithm,
and perform numerical experiments on problems designed to
gauge the performance of the two-grid method relative to a
standard Newton iterative nonlinear solver.



	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\begin{center} \rule{6in}{1pt} \end{center}
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{center}
{\large			% \hypertarget{Howle}
{\bf The effect of boundary conditions and inner solver accuracy
within  \\ pressure convection-diffusion preconditioners for
the \\ incompressible Navier-Stokes equations}}

	Victoria Howle \\
	Sandia National Labs, PO Box 969 \\
	MS9159, Livermore CA 94551 \\
	{\tt vehowle@sandia.gov} \\
			% \hspace*{9mm}\hfill
	Ray Tuminaro, Jacob Schroder
			% \hfill \hyperlink{index}{\small {\em index}} \\
\end{center}
{\it Pressure convection-diffusion} preconditioners for
solving the incompressible Navier-Stokes equations were
first proposed by Kay, Loghin, and Wathen and Silvester,
Elman, Kay, and Wathen. While numerous theoretical and
numerical studies have demonstrated mesh independent
convergence for these block methods on several problems and
their overall efficacy, there are several potential
weaknesses remaining in the practical use of these methods.

Perhaps one of the most poorly understood topics within
this block preconditioner family is the influence of
boundary conditions on overall algorithm convergence. The
notion of differential commuting is the basis for all {\it
pressure convection-diffusion} preconditioners. The main
mathematical difficulty is that differential commuting does
not hold at the boundaries. Thus, it is unclear what
boundary conditions should be enforced in subblocks of the
preconditioner. Heuristics have been developed that roughly
account for boundary conditions associated with inflow,
outflow, and no-slip. However, these rough heuristics often
do not properly capture the boundary interactions, and can
in fact lead to a degradation in convergence rates as the
mesh is refined. We first explore the effect of having
``ideal'' boundary conditions within the preconditioner.
While not computationally feasible, the ideal boundary
condition results highlight the importance of choosing
suitable boundary conditions. We then explore somewhat more
practical approximations to the ideal conditions based on
ILU factorizations and probing [Siefert and de Sturler,
2005].

Another important issue is the relationship
between the accuracy of inner sub-problem solves to the
overall convergence rate of the outer iteration. It has been
known for quite some time that when mesh-independent
sub-problem solvers are used inexactly within this block
preconditioner, the overall convergence of the outer
iteration remains mesh independent for the Stokes equations
[Silvester and Wathen, 1994]. The situation is not well
understood for the Navier-Stokes equations, and it is also
not well understood when the inner subblock solver has less
than ideal behavior. We have observed a noticeable
degradation in the outer iteration convergence rate when a
sub-solver is terminated too quickly. We discuss possible
solutions to this issue including reusing information from
repeated linear solves.



	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\begin{center} \rule{6in}{1pt} \end{center}
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{center}
{\large			% \hypertarget{Hu}
{\bf Alternatives to smoothed aggregation multigrid prolongators \\
	for anisotrophic problems}}

	Jonathan Hu \\
	Sandia National Laboratories, 7011 East Avenue \\
	MS9159, Livermore CA 94551 \\
	{\tt jhu@sandia.gov} \\
			% \hspace*{9mm}\hfill
	Ray Tuminaro
			% \hfill \hyperlink{index}{\small {\em index}} \\
\end{center}
We consider alternatives to the traditional methods in
smoothed aggregation for generating prolongator operators.
The goal is to produce prolongators that are appropriate for
anisotropic operators.

Consider the linear problem
$Ax=b$. In the first approach, smoothed aggregation with
basis function shifting, we begin with the standard smoothed
prolongator,
$P^{(sm)} = (I - \omega D^{-1} A) P^{(t)}$,
where $P^{(t)}$ is the tentative prolongator.
Given a
prescribed prolongator sparsity pattern, this method moves
basis function support (columns of $P^{(sm)}$) from one
aggregate to another to produce a new prolongator,
$P^{(shift)}$.
The shifting is done in such a way that null
space interpolation is maintained.

In the second
approach, we consider extensions to building prolongator
operators via energy optimization (Vanek, Mandel, Brezina).
In this method, the sum of the energies of the prolongator
basis functions is minimized, subject to a fixed prolongator
nonzero pattern and interpolation of low-energy modes. We
consider modifications such as filtering $A$ to account for
anisotropies and applying a modified CG method to solve the
optimization problem.

We present numerical experiments
that compare the two methods to traditional smoothed
aggregation on a variety of model problems.



	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\begin{center} \rule{6in}{1pt} \end{center}
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{center}
{\large			% \hypertarget{Huhtanen}
{\bf Splittings for iterative solution of linear systems}}

	Marko Huhtanen \\
	Institute of Mathematics, Helsinki University of Technology \\
	Box 1100, FIN-02015, Finland \\
	{\tt marko.huhtanen@tkk.fi} \\
			% \hspace*{9mm}\hfill
	Mikko Byckling
			% \hfill \hyperlink{index}{\small {\em index}} \\
\end{center}
Consider iteratively solving a
linear system
$Ax=b$,
with invertible $A\in \Cplex^{n \times n}$ and
$b\in \Cplex^n$, by splitting the matrix $A$ as
$A=L+R$, where $L$
and $R$ are both readily invertible. In such a case the
recently introduced residual minimizing Krylov subspace
method [1] can be executed, allowing, in a certain
sense, preconditioning simultaneously with $L$ and $R$.

Splittings satisfying $A=L+R$ result either form the
structure of the problem, or are algebraic. Splittings of
Gauss-Seidel type belong to the latter category. In this
talk we discuss such splittings of $A$.

[1] M.~Huhtanen and O.~Nevanlinna,
{\em A minimum residual algorithm for
solving linear systems},
submitted manuscript available at
\verb9www.math.hut.fi/~mhuhtane/index.html9.
% \texttt{www.math.hut.fi/$\sim$mhuhtane/index.html}.



	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\begin{center} \rule{6in}{1pt} \end{center}
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% \pdfbookmark[1]{J-K}{j-k}
\begin{center}
{\large			% \hypertarget{Jiang}
{\bf A preconditioned L-BFGS algorithm with application to \\
	protein structure prediction}}

	Lianjun Jiang \\
	Computer Science, University of Colorado \\
	Boulder CO 80309-0430 \\
	{\tt lianjunj@gmail.com} \\
			% \hspace*{9mm}\hfill
	Richard Byrd, Elizabeth Eskow, Robert B.~Schnabel
			% \hfill \hyperlink{index}{\small {\em index}} \\
\end{center}
The limited-memory BFGS method has been widely used in large
scale unconstrained optimization problems, including protein
structure prediction. A major weakness of the L-BFGS method
is that it may converge very slowly for ill-conditioned
problems. We propose a preconditioned L-BFGS method, where
we form the preconditioner from parts of the partially
separable objective function.

We report results of
experiments in the context of the protein structure
prediction problem for four different proteins, using a
protein energy model as the objective function and multiple
initial configurations for each protein. The results show
speed-ups with factors between 3 and 10 in terms of function
evaluations and with factors between 2 and 7 in terms of CPU
time. The difference between CPU time and function
evaluation speed-up is due to the extra overhead of
calculating and applying the preconditioner. We also compare
our results to a method from the other competitive class of
large-scale methods, preconditioned truncated Newton method
(TNPACK). The limited results indicate that the
preconditioned L-BFGS method may be more efficient.

We
also tried this approach in a more general context, using
limited memory with an incomplete Cholesky factorization of
the Hessian as a preconditioner. We compared the performance
with the truncated Newton algorithm TRON, which uses a
similar preconditioner. Tested on a subset of the CUTER test
problems, our results show that, using this preconditioner,
the preconditioned LBFGS method is competitive with TRON and
much better than the LBFGS algorithm without preconditioner.



	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\begin{center} \rule{6in}{1pt} \end{center}
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{center}
{\large			% \hypertarget{Jin}
{\bf Parallel domain decomposition methods for some \\
	stochastic partial differential equations}}

	Chao Jin \\
	Dept. of Applied Mathematics, University of Colorado \\
	Boulder  CO  80309-0526 \\
	{\tt chao.jin@colorado.edu} \\
			% \hspace*{9mm}\hfill
	Xiao-Chuan Cai, Congming Li
			% \hfill \hyperlink{index}{\small {\em index}} \\
\end{center}
In this talk, we discuss some  parallel multilevel Schwarz
type domain decomposition preconditioned recycling Krylov
subspace method for the numerical solution of some partial
differential equations with stochastic uncertainties in the
operator. Using a Karhunen-Loeve expansion and a finite
element method with double orthogonal polynomial basis, we
transform the stochastic problem into a large number of
deterministic equations. We will report results obtained
from a PETSc based parallel implementation of a recycling
Krylov subspace method with a domain decomposition
preconditioning



	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\begin{center} \rule{6in}{1pt} \end{center}
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{center}
{\large			% \hypertarget{Jordan}
{\bf Blue Gene/L impacting computational science and engineering}}

	Kirk E.~Jordan \\
	IBM Strategic Growth Business/Deep Computing \\
	1 Rogers St, Cambridge MA 02142 \\
	http://www-3.ibm.com/software/info/university/people/kjordan.html \\
			% \hspace*{9mm}\hfill
	{\tt kjordan@us.ibm.com}
			% \hfill \hyperlink{index}{\small {\em index}} \\
\end{center}
One year has passed and Blue Gene has been placed at several
sites, many of which have a computational science component
that involves iterative methods. In this talk, I will review
some of the results obtained at some of these sites. I will
elaborate on work underway with collaborators and colleagues
in the area of computational science. For those unfamiliar
with the Blue Gene System, I will very briefly describe the
hardware and software environment.

I will describe how
Blue Gene might be used to tackle multi-scale problems, many
of which will need good parallel iterative solvers. While
progress is being made, there remain many challenges for the
computational science community to apply the Blue Gene
resource to Big science problems with impact on society that
until now or in current implementations have fallen short of
the mark. Finally, I will elaborate on opportunities that
exist for the community to get access to Blue Gene.



	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\begin{center} \rule{6in}{1pt} \end{center}
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{center}
{\large			% \hypertarget{Karampataki}
{\bf Balancing iteration accuracy in control problems governed by PDEs}}

	Marian Karampataki \\
	Emory University \\
			% \hspace*{9mm}\hfill
	{\tt mkaramp@emory.edu}
			% \hfill \hyperlink{index}{\small {\em index}} \\
\end{center}
We consider the solution of large scale optimization
problems governed by parabolic partial differential
equations (PDEs). A quadratic functional containing a data
misfit term, is minimized to approximately recover the
parameter function.  The resulting constrained optimization
problem is solved by using the reduced Hessian approach. The
conjugate gradient method (CG) is employed for the solution
of the system involving matrix vector multiplications which
are nontrivial. These matrix vector products do not need to
be computed exactly. We investigate two approaches for
determining the inner iteration tolerance at each CG step
and provide numerical experiments comparing these
approaches.


	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\begin{center} \rule{6in}{1pt} \end{center}
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{center}
{\large			% \hypertarget{Kelley}
{\bf A scalable preconditioner for the Wigner-Poisson equations}}

	C.~T.~Kelley \\
	Dept of Mathematics, NC State University \\
	Box 8025, Raleigh NC 27695-8205 \\
	{\tt tim\_kelley@ncsu.edu} \\
			% \hspace*{9mm}\hfill
	M.~I.~Lasater, A.~G.~Salinger,
	D.~L.~Woolard, G.~Recine, P.~Zhao
			% \hfill \hyperlink{index}{\small {\em index}} \\
\end{center}
In this paper we propose and analyze a scalable
preconditioner for the Wigner-Poisson equations for a
resonant tunneling diode (RTD), and apply that
preconditioner to a matrix-free continuation study of the
dependence of the current through the device on the applied
voltage.

The equations are a integro-partial differential
equation for the distribution of the electrons in the device
couples with Poisson's equation for the electrostatic
potential. Our preconditioner is the inverse of the kinetic
energy operator. We prove that, after elimination of the
Poisson equation, the equation after left preconditioning is
a compact fixed point problem for the Wigner distribution.
We then apply that compactness to show mathematical
scalability of the inner Krylov iteration, and use that to
show scalability of the continuation. We present numerical
results that support the theory.



	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\begin{center} \rule{6in}{1pt} \end{center}
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{center}
{\large			% \hypertarget{Kilmer}
{\bf A regularized Gauss-Newton method for nonlinear imaging problems \\
	in diffuse optical tomography}}

	Misha Kilmer \\
	Mathematics Dept., Tufts Univ. \\
	503 Boston Ave.,  Medford MA 02155 \\
	{\tt misha.kilmer@tufts.edu} \\
			% \hspace*{9mm}\hfill
	Eric de Sturler
			% \hfill \hyperlink{index}{\small {\em index}} \\
\end{center}
The goal in diffuse optical tomography for medical imaging
is the joint reconstruction of parameterized images of
absorption and scattering of light in the body. The
reconstruction requires the approximate solution of a
nonlinear least squares problem for the image parameters.
While traditional approaches such as damped Gauss-Newton
(GN) and Levenberg-Marquardt (LM) have been shown to be
effective at solving the imaging problem in its various
forms, a considerable number of additional function and
Jacobian evaluations are involved in determining the correct
step length and/or damping parameter. In 3D imaging
problems, depending on the particular image model, the cost
of one function evaluation is, at a minimum, the cost of a
dense matrix-vector product and in the worst, but more
realistic, case requires the solution of several large-scale
PDEs. A Jacobian evaluation is even slightly more
expensive. Therefore, it is crucial to keep the number of
function and Jacobian evaluations to a minimum.

The
ill-conditioning of the Jacobian, together with the presence
of noise in the data, motivates us to devise a regularized,
trust-region-based Gauss-Newton approach for determining
search directions. Although LM can be thought of as a
regularized analogue to determining the GN direction, LM has
the property of damping possibly important contributions to
the search direction in spectral components corresponding to
small singular values. On the other hand, the Gauss-Newton
direction is too influenced by components due to small
singular values early on, causing the line search to work
hard to refine the step length. We propose a method that
systematically evaluates the potential contribution of each
of the spectral components corresponding to the GN-direction
and constructs the new direction relative to this
contribution within the confines of a trust-region. Examples
show the success of our method in minimizing function
evaluations with respect to other well-known methods.



	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\begin{center} \rule{6in}{1pt} \end{center}
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{center}
{\large			% \hypertarget{Klie}
{\bf A Krylov-Karhunen-Loeve moment equation (KKME) approach for \\
	solving stochastic porous media flow equations}}

	Hector Klie \\
	Center for Subsurface Modeling, Institute for Computational
	Engineering and Science \\
	The University of Texas, ACES 5.326, Mailcode C0200, Austin TX 78712 \\
	{\tt klie@ices.utexas.edu} \\
			% \hspace*{9mm}\hfill
	Adolfo Rodriguez, Mary F.~Wheeler
			% \hfill \hyperlink{index}{\small {\em index}} \\
\end{center}
In contrast to the widespread use of Monte Carlo simulations
(MCS), stochastic equations have shown remarkable potential
to develop efficient, accurate and physical insightful
models. The main challenge of solving stochastic equations
is to develop tractable descriptions of the system response
in terms of stochastic differential operators and random
fields. In particular, the solution of stochastic PDEs in
porous media flow raises unexplored challenges to the
solution of the discretized system of equations due to the
significant size of standard reservoir problems combined
with the uncertainty induced by error measurements,
discontinuities, nonlinearities in the reservoir parameters
at different spatial and temporal scales.

This work
introduces a Krylov-Karhunen-Loeve moment equation (KKLME)
approach for the solution of stochastic PDEs arising in
large-scale porous media flow applications. The approach
combines recent developments in Karhunen-Loeve moment
equation methods with a block deflated Krylov iterative
solution of a sequence of deterministic linear algebraic
equations sharing the same matrix operator but different
right-hand sides (RHSs).

In this approach, the log of the
random field (i.e., log of permeability) describing the
transmissibility coefficients is decomposed as the sum of a
deterministic average log field plus a mean-zero random
fluctuation. The covariance function associated with the
fluctuation component is further decomposed by means of the
Karhunen-Loeve (KL) expansion scheme. This expansion
consists of modes (i.e. stochastic orders) of increasing
frequency but decreasing magnitude. It has been shown that
the KL expansion is of mean square convergence and summation
thus implying significant computational savings.
Subsequently, a mixed finite element procedure (equivalent
to a cell-centered finite difference scheme under a suitable
quadrature rule) is employed to derive a system of linear
random algebraic equations.

In order to compute
higher-order approximations for the different pressure
moments, a perturbation approach followed by an expansion of
orthogonal random variables is performed to express the
variability of pressures with respect to the random field.
The algebraic manipulation of modes and moments results in a
sequence of deterministic linear systems with multiple RHSs
sharing the same matrix operator. This matrix operator
corresponds to the discretization of the average random
field that, in general, has better algebraic properties than
the operator associated with the original random field. A
set of independent RHSs becomes available when a lower
moment is computed, and each moment involves the solution of
several modes or combinations of them with previous moment
solutions. Since the associated average system is generally
large and sparse, a Krylov subspace iterative solver is
suitable in this case. The availability of RHSs describes a
particular computational pattern that is amenable for highly
scalable implementations and, at the same time, imposes
particular challenges for an efficient Krylov subspace
implementation.

With regard to the solution of systems
with multiple RHSs, significant advances have been made in
recycling the information generated by Krylov iterative
methods. Deflation methods have been shown to be very
effective in these circumstances as they ``remove''
components of the solution associated with extreme
eigenvalues that prevent or slow down convergence. To
perform deflation the Krylov subspace is selectively
augmented with approximate eigenvectors that are either
computed during the iteration or somehow known \emph{a
priori} from some geometrical/physical mean.

On the other
hand, in order to reduce the negative effects of sequential
inner products on memory performance, it is advisable to
rely on block implementations or, in other words, process a
subset of right-hand-sides in a simultaneous fashion. A
novel block deflation Krylov iterative method is proposed.
The main feature of this implementation is to enable changes
both in the size of the block and in the augmented subspace
as the iteration proceeds. This ensures both numerical
stability and flexibility in replacing deflated RHSs
(i.e., associated with converging solutions)
with new RHSs.


Numerical experiments show that the KKLME approach requires
significant less computing time than MCS to converge to the
different statistical moments for the pressure response.
Results are shown for single phase flow and for pressure
system arising in two-phase fully implicit formulations
using a block deflation CG iterative method. In light of
these preliminary results, extensions to relate random
fields with spectrum information are required in order to
exploit further efficiencies.



	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\begin{center} \rule{6in}{1pt} \end{center}
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{center}
{\large			% \hypertarget{Knepper}
{\bf A mathematical framework for equivalent real formulations}}

	Sarah M.~Knepper \\
	37 N College Ave, Box 787 \\
	Saint Joseph MN 56374 \\
	{\tt smknepper@csbsju.edu} \\
			% \hspace*{9mm}\hfill
	Michael A.~Heroux
			% \hfill \hyperlink{index}{\small {\em index}} \\
\end{center}
Equivalent real formulations (ERFs) are useful for solving
complex linear systems using real solvers. Using the four
ERFs discussed by Day and Heroux [1], each can be
expressed by multiplying the \emph{canonical} $K$ form of
the complex matrix by certain diagonal and permutation
matrices on either side. This will allow, for instance, one
ERF to be used as a preconditioner and another ERF to be
used to iteratively solve the linear system by simply
switching back and forth between the forms through scaling
and permuting.

Many real world problems result in a
complex-valued linear system of the form
$C w = d$, where $C$ is a known
$m\times n$ complex matrix, $d$ is a known $m\times 1$
complex vector, and $w$ is an unknown $n\times 1$
complex vector. We
can re-write $C$ as a real matrix of size $2m\times 2n$
called the \emph{canonical} $K$ form. If we let matrix $A$
contain the real parts of the complex matrix $C$ and let
matrix $B$ consist of the corresponding imaginary parts, we
can write $A + i B = C$.
The \emph{canonical} $K$ form is created by
forming the matrix
$K = \TwoMatrx{A}{-B}{B}{A}$.

To preserve the sparsity pattern of $C$,
each complex value $c_{pq} = a_{pq} + ib_{pq}$ is converted
into a $2\times 2$ sub-block with the structure
$ \TwoMatrx{a_{pq}}{-b_{pq}}{b_{pq}}{a_{pq}}.$
For instance, if
$$C = \TwoMatrx{a_{11} + i b_{11}}{a_{12} + i b_{12}}{0}{a_{22} + i b_{22}}$$
then the \emph{permuted canonical} $K$ form is
$$K = \left(
\begin{array}{cccc} a_{11} & -b_{11} & a_{12} & -b_{12} \\
b_{11} & a_{11} & b_{12} & a_{12} \\ 0 & 0 & a_{22} &
-b_{22} \\ 0 & 0 & b_{22} & a_{22} \end{array} \right).
$$

The four ERFs that we will concern
ourselves with are:
$K_1 = \TwoMatrx{A}{-B}{B}{A}$,
$K_2 = \TwoMatrx{A}{B}{B}{-A}$,
$K_3 = \TwoMatrx{B}{A}{A}{-B}$, and
$K_4 = \TwoMatrx{B}{-A}{A}{B}$.
Each of the ERFs can be obtained from the
\emph{permuted canonical} $K$ form by multiplying by
diagonal and permutation matrices on both sides.
In other words,
$K_i = D_l P_l K P_r D_r$,
where $D_l$, $P_l$, $P_r$, and $D_r$ are
certain matrices depending on the size of the complex matrix
and which ERF we desire. Three diagonal matrices and two
permutation matrices (together with their transposes) exist
for the ERFs we are considering.

The talk will describe
the specific diagonal and permutation matrices needed as
well as how to transform from one ERF to another.

[1] David Day and Michael A.~Heroux,
{\em Solving Complex-Valued Linear Systems
via Equivalent Real Formulations},
SIAM J.~Sci. Comput. {\bf 23}(2) (2001) 480--498.



	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\begin{center} \rule{6in}{1pt} \end{center}
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{center}
{\large			% \hypertarget{Knyazev}
{\bf Block locally optimal preconditioned eigenvalue xolvers (BLOPEX)}}

	Andrew Knyazev \\
	Dept.~of Mathematics, University of Colorado at Denver \\
	P.O.~Box 173364, Campus Box 170, Denver CO 80217-3364 \\
	{\tt andrew.knyazev@cudenver.edu} \\
			% \hspace*{9mm}\hfill
	Ilya Lashuk, Merico Argentati, Evgueni Ovtchinnikov
			% \hfill \hyperlink{index}{\small {\em index}} \\
\end{center}
Block Locally Optimal Preconditioned Eigenvalue Xolvers
(BLOPEX) is a package, written in C, that at present
includes only one eigenxolver, Locally Optimal Block
Preconditioned Conjugate Gradient Method (LOBPCG). BLOPEX
supports parallel computations through an abstract layer.
BLOPEX is incorporated in the HYPRE package from LLNL and is
available as an external block to the PETSc package from ANL
as well as a stand-alone serial library. HYPRE and PETSc
packages provide high quality multigrid and domain
decomposition preconditioning on parallel clusters with
distributed or shared memory.

 The LOBPCG method,
suggested and developed by Andrew Knyazev [1] in the past
decade, recently attracts an increasing attention as a
potential alternative to the shift-and-invert Lanczos and
preconditioned Davidson methods due to its simplicity,
robustness and fast convergence. Several MATLAB, C, C++ and
FORTRAN implementations of the LOBPCG are developed by
different groups, e. g., for such applications areas as
structured mechanics and electronic structure calculations.
Main LOBPCG features: a matrix-free iterative method for
computing several extreme eigenpairs of symmetric positive
generalized eigenproblems; a user-defined preconditioner;
robustness with respect to random initial approximations,
variable preconditioners, and ill-conditioning of the
stiffness matrix; apparently optimal convergence speed.
Numerical comparisons suggest that LOBPCG may be a genuine
block analog for eigenproblems of the standard
preconditioned conjugate gradient method for symmetric
linear systems.

We present initial scalability results
using BLOPEX with HYPRE and PETSc on one BlueGene/L box
solving eigenvalue problems of record sizes.

[1] A.~V.~Knyazev, {\em Toward the Optimal Preconditioned
Eigensolver: Locally Optimal Block Preconditioned Conjugate
Gradient Method}, SIAM J.~Sci. Comp. {\bf 23}(2) (2001)
517--541.



	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\begin{center} \rule{6in}{1pt} \end{center}
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{center}
{\large			% \hypertarget{Kolev}
{\bf H(curl) auxiliary mesh preconditioning}}

	Tzanio V.~Kolev \\
	Lawrence Livermore National Laboratory \\
	P.O.~Box 808, L-560, Livermore CA 94551 \\
	{\tt tzanio@llnl.gov} \\
			% \hspace*{9mm}\hfill
	Joseph E.~Pasciak, Panayot S.~Vassilevski
			% \hfill \hyperlink{index}{\small {\em index}} \\
\end{center}
In this talk we present a two-level preconditioning scheme
for H(curl) bilinear forms. The scheme utilizes an auxiliary
problem on a related mesh that is more amenable for
constructing optimal order multigrid methods. Combined with
a domain embedding (or ``fictitious'' domain) technique our
method can precondition a problem defined on a very
complicated mesh by a standard geometric multigrid on a box.



	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\begin{center} \rule{6in}{1pt} \end{center}
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{center}
{\large			% \hypertarget{Kostic}
{\bf How a step toward wider class of matrices could help improve \\
	convergence area of relaxation methods}}

	Vladimir Kostic \\
	Kralja Petra I 69/44 \\
	21000 Novi Sad, Serbia and Montenegro \\
	{\tt vkostic@im.ns.ac.yu} \\
			% \hspace*{9mm}\hfill
	Ljiljana Cvetkovic
			% \hfill \hyperlink{index}{\small {\em index}} \\
\end{center}
Investigations are related to several different relaxation
methods for solving systems of linear equations, but the
main idea is always the same: knowing that system matrix is
strictly diagonally dominant (SDD), we can consider it as an
S-SDD (see Lj. Cvetkovic, V.~Kostic and R.~S.~Varga,
{\em A new Gerschgorin-type eigenvalue inclusion area},
ETNA 18, 2004)
matrix for every nonempty proper subset S of the set
of indices, and from this fact we can derive, in some sense,
an optimal convergence area for relaxation parameter(s).
This convergence area is usually significantly wider than
the corresponding one, obtained from the knowledge of SDD
property, only. Instead of S-SDD class, some more subclasses
of H-matrices can be used for the same purposes.



	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\begin{center} \rule{6in}{1pt} \end{center}
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% \pdfbookmark[1]{L}{l}
\begin{center}
{\large			% \hypertarget{Langdon}
{\bf Coupled Gauss-Seidel algorithm in multigrid mode for the \\
	thin film equation}}

	Stephen Langdon \\
	Dept.~of Mathematics, University of Reading \\
	Whiteknights, PO Box 220, Reading RG6 2AX United Kingdom \\
	{\tt s.langdon@reading.ac.uk} \\
			% \hspace*{9mm}\hfill
	John W Barrett
			% \hfill \hyperlink{index}{\small {\em index}} \\
\end{center}
In this talk we consider the iterative solution of a
nonlinear system arising from a finite element
discretisation of the fourth order equation \[
\frac{\partial u}{\partial t} + \nabla \cdot
(|u|^{\gamma}\nabla\Delta u) = 0, \] where $\gamma>0$. This
equation models a thin liquid film spreading on a solid
surface, with $u$ the height of the film. It is well known
that for nonnegative initial data, the solution $u$ remains
nonnegative for all time. However, this nonnegativity of $u$
is not guaranteed if the equation is discretised in a naive
way. Imposing the nonnegativity of $u$ as a constraint leads
to a discrete variational inequality to be solved at each
time step. Specifically defining $S^h$ to be the space of
piecewise linear functions on a uniform mesh and $K^h\subset
S^h$ to be the space of nonnegative functions in $S^h$,
given $U^{n-1}\in K^h$ we seek $U^{n} \in K^h$ and $W^n \in
S^h$ such that \begin{eqnarray*} &(U^{n},\chi)^h +
\tau\,(|U^{n-1}|^{\gamma}\nabla W^n,\nabla \chi) =
(U^{n-1},\chi)^h \qquad \forall \ \chi \in S^h,& \\ &(\nabla
U^{n},\nabla (\chi-U^{n})) \geq (W^{n}, \chi-U^n)^h \qquad
\forall \ \chi \in K^h,& \end{eqnarray*} where $\tau$
represents the time step, and $(\cdot,\cdot)$ and
$(\cdot,\cdot)^h$ represent the $L^2$ inner product and its
trapezoidal rule discretisation respectively.


Well-posedness, stability, unique solvability, and
convergence of $U^n$ to $u$ and $W^n$ to $w=-\Delta u$ were
established by Barrett, Blowey and Garcke in 1998. To solve
the nonlinear system they used an Uzawa algorithm, for which
they were able to demonstrate convergence of
$U^{n,p}\rightarrow U^n$ and of $\int_{\Omega}
|U^{n-1}|^{\gamma} |\nabla(W^n-W^{n,p})|^2 dx \rightarrow
0$, as the number of iterations $p\rightarrow\infty$.
However, the convergence of this algorithm was found to be
extremely slow. Here, we propose instead a coupled
Gauss-Seidel algorithm in multigrid mode for the iterative
solution of the nonlinear system. Proving convergence for
the multigrid algorithm remains an open question, but
numerical results indicate mesh independent convergence to
the same solution as that achieved with the Uzawa algorithm
in most cases tested, with a greatly reduced computational
cost compared to iterating on a single grid.



	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\begin{center} \rule{6in}{1pt} \end{center}
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{center}
{\large			% \hypertarget{Langou}
{\bf A fast a-posteriori reorthogonalization scheme for the classical \\
	Gram-Schmidt orthogonalization in the context of iterative methods}}

	Julien Langou \\
	1122 Volunteer Blvd, Claxton Bldg. Room 233 \\
	Knoxville TN 37996-3450 \\
			% \hspace*{9mm}\hfill
	{\tt langou@cs.utk.edu}
			% \hfill \hyperlink{index}{\small {\em index}} \\
\end{center}
The year 2005 have been marked by two new papers on the
Classical Gram-Schmidt algorithm (see [1,2]). These results
offer a better understanding of the Classical Gram-Schmidt
algorithm. It is finally proved that the Classical
Gram-Schmidt algorithm generates a loss of orthogonality
bounded by the square of the condition number of the initial
matrix. In the first part of the talk, I will quickly review
the proof, explain its key points and its implication in the
context of iterative methods. In the second part, I will
focus on the new results that we have found related to the
Classical Gram-Schmidt algorithm. In particular an
a-posteriori reorthogonalization scheme extremely efficient
is given in the context of iterative methods. (We borrow
ideas developed in [3] in the context of GMRES-MGS.)

[1] A.~Smoktunowicz and J.~Barlow,
{\em A note on the error analysis of Classical Gram Schmidt},
submitted to Numerische Mathematik (2005).

[2] Luc Giraud, Julien Langou, Miroslav Rozlo\v{z}n\'{\i}k,
Jasper van den Eshof, {\em Rounding error analysis of
the classical Gram-Schmidt orthogonalization process},
Numerische Mathematik {\bf 101}(1) (July 2005) 87--100.

[3] Luc Giraud, Serge Gratton, Julien Langou,
{\em A rank-$k$ update procedure for
reorthogonalizing the orthogonal factor from modified
Gram-Schmidt}, SIAM J.~Matrix An. Appl. {\bf 25}(4)
(August 2004) 1163--1177.



	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\begin{center} \rule{6in}{1pt} \end{center}
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{center}
{\large			% \hypertarget{Lapenta}
{\bf A preconditioned Newton-Krylov strategy for moving mesh adaptation}}

	Giovanni Lapenta \\
	MS: K717, Los Alamos National Laboratory \\
	Los Alamos NM 87545 \\
	{\tt lapenta@lanl.gov} \\
			% \hspace*{9mm}\hfill
	Luis Chac\'on
			% \hfill \hyperlink{index}{\small {\em index}} \\
\end{center}
We propose a new approach to adaptive mesh motion based on
solving a coupled self-consistent system for the physics
equations and for the grid generation equations. The key
aspect of the new method is the solution of the non-linear
coupled system with a preconditioned Newton-Krylov method.
The present work described the approach and focuses on the
preconditioning techniques.

Adaptive grids are becoming
an ever more common tool for high performance scientific
computing. We focus here on the type of adaptation achieved
by moving a constant number of points according to
appropriate rules, an approach termed moving mesh adaptation
(MMA). The approach we consider here is based specifically
on retaining a finite volume approach but allowing the grid
to evolve in time according to a grid evolution equation
obtained from minimization principles. The approach
originates from the seminal papers by Brackbill and
Saltzmann [1] and by Winslow [2].

In the present paper we
consider the fundamental question in the application of MMA.
Is it worth the effort? The literature is very rich and
considerable results have been obtained in designing MMA
approaches that provide grids that can indeed present the
desired properties. But the question of whether once the
adaptive grids are used the simulations are actually more
cost effective remains largely unanswered.

We have
revisited the question and have reached the conclusion that
in order to obtain an effective MMA strategy, three
ingredients need to be considered.

First is the effective
formulation of the moving grid equations. In 1D the problem
is benign, as error minimization leads to error
equidistribution and to a rigorous and simple minimization
procedure. In 2D and 3D the problem is more challenging but
we have derived an effective approach based on the classic
approach by Brackbill-Saltzmann-Winslow [1,2]. The crucial
ingredients of our approach are the formulation of the
physics equations in a conservative form and of the
formulation of the grid generation equations using harmonic
mapping [3,4]. The independent variables of the physics
equations are changed from the physical to the logical space
and the equations are rewritten in the logical space in a
fully conservative form [4].

Second is the solution
algorithm for the MMA method. Here we bring a new
development. The moving mesh equations and the physics
equations, derived by discretizing the problem under
investigation on a moving grid, form a tightly coupled
system of algebraic non-linear equations. Traditionally, the
coupling is broken, the physics and grid equations being
solved separately in a lagged time-splitting approach. Each
time step is composed of two alternating steps: the physics
equations are solved on the current grid, the grid equations
are then solved using new information from the solution of
the physics equations. However, in presence of sharp fronts
or other moving features, breaking such coupling can lead to
grid lagging with respect of the physics equations, with
adaptation resulting behind rather than on the moving
feature.

 We avoid breaking the coupling and solve the
full non-linear set of physics and grid equation using the
preconditioned Newton-Krylov (NK) approach [5].

Third
ingredient in a cost-effective grid adaptation is an
efficient preconditioning technique. In 1D a simple block
tridiagonal approach works effectively [6]. Each set of
equations, for physics and for grid generation, is
preconditioned with a tridiagonal matrix obtained by
numerically approximating the corresponding diagonals in the
Jacobian. In 2D, we rely on a multigrid preconditioning
strategy where a crucial innovation is how to coarsen the
information relative to the adaptivity in the harmonic grid
generation equations [4].

In the present paper we
describe the approach followed and we report a number of
examples to illustrate the performance of the new approach.

[1] J.~U.~Brackbill, J.~S.~Saltzmann,
{\em Adaptive zoning for singular problems in 2 dimensions},
J.~Comput. Phys. {\bf 46}(3) (1982) 342--368.

[2] A.~Winslow,
{\em Adaptive mesh zoning by the equipotential method},
Tech. Rep. UCID-19062, Lawrence Livermore Laboratory (1981).

[3] V.~D.~Liseikin,
{\em Grid generation methods}, Springer, Berlin, New York, 1999.


[4] L.~Chac\'{o}n, G.~Lapenta,
{\em A fully implicit, nonlinear adaptive grid strategy},
J.~Comput. Phys. {\bf 212} (2006) 703--717.

[5] C.~T.~Kelley,
{\em Iterative methods for linear and nonlinear equations},
SIAM, Philadelphia, 1995.


[6] G.~Lapenta, L.~Chac\'{o}n,
{\em Cost-effectiveness of fully implicit moving mesh
adaptation: a practical investigation in 1D},
J.~Comput. Phys., submitted.



	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\begin{center} \rule{6in}{1pt} \end{center}
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{center}
{\large			% \hypertarget{Lashuk}
{\bf Steepest descent and conjugate gradient methods with \\
	variable preconditioning}}

	Ilya Lashuk \\
	Dept.~of Mathematical Sciences \\
	University of Colorado at Denver and Health Sciences Center \\
	P.O.~Box 173364, Campus Box 170, Denver CO 80217-3364 \\
	{\tt ilashuk@math.cudenver.edu} \\
			% \hspace*{9mm}\hfill
	Andrew Knyazev
			% \hfill \hyperlink{index}{\small {\em index}} \\
\end{center}
We show that the conjugate gradient method with variable
preconditioning in certain situations cannot give any
improvement compared to the steepest descent method for
solving a linear system with a symmetric positive definite
(SPD) matrix of coefficients. We assume that the
preconditioner is SPD on each step, and that the condition
number of the preconditioned system matrix is bounded from
above by a constant independent of the step number. Our
proof is geometric and is based on the simple fact that a
nonzero vector multiplied by all SPD matrices with a
condition number bounded by a constant generates a circular
cone.



	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\begin{center} \rule{6in}{1pt} \end{center}
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{center}
{\large			% \hypertarget{Lee11}
{\bf Incomplete LU preconditioning enhancement strategies for sparse matrices}}

	Eun-Joo Lee \\
	Laboratory for High Performance Scientific Computing
		\& Computer Simulation \\
	Dept. of Computer Science, University of Kentucky \\
	Lexington KY 40506-00046 \\
	{\tt elee3@csr.uky.edu}
			% \hspace*{9mm}\hfill
	\\ Jun Zhang
			% \hfill \hyperlink{index}{\small {\em index}} \\
\end{center}
Several preconditioning enhancement strategies for improving
inaccurate preconditioners produced by the incomplete LU
factorizations of sparse matrices are presented.  The strategies
employ the elements that are dropped during the incomplete LU
factorization and utilize them in different ways by separate
algorithms.

 The first strategy (error compensation) applies the
dropped elements to the lower and upper parts of the LU
factorization to computer a new error compensated LU factorization.
Another strategy (inner-outer iteration), which is a variant of the
incomplete LU factorization, embeds the dropped elements in its
iteration process.

Experimental results show that the presented
enhancement strategies improve the accuracy of the incomplete LU
factorization when the initial factorizations found to be
inaccurate.  Furthermore, the convergence cost of the preconditioned
Krylov subspace methods is reduced on solving the original sparse
matrices with the proposed strategies.


	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\begin{center} \rule{6in}{1pt} \end{center}
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\newpage

\begin{center}
{\large			% \hypertarget{Lee21}
{\bf A novel algebraic multigrid-based approach for solving \\
	Maxwell's equations}}

	Barry Lee \\
	CASC L-561 LLNL, P.O.~Box 808 \\
	Livermore CA 94551-0909 \\
	{\tt lee123@llnl.gov} \\
			% \hspace*{9mm}\hfill
	Charles Tong
			% \hfill \hyperlink{index}{\small {\em index}} \\
\end{center}
This talk presents a new algebraic multigrid-based method
for solving the curl-curl formulation of Maxwell's equations
discretized with edge elements. The ultimate goal of this
approach is two-fold. The first is to produce a
multiple-coarsening multigrid method with two approximately
decoupled hierarchies branching off at the initial coarse
level, one resolving the divergence-free error and the other
resolving the curl-free error, i.e., a multigrid method that
couples only on the finest level and mimics a Helmholtz
decomposition on the coarse levels. The second consideration
is to produce the hierarchies using a non-agglomerate
coarsening scheme.

To roughly attain this two-fold goal,
this new approach constructs the first coarse level using
topological properties of the mesh. In particular, a
discrete orthogonal decomposition of the finest edges is
constructed by dividing them into two sets, those forming a
minimum spanning tree and the complement set forming the
cotree. Since the cotree edges do not form closed cycles,
these edges cannot support ``complete'' near-nullspace
gradient functions of the curl-curl Maxwell operator. Thus,
partitioning the finest level matrix using this tree/cotree
decomposition, the cotree-cotree submatrix does not have a
large near-nullspace. Hence, a non-agglomerate algebraic
multigrid method (AMG) that can handle strong positive and
negative off-diagonal elements can be applied to this
submatrix. This cotree operator is related to the initial
coarse-grid operator for the divergence-free hierarchy.

The
curl-free hierarchy is generated by a nodal Poisson operator
obtained by restricting the Maxwell operator to the space of
gradients. Unfortunately, because the cotree operator itself
is not the initial coarse-grid operator for the
divergence-free hierarchy, the multiple-coarsening scheme
composed of the cotree matrix and its coarsening, and the
nodal Poisson operator and its coarsening does not give an
overall efficient method. Algebraically, the tree/cotree
coupling on the finest level, which is accentuated through
smooth divergence-free error, is too strong to be handled
sufficiently only on the finest level. In this new approach,
these couplings are handled using oblique/orthogonal
projections onto the space of discretely divergence-free
vectors. In the multigrid viewpoint, the initial coarsening
from the target fine level to the divergence-free subspace
is obtained using these oblique/orthogonal
restriction/interpolation operators in the Galerkin
coarsening procedure. The resulting coarse grid operator can
be preconditioned with a product operator involving a
cotree-cotree submatrix and a topological matrix related to
a discrete Poisson operator.

The overall iteration is then a
multigrid cycle for a nodal Poisson operator (the curl-free
branch) coupled on the finest grid to a preconditioned
Krylov iteration for the fine grid Maxwell operator
restricted to the subspace of discretely divergence-free
vectors. Numerical results are presented to verify the
effectiveness and difficulties of this new approach for
solving the curl-curl formulation of Maxwell's equations.



	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\begin{center} \rule{6in}{1pt} \end{center}
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{center}
{\large			% \hypertarget{Leyffer}
{\bf The return of the filter method}}

	Sven Leyffer \\
	9700 South Cass Ave \\
	Argonne IL 60439 \\
	{\tt leyffer@mcs.anl.gov} \\
			% \hspace*{9mm}\hfill
	Michael Friedlander
			% \hfill \hyperlink{index}{\small {\em index}} \\
\end{center}
Filters have been introduced as an alternative to penalty
functions to promote global convergence for nonlinear
optimization algorithms. A filter borrows ideas from multi-
objective optimization and accepts a trial point whenever
the objective or the constraint violation is improved
compared to previous iterates. We present new filter active
set approaches to nonlinear optimization based on a two-
phase methodology. The first finds an estimate of the
optimal active set, and the second phase performs a Newton
step on the corresponding equality constrained problem. The
approach allows inexact subsystem solves, making it suitable
for PDE constrained optimization. Time permitting we present
numerical experience on large structured optimization
problems.



	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\begin{center} \rule{6in}{1pt} \end{center}
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{center}
{\large			% \hypertarget{Li}
{\bf Towards an automatic and application-based eigensolver selection}}

	Xiaoye S.~Li \\
	MS 50F-1650, Lawrence Berkeley National Laboratory \\
	1 Cyclotron Rd, Berkeley CA 94720-8139 \\
	{\tt xsli@lbl.gov} \\
			% \hspace*{9mm}\hfill
	Osni Marques, Yeliang Zhang
			% \hfill \hyperlink{index}{\small {\em index}} \\
\end{center}
The computation of eigenvalues and eigenvectors is an
important and often time-consuming phase in computer
simulations. Recent efforts in the development of
eigensolver libraries have given users good algorithm
implementations without the need for users to spend much
time in programming. Yet, given the variety of algorithms
that are available to domain scientists, choosing the
``optimal'' algorithm for a particular application is a
daunting task. In addition, as simulations become
increasingly sophisticated and larger, it becomes infeasible
for a user to try out every reasonable algorithm
configuration in a timely fashion. Therefore, there is a
need for an automated tool that is able to guide the user
through the maze of various solvers with different
configurations.

In this talk, we will describe a
high-end, intelligent sparse eigensolver toolbox, EigAdept,
which comprises the following components:

\begin{itemize}
\item A uniform and extensible interface for a collection
of parallel sparse eigensolvers. The collection focuses on a
class of solvers based on projection methods which are
amenable to scalable implementations, which include ARPACK
(implicitly restarted Arnoldi method), BLZPACK (block
Lanczos method), TRLan (thick-restart Lanczos method), the
Jacobi-Davidson method and the multi-level sub-structuring
(AMLS) method. The Arnoldi/Lanczos-based solvers are
enhanced with shift-and-invert capabilities using the
scalable sparse direct linear solvers such as SuperLU and
MUMPS.

\item An intelligent engine to guide the user
through the maze of various solvers and to automate the
process of algorithm selection. To achieve that, a ``history''
knowledge base (algorithm selection criteria, or decision
tree) incorporates initial information from our prior
experience as well as from the literature (e.g., from
``Templates for the Solution of Algebraic Eigenvalue
Problems: a Practical Guide'', edited by Bai et al.) The
contents of the knowledge base are gradually improved as
more problems are solved, and can be ``adapted'' at runtime
through the repeated solutions of similar eigensystems from
a specific application domain. An efficient data analyzer
takes a user's problem specification at runtime, queries the
knowledge base, and finds the best match of an algorithm
configuration with the target problem.

\item Highly-tuned
performance-critical kernels for high-end architectures. We
identify and isolate the performance-critical kernels (e.g.,
parallel sparse matrix-vector multiplication), and provide
highly-tuned versions for them. The methodology of automatic
performance tuning consists of both off-line optimization
guided by detailed performance model, and on-line
optimization by running the kernels in the pruned space of
possible implementations. Furthermore, these tuned kernels
will be made as standard-alone components, so that they can
be used directly in any new eigensolver technology, or even
in other areas of matrix computations.
\end{itemize}

EigAdept is implemented in C++ with Fortran interface. We
have implemented distinct class structures for eigensolvers,
linear equation solvers, and matrix types, so that for each
eigensolver algorithm, we can easily support different
sparse matrix formats, or use different linear solvers
internally (e.g., for performing shift-and-invert). We use
MySQL relational database to facilitate the implementation
of the intelligent engine. MySQL is a free open source
database software with a reliable C API. We will illustrate,
with some case studies, that EigAdept can be a valuable tool
for users from application domains, as well as for experts
doing algorithm research.



	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\begin{center} \rule{6in}{1pt} \end{center}
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{center}
{\large			% \hypertarget{Liao}
{\bf An iterative projection method for solving large-scale nonlinear \\
eigenproblems with application to next-generation accelerator design}}

	Ben-Shan Liao \\
	Dept.~of Mathematics \\
	University of California, Davis CA 95616 \\
	{\tt liao@math.ucdavis.edu} \\
			% \hspace*{9mm}\hfill
	Lie-Quan Lee, Zhaojun Bai, Kwok Ko
			% \hfill \hyperlink{index}{\small {\em index}} \\
\end{center}
The emerging needs to solve large-scale nonlinear eigenvalue
problems arising in many engineering applications have come
into notice. More researches have been conducted on
efficient algorithm development and computational theory.
However, the nonlinearity varying greatly from problem to
problem results in a challenging computational task. Instead
of considering arbitrary nonlinear eigenvalue problems, we
consider a certain type of problems for robust and efficient
algorithm developments. This particular type nonlinear
eigenvalue problems consist of a dominated linear and
positive definite pencil and a ``small'' nonlinear component.
A number of applications give rise of nonlinear eigenvalue
problems of such type.  Examples include vibration study of
fluid solid structures and eigencomputation problem from
fiber optic design.

In this talk, a nonlinear eigenvalue problem we particular
interested in is from the finite element analysis of the
resonant frequencies and external Q of a waveguide loaded
cavity, as currently be studied by researchers for
next-generation accelerator design. We study iterative
subspace projection methods, such as nonlinear Arnoldi
method. We focus on the critical stages of algorithms, such
as the choice of initial projection subspace, and the
expansion and the refinement of projection subspace. We
present a notable improvement over the early iterative
projection methods in our case study.


	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\begin{center} \rule{6in}{1pt} \end{center}
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{center}
{\large			% \hypertarget{Limon}
{\bf Adaptive mesh refinement: in the presence of discontinuities}}

	Alfonso Limon \\
	School of Mathematical Sciences, Claremont Graduate University \\
	710 N.~College Ave., Claremont CA 91711 \\
	{\tt alfonso.limon@cgu.edu} \\
			% \hspace*{9mm}\hfill
	Hedley Morris
			% \hfill \hyperlink{index}{\small {\em index}} \\
\end{center}
Classical multiresolution wavelet techniques have been used
successfully to simplify the computation of PDEs by
concentrating resources in places where the solution varies
quickly. However, classical techniques tend to fail near
solution discontinuities, as Gibb's effects contaminate the
wavelet coefficients used to refine the solution. Non-linear
adaptive stencil methods, such as the ENO scheme, can
reconstruct the solution accurately across jumps, but
possess neither the compression capabilities nor the
well-understood stability properties of wavelets. Expanding
on Harten's ideas, we construct an alternative to wavelets,
a multiresolution method that does not suffer from Gibb's
effects and has good compression properties. We will present
this alternative multiresolution method and compare its
performance to other methods by means of several examples.


	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\begin{center} \rule{6in}{1pt} \end{center}
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{center}
{\large			% \hypertarget{Liu}
{\bf Preconditioning techniques for the Navier-Stokes equations \\
	in rotation form}}

	Jia Liu \\
	Dept.~of Mathematics and Computer Science \\
	Emory University, Atlanta GA 30322 \\
	{\tt jliu8@emory.edu} \\
			% \hspace*{9mm}\hfill
	Michele Benzi
			% \hfill \hyperlink{index}{\small {\em index}} \\
\end{center}
We consider preconditioned iterative methods applied to
discretizations of the Navier-Stokes equations in 2D and 3D
bounded domains. Both unsteady and steady flows are
considered. The equations are linearized by Picard
iteration. We make use of the rotation form of the momentum
equations, which has several advantages from the linear
algebra point of view.

We focus on two classes of
preconditioners for the resulting nonsymmetric saddle point
problems, namely, block triangular preconditioners and some
variants of the Hermitian/Skew-Hermitian splitting (HSS)
preconditioner. Both types of preconditioners have
comparable cost per iteration, and make use of (standard)
fast solvers for elliptic scalar PDEs (convection-diffusion
and Poisson-type).

We compare the performance of both
types of preconditioners with regard to the mesh size, the
Reynolds number, the time step, and other problem
parameters. Our experiments indicate that fast convergence
independent of problem parameters is achieved in many cases.
We include comparing experiments for both the rotation form
and convection diffusion form of the Navier-Stokes equations
the nonlinear iteration.



	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\begin{center} \rule{6in}{1pt} \end{center}
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{center}
{\large			% \hypertarget{Livshits}
{\bf AMG eigenbasis solver for the Schr\"{o}dinger eigenvalue problem}}

	Ira Livshits \\
	Dept.~of Mathematical Sciences \\
	Ball State University, Muncie IN 47306-0490 \\
	{\tt ilivshits@bsu.edu} \\
			% \hspace*{9mm}\hfill
	Achi Brandt
			% \hfill \hyperlink{index}{\small {\em index}} \\
\end{center}
In this talk the AMG algorithm for solving the
Scr\"{o}dinger eigenvalue problem is discussed. Its goal is
to approximate the eigenbasis, i.e., all eigenfunctions, of
the Schr\"{o}dinger operator as it appears in the Kohn-Sham
equation.

The algorithm employs multilevel
eigenvalues/eigenfunction representations that allows
approximation of most of the eigenfunctions on the
inexpensive coarse grids and leads to a reduction of both
computational and storage costs. In addition this structure
is beneficial for performance of a variety of applications
essential to the Kohn-Sham equations. Also addressed is the
issue of quality of the obtained sets of eigenfunctions,
such as their accuracy and independence. Numerical results
and discussion of the further extension of the approach will
conclude the talk.



	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\begin{center} \rule{6in}{1pt} \end{center}
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{center}
{\large			% \hypertarget{Loisel}
{\bf A domain decomposition method that converges in two steps \\
	for three subdomains}}

	S\'ebastien Loisel \\
	2~4, rue du Li\`evre, Case postale 64 \\
	1211 Gen\`eve 4 (Suisse) \\
			% \hspace*{9mm}\hfill
	{\tt loisel@math.unige.ch}
			% \hfill \hyperlink{index}{\small {\em index}} \\
\end{center}
In Schwarz-like domain decomposition methods, a domain
$\Omega$ is broken into two or more subdomains and
Dirichlet, Neumann, Robin or pseudo-differential problems
are iteratively solved on each subdomain. For certain
problems, it is well-known that the Dirichlet-Neumann
iteration for two subdomains will converge in two steps. Let
$\Omega$ be an open domain and
$\Omega_{1},\Omega_{2},\Omega_{3}$ a domain decomposition of
$\Omega$ such that each pair of subdomains shares an
interface (for instance,
$\Omega=\{ z\in\Cplex \;|\; |z|<1\}$
and $\Omega_{j}=\{ re^{i\theta} \;|\; 0<r<1$ and
$\theta\in(2j\pi/3,2(j+1)\pi/3)\}$,
$j=1,2,3$).
We will show a new Schwarz-like domain decomposition
method that converges in two iterations in this situation.



	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\begin{center} \rule{6in}{1pt} \end{center}
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% \pdfbookmark[1]{M-O}{m-o}
\begin{center}
{\large			% \hypertarget{MacLachlan}
{\bf A greedy strategy for coarse-grid selection}}

	Scott MacLachlan \\
	Dept.~of Computer Science and Engineering \\
	University of Minnesota, 4-192, EE/CS Building \\
	200 Union Street SE, Minneapolis MN 55455 \\
	{\tt maclach@cs.umn.edu} \\
			% \hspace*{9mm}\hfill
	Yousef Saad
			% \hfill \hyperlink{index}{\small {\em index}} \\
\end{center}
In recent years, substantial effort has been focused on
developing methods capable of solving the large linear
systems that arise from the discretization of partial
differential equations. This research has been driven by
application scientists' demands of higher accuracy, in both
mathematical modeling and computational solution. Efficient
solution of many of these linear systems is possible only
through the use of multilevel solution techniques. While
highly optimized algorithms may be developed using knowledge
about the origins of the matrix problem to be considered,
much current interest is in the development of purely
algebraic approaches that may be applied in many situations,
without extensive problem-specific tuning.

In this talk,
we present a new algebraic approach to finding the
fine/coarse partitions needed in multilevel approaches. The
algorithm is motivated by theoretical analysis of the
performance of algebraic multigrid (AMG) and algebraic
recursive multilevel solvers (ARMS). From the AMG point of
view, the coarsening is consistent with the ideas of
compatible relaxation, while it may also be motivated by the
algebraic criteria central to ARMS. While no guarantee on
the rate of coarsening is given, the splitting is shown to
always yield an effective preconditioner in the two-level
sense. Numerical performance of two-level and multilevel
variants of this approach is demonstrated.



	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\begin{center} \rule{6in}{1pt} \end{center}
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{center}
{\large			% \hypertarget{Mandel}
{\bf Adaptive selection of face coarse degrees of freedom in the \\
	BDDC and the FETI-DP iterative substructuring methods}}

	Jan Mandel \\
	Dept.~of Mathematical Sciences \\
	University of Colorado at Denver and Health Sciences Center \\
	Campus Box 170, P.O.~Box 173364, Denver CO 80217-3364 \\
	{\tt jmandel@math.cudenver.edu} \\
			% \hspace*{9mm}\hfill
	B.~Sousedik
			% \hfill \hyperlink{index}{\small {\em index}} \\
\end{center}
We propose adaptive selection of the coarse space of the
BDDC and FETI-DP iterative substructuring methods by adding
coarse degrees of freedom with support on selected
intersections of adjacent substructures. The coarse degrees
of freedom are constructed using eigenvectors associated
with the intersections. The minimal number of coarse degrees
of freedom on the selected intersections is added to
decrease a heuristic indicator of the the condition number
under a target value specified a priori. It is assumed that
the starting coarse degrees of freedom are already
sufficient to prevent relative rigid body motions of any
selected pair of adjacent substructures. It is shown
numerically on 2D elasticity problems that the indicator
based on pairs of substructures with common edges predicts
reasonably well the actual condition number, and that the
method can select adaptively the hard part of the problem
and concentrate computational work there to achieve good
convergence of the iterations at a modest cost.



	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\begin{center} \rule{6in}{1pt} \end{center}
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{center}
{\large			% \hypertarget{Marques}
{\bf A comparison of eigensolvers for large electronic structure calculations}}

	Osni Marques \\
	Lawrence Berkeley National Laboratory, 1 Cyclotron Road \\
	MS 50F-1650, Berkeley CA 94720-8139 \\
	{\tt oamarques@lbl.gov} \\
	Andrew Canning, Julien Langou, Stanimire Tomov, \\
			% \hspace*{9mm}\hfill
	Christof Voemel, Lin-Wang Wang
			% \hfill \hyperlink{index}{\small {\em index}} \\
\end{center}
The solution of the single particle Schr\"{o}dinger equation
that arises in electronic structure calculations often
requires solving for interior eigenstates of a large
Hamiltonian. The states at the top of the valence band and
at the bottom of the conduction band determine the band gap
that relates to important physical characteristics such as
optical or transport properties.

In order to avoid the
explicit computation of all eigenstates, a folded spectrum
method has been usually employed to compute only the
eigenstates near the band gap. In this talk, we compare the
conjugate gradient minimization and the optimal block
preconditioned conjugate gradient (LOBPCG) applied to the
folded spectrum matrix with the Jacobi-Davidson algorithm.



	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\begin{center} \rule{6in}{1pt} \end{center}
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{center}
{\large			% \hypertarget{Mavriplis}
{\bf Solution of high-order discontinuous Galerkin methods using \\
	a combined H-P multigrid approach}}

	Dimitri Mavriplis \\
	Dept.~of Mechanical Engineering, Dept 3295 \\
	University of Wyoming, 1000E. University Ave., Laramie WY 82071 \\
	{\tt mavripl@uwyo.edu} \\
			% \hspace*{9mm}\hfill
	Cris Nastase, Li Wang
			% \hfill \hyperlink{index}{\small {\em index}} \\
\end{center}
The development of optimal, or near optimal solution
strategies for higher-order discretizations, including
steady-state solutions methodologies, and implicit time
integration strategies, remains one of the key determining
factors in devising higher-order methods which are not just
competitive but superior to lower-order methods in overall
accuracy and efficiency. The goal of this work is to
investigate and develop a fast and robust algorithm for the
solution of high-order accurate discontinuous Galerkin
discretizations of non-linear systems of conservation laws
on unstructured grids.

We develop a spectral multigrid
method, whereby the coarse ``grid'' levels are constructed by
reducing the order ($p$) of approximation of the
discretization using hierarchical basis
functions($p$-multigrid), keeping the grid elements fixed.
This approach is coupled with a traditional agglomeration
multigrid ($h$-multigrid) approach for unstructured grids,
by constructing additional coarse levels at the lowest
($p=0$) spectral level through element agglomeration. The
overall goal is the development of a solution algorithm
which delivers convergence rates which are independent of
``$p$'' (the order of accuracy of the discretization) and
independent of ``$h$'' (the degree of mesh resolution), while
minimizing the cost of each iteration. The investigation of
efficient smoothers to be used at each level of the
multigrid algorithm is also pursued, and comparisons between
different integration strategies are made as well.



	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\begin{center} \rule{6in}{1pt} \end{center}
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{center}
{\large			% \hypertarget{Mckenzie}
{\bf AMGLAB: an interactive MATLAB testbench for learning and \\
	experimentation with algebraic multigrid methods}}

	Ryan Mckenzie \\
	Computer Science, University of Kentucky \\
	{\tt ryan.m.mckenzie@qmail.edu} \\
			% \hspace*{9mm}\hfill
	Craig C.~Douglas, Gundolf Haase
			% \hfill \hyperlink{index}{\small {\em index}} \\
\end{center}
We describe a first step towards a general algebraic
multigrid expert system that we expect to become a community
project in the multigrid field.



% 	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% 	\begin{center} \rule{6in}{1pt} \end{center}
% 	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% 
% \begin{center}
% {\large			% \hypertarget{Morgan}
% {\bf Restarted Lanczos for nonsymmetric eigenvalue problems and \\
% 	linear equations}}
% 
% 	Ron Morgan \\
% 	Math Department, Baylor University \\
% 	Waco TX 76798-7328 \\
% 	{\tt Ronald\_Morgan@baylor.edu} \\
% 			% \hspace*{9mm}\hfill
% 	Dywayne Nicely
% 			% \hfill \hyperlink{index}{\small {\em index}} \\
% \end{center}
% First, a restarted nonsymmetric Lanczos method will be
% discussed. It can be used to compute both left and right
% eigenvectors even when storage is limited. Approximate
% eigenvectors are retained at the restart as with implicitly
% restarted Arnoldi. It uses a three-term recurrence, but some
% reorthogonalization is needed.
% 
% The next topic is a
% related method called BiCG with deflated restarting (QMR
% with deflated restarting may also be discussed). It
% simultaneously solves linear equations and computes left and
% right eigenvectors. For the case of multiple right-hand
% sides, the eigenvector information from solving the first
% right-hand side can help efficiently solve subsequent
% right-hand sides. A deflated BiCGStab can be used for this.
% Deflated BiCGStab has a projection over the eigenvectors
% followed by regular BiCGStab.



	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\begin{center} \rule{6in}{1pt} \end{center}
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{center}
{\large			% \hypertarget{Newman}
{\bf A scalable projection method for the unsteady \\
	incompressible Navier-Stokes equations}}

	Christopher K Newman \\
	PO Box 5800, MS 0382, Sandia National Laboratories \\
	Albuquerque NM 87185-0835 \\
	{\tt cnewman@sandia.gov} \\
			% \hspace*{9mm}\hfill
	Richard B Lehoucq
			% \hfill \hyperlink{index}{\small {\em index}} \\
\end{center}
We discuss a high order projection scheme for time
integration of the incompressible Navier-Stokes equations.
The method is based on a projection onto a divergence-free
subspace interleaved with a Krylov based exponential time
integration. This semi-explicit approach provides stability
and high order accuracy without the need for a nonlinear
iteration. We present numerical examples to support our
claims and provide comparison against a Crank Nicolson
scheme.



	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\begin{center} \rule{6in}{1pt} \end{center}
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{center}
{\large			% \hypertarget{Nolting}
{\bf HP local refinement using FOSLS}}

	Josh Nolting \\
	2467 E 127th Court,  Thornton CO 80241 \\
	{\tt josh.nolting@colorado.edu} \\
			% \hspace*{9mm}\hfill
	Thomas Manteuffel
			% \hfill \hyperlink{index}{\small {\em index}} \\
\end{center}
Local refinement enables us to concentrate computational
resources in areas that need special attention, for example,
near steep gradients and singularities. In order to use
local refinement efficiently, it is important to be able to
quickly estimate local error. FOSLS is an ideal method to
use for this because the FOSLS functional yields a sharp a
posteriori error measure for each element. This talk will
discuss a strategy for determining which elements to refine
in order to optimize the accuracy/computational cost. Set in
the context of a full multigrid algorithm, our strategy
leads to a refinement pattern with nearly equal error on
each element. Further refinement is essentially uniform,
which allows for an efficient parallel implementation.
Numerical experiments will be presented.



	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\begin{center} \rule{6in}{1pt} \end{center}
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{center}
{\large			% \hypertarget{Olson}
{\bf Developments in algebraic multigrid preconditioning for \\
	high-order spectral elements}}

	Luke Olson \\
	Siebel Center for Computer Science \\
	University of Illinois at
	Urbana-Champaign \\ 201 N.~Goodwin Ave., Urbana IL 61801 \\
			% \hspace*{9mm}\hfill
	{\tt lukeo@uiuc.edu}
			% \hfill \hyperlink{index}{\small {\em index}} \\
\end{center}
In this talk we highlight recent attempts to solve systems
of equations arising from high-order spectral element
discretizations. In particular, we extend the success of
Algebraic Multigrid (AMG) preconditioning on structured
grids to the unstructured case (using triangles).

 We
consider high-order nodal spectral elements based on the
electrostatic distribution. A low-order finite element
preconditioner is utilized and accelerated with Conjugate
Gradient. The elements cause a particular challenge as the
local grids are also unstructured and suffer from poor
aspect ratios. We present numerical evidence in support of
this method and discuss the implications of using this
approach.



	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\begin{center} \rule{6in}{1pt} \end{center}
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{center}
{\large			% \hypertarget{Overton}
{\bf Nonsmooth, nonconvex optimization: theory, algorithms, and applications}}

	Michael Overton \\
	Courant Institute \\
	251 Mercer St, New York NY 10012 \\
			% \hspace*{9mm}\hfill
	{\tt overton@cs.nyu.edu}
			% \hfill \hyperlink{index}{\small {\em index}} \\
\end{center}
Theory: there are two standard approaches to generalizing
derivatives to nonsmooth, nonconvex optimization: the Clarke
subdifferential (or generalized gradient), and the MIRW
subdifferential (or subgradient sets), as expounded in
Rockafellar and Wets (Springer, 1998). We briefly discuss
these and mention their advantages and disadvantages. They
coincide for an important class of functions: those that are
locally Lipschitz and regular, which includes continuously
differentiable functions and convex functions.


Algorithms: the usual approach is bundle methods, which are
complicated. We describe some alternatives: BFGS (a new look
at an old method), and Gradient Sampling (a simply stated
method that, although computationally intensive, has solved
some previously unsolved problems and has a nice convergence
theory).

 Applications: these abound in control, but
surely in other areas too. Of particular interest to me are
applications involving eigenvalues and singular values of
nonsymmetric matrices. Sometimes even easily stated problems
in a few variables are hard. Our new code HIFOO (H-Infinity
Fixed-Order Optimization) is intended for use by practicing
control engineers and has solved some open problems in
control.

 This is all joint work with James Burke and
Adrian Lewis. HIFOO is also joint with Didier Henrion.



	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\begin{center} \rule{6in}{1pt} \end{center}
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{center}
{\large			% \hypertarget{Ovtchinnikov}
{\bf Additive Schwarz methods for elliptic problems with \\
	periodic boundary conditions}}

	Serguei Ovtchinnikov \\
	Dept.~of Computer Science, University of Colorado at
	Boulder \\ Campus Box 430, Boulder CO 80309-0430 \\
	{\tt Serguei.Ovtchinnikov@Colorado.edu} \\
			% \hspace*{9mm}\hfill
	Xiao-Chuan Cai, Max Dryja
			% \hfill \hyperlink{index}{\small {\em index}} \\
\end{center}
In this presentation we discuss additive Schwarz methods for
numerical solutions of elliptic problems with periodic
boundary conditions. Unlike Dirichlet or Neumann type
conditions that are purely local, periodic conditions are
more global, therefore Schwarz type domain decomposition
preconditioning techniques do not perform in the same manner
as in Dirichlet or Neumann problems. In this work we study
the parallel performance of one- and two-level algorithms
and report experimental results obtained on the IBM BG/L.
We also discuss some applications of additive Schwarz
preconditioners for the numerical simulation of
magnetohydrodynamics.



	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\begin{center} \rule{6in}{1pt} \end{center}
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% \pdfbookmark[1]{P-R}{p-r}
\begin{center}
{\large			% \hypertarget{Pan}
{\bf Novel preconditioning techniques in matrix computations}}

	Victor Pan \\
	Math. and Computer Science Dept. \\
	Lehman College, CUNY, Bronx NY 10468 \\
			% \hspace*{9mm}\hfill
	{\tt vpan@lehman.cuny.edu}
			% \hfill \hyperlink{index}{\small {\em index}} \\
\end{center}
Multiplicative preconditioners are popular for solving
linear systems of equations. We introduce additive
preconditioners, which are more robust and more readily
available. By combining them with aggregation processes, we
obtain preconditioners that are nearly as effective as
SVD-based multiplicative preconditioners. Besides
simplifying and stabilizing the generation of such
preconditioners, this technique also preserves the structure
of the input matrices, and we also employ it for numerical
computation of the sign of the matrix determinant. Our
alternative techniques employ additive preconditioners for
computing null vectors and null space bases for a singular
matrix, and we extend this approach to yield alternative
linear solvers and to compute the tails of the SVDs of ill
conditioned matrices and matrix eigenvectors. We support our
approach with extensive analysis and numerical experiments.



	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\begin{center} \rule{6in}{1pt} \end{center}
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\newpage

\begin{center}
{\large			% \hypertarget{Pautasso}
{\bf Performance of the predictor-corrector preconditioners for \\
	Newton-Krylov solvers}}

	Gavino Pautasso \\
	MS: K717,  Los Alamos National Laboratory \\
	Los Alamos NM 87545 \\
	{\tt valsusa@gmail.com} \\
			% \hspace*{9mm}\hfill
	Giovanni Lapenta, Jianwei Ju
			% \hfill \hyperlink{index}{\small {\em index}} \\
\end{center}
We investigate an alternative implementation of
preconditioning techniques for the solution of non-linear
problems. Within the framework of Newton-Krylov methods,
preconditioning techniques are needed to improve the
performance of the solvers. We use a different
implementation approach to re-utilize existing semi-implicit
methods to precondition fully implicit non-linear schemes.
We use a predictor- corrector approach where the fully
non-linear scheme is the corrector and the pre- existing
semi-implicit scheme is the predictor [1,2]. The advantage
of the proposed approach is that it allows to retrofit
existing codes, with only minor modifications, in particular
avoiding the need to reformulate existing methods in terms
of variations, as required instead by other approaches now
currently used.

A classic problem of computational
science and engineering is the search for an efficient
numerical scheme for solving non-linear time-dependent
partial differential equations. Explicit and semi-implicit
methods can provide simple solution techniques but are
seriously limited by time step limitations for stability
(explicit methods) and accuracy (semi-implicit methods).


Recently, significant progress has been made in the
development of fully implicit approaches for solving
nonlinear problems: the Newton-Krylov (NK) method. The
method is developed from the Newton iterative method, by
applying a linear iterative solver to the Jacobian equation
for the Newton step and terminating that iteration when a
suitable convergence criterion holds.

For the solution of
the linear Jacobian equation, Krylov methods are often the
choice, leading to the Newton-Krylov (NK) approach. However,
for most cases, Krylov solvers can be extremely inefficient.
The need for good preconditioners techniques becomes a
constraining factor in the development of NK solvers.

In
a number of fields, recent work based on multi-grid and
physics-based preconditioners[3] have demonstrated extremely
competitive performances.

In the present study, we
discuss a different implementation of preconditioning: the
predictor-corrector (PC) preconditioner [1,2]. The approach
has two novelties. First, it preconditions directly the
non-linear equations rather than the linear Jacobian
equation for the Newton step. The idea is not
new, but it is implemented here in a new way
that leads to great simplifications of the implementation.
We note that this simplification is designed also to
minimize the effort in refitting existing semi-implicit
codes into full fledged implicit codes, representing perhaps
a greater advance in software engineering than in
computational science. Second, we test new ways of
preconditioning the equations by using a combination of
predictor-corrector semi-implicit preconditioning.

The
fundamental idea is to use a predictor to advance a
semi-implicit discretization of the governing equations and
use a corrector Newton step to correct for the initial state
of the predictor step. The typical NK solver is used to
compute the unknown value of the state vector at the end of
the time step ${\bf x}^{1}$ from its known value at the
previous time step ${\bf x}^0$. Instead, we use the Newton
method to iterate for a modification of the actual known
state $ {\bf x}^{*}$ from the previous time step to find a
modified {\it ``previous''} state that makes the semi-implicit
predictor step give the solution of the fully implicit
method.

Two advantages are obvious. First, the actual
previous state ${\bf x}^0$ is likely to be a better first
guess for the modified initial state $ {\bf x}^{*}$ of the
predictor than it is for the final state of the corrector
step. Second, by modifying the non-linear function and
consequently modifying the Jacobian equation, the PC
preconditioner modifies the spectral properties of the
Jacobian matrix in the same way as preconditioners applied
directly to the Jacobian equation. Indeed, as shown below
the PC preconditioner gives the same type of speed-up of the
Krylov convergence without requiring to formulate an actual
preconditioning of the Krylov solver.

We use a suite of
problems, including non-linear diffusion [2] and the standard
driven cavity flow problem [1], as benchmarks to demonstrate
the performance and the reliability of the PC
preconditioning method.

[1] J.~Ju, G.~Lapenta,
{\em Predictor-Corrector Preconditioned Newton-Krylov Method
For Cavity Flow}, Lecture Notes in Computer Science
{\bf 82} (2005) 3514.

[2] G.~Lapenta, J.~Ju, {\em Predictor-Corrector
Preconditioners for Newton-Krylov Solvers},
J.~Comp. Phys., submitted.

[3] D.~A.~Knoll, D.~Keyes,
{\em Jacobian-free Newton-Krylov methods: a survey of
approaches and applications}, J.~Comp. Phys. {\bf 193}
(2004) 357--397.



	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\begin{center} \rule{6in}{1pt} \end{center}
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{center}
{\large			% \hypertarget{Pettitt}
{\bf Theory of molecular fluids}}

	B.~Montgomery Pettitt \\
	Dept.~of Chemistry \\
	University of Houston, Houston TX 77204-5003 \\
			% \hspace*{9mm}\hfill
	{\tt pettitt@uh.edu} \\
			% \hfill \hyperlink{index}{\small {\em index}} \\
\end{center}
A quantitative theory of the structure of molecular fluids
described by atoms or sites has remained elusive in soft
condensed matter theory. Many-body and field theoretic
approaches to the correlations liquids have advanced slowly
since the 1930s. The qualitative and quantitative
inconsistencies of the many-body integral equation theory
for predicting the structure and thermodynamic properties of
model molecular fluids have been understood for some time.

Several means have been proposed to correct these
inconsistencies, many concentrating on the Goldstone
theorem. A formally distinct method for constructing a
diagrammatically proper theory eliminates terms in the
expansion which correspond to unphysical intramolecular
interactions, or so-called bad graphs. Unfortunately, while
certain qualitative advances using the proper theory have
been successful the quantitative results appear to be
uniformly disappointing in comparison to simulation.

We present a new derivation from a topological expansion of
a model for the single atom activity followed by a
topological reduction and low order truncation. This leads
to an approximate numerical value for the new density
coefficient.  The resulting equations give a substantial
improvement over the standard construction as shown with
a series of simple diatomic model simulations.



	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\begin{center} \rule{6in}{1pt} \end{center}
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{center}
{\large			% \hypertarget{Philip}
{\bf Resistive magnetohydrodynamics with implicit adaptive mesh refinement}}

	Bobby Philip \\
	MS B256, Computer and Computational Sciences Division \\
	Los Alamos National Laboratory, PO Box 1663, Los Alamos NM 87545 \\
	{\tt bphilip@lanl.gov} \\
			% \hspace*{9mm}\hfill
	Michael Pernice, Luis Chacon
			% \hfill \hyperlink{index}{\small {\em index}} \\
\end{center}
Implicit adaptive mesh refinement (AMR) is used to simulate
a model resistive magnetohydrodynamics problem. This
challenging multi-scale, multi-physics problem involves a
wide range of length and time scales. AMR is employed to
resolve extremely thin current sheets, essential for an
accurate macroscopic description. Implicit time integration
is used to step over fast Alfven time scales. At each time
step, large-scale systems of nonlinear equations are solved
using Jacobian-free Newton-Krylov methods together with a
physics-based preconditioner. The preconditioner is
implemented using optimal multilevel solvers such as the
Fast Adaptive Composite grid (FAC) method. We will describe
our initial results highlighting various aspects of problem
formulation, optimal preconditioning on AMR grids, and
efforts towards achieving parallelism.



	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\begin{center} \rule{6in}{1pt} \end{center}
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{center}
{\large			% \hypertarget{Phipps}
{\bf Solving bordered systems of linear equations for large-scale \\
	continuation and bifurcation analysis}}

	Eric T Phipps \\
	Sandia National Laboratories, Applied Computational Methods Dept. \\
	P.O.~Box 5800, MS-0316, Albuquerque NM 87185 \\
	{\tt etphipp@sandia.gov} \\
			% \hspace*{9mm}\hfill
	Andrew G Salinger
			% \hfill \hyperlink{index}{\small {\em index}} \\
\end{center}
Solving bordered systems of linear equations where the
matrix is augmented by a small number of additional rows and
columns is ubiquitous in continuation and bifurcation
analysis. Examples include pseudo-arclength continuation,
constraint following, and turning point location. However
solving these systems in a large-scale setting where the
original matrix is large and sparse is difficult. Directly
augmenting the matrix destroys the sparsity structure of the
original matrix since the additional rows and columns are
usually dense, while block elimination methods have
difficulty when the original matrix is nearly singular and
result in additional linear solves.

In this talk we
discuss a simple method for solving systems of this form
using Krylov iterative linear solvers based on computing the
$QR$ factorization of the augmented rows, and is an
extension of the Householder pseudo-arclength continuation
method developed by H.~Walker. It allows solutions of the
bordered system to be computed with a cost roughly
equivalent to solving the original matrix and is
well-conditioned even when the original matrix is singular.


We then apply this technique to the problem of computing
turning point bifurcations in large-scale nonlinear systems.
The $QR$ approach allows turning point algorithms that are
faster, more robust and scale better to millions of unknowns
compared to traditional block elimination schemes. Examples
of applying these techniques to large-scale structural and
fluid mechanics problems will be presented. These techniques
have been implemented in a continuation and bifurcation
software package called LOCA, short for The Library of
Continuation Algorithms, developed by the authors and
publicly available as a part of Trilinos, a set of scalable
linear and nonlinear solvers.



	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\begin{center} \rule{6in}{1pt} \end{center}
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{center}
{\large			% \hypertarget{Quian}
{\bf Stochastic preconditioning for iterative linear equation solvers}}

	Haifeng Qian \\
	Dept. of Electrical and Computer Engineering, 200 Union Street SE \\
	University of Minnesota, Minneapolis MN 55455 \\
	{\tt qianhf@ece.umn.edu} \\
			% \hspace*{9mm}\hfill
	Sachin Sapatnekar
			% \hfill \hyperlink{index}{\small {\em index}} \\
\end{center}
Stochastic techniques, namely random walks, have been used
to form linear equation solvers since the 1940s, but have
not been used effectively for preconditioning, to the best
of our knowledge. In this talk, we present a new stochastic
preconditioning approach: we prove that for symmetric
diagonally-dominant M-matrices, an incomplete LDL
factorization can be obtained from random walks, and used as
a preconditioner for an iterative solver, e.g., conjugate
gradient. The theory can be extended to general matrices
with nonzero diagonal entries.

The stochastic
preconditioning is performed by a random walk ``game''
defined as follows. Given a finite undirected connected
graph representing a street map, a walker starts from one of
the nodes, and goes to one of the adjacent nodes every day
with a certain probability. The walker pays an amount of
money, $m_i$ at node $i$, to a motel for lodging everyday,
until he/she reaches one of the homes, which are a subset of
the nodes. Then the journey is complete and he/she will be
rewarded a certain amount of money, $m_0$. The problem is to
determine the gain function:
$$
f(i)=E[\textrm{money earned }|
\textrm{walk starts at node }i]
$$
These gain values satisfy
the following linear equations:
\begin{eqnarray*} & &
f(i)=\sum_{j \in \textrm{neighbors of }i}{p_{i,j}f(j)}-m_i
\quad,\quad \forall i \nonumber \\
& & f(\textrm{a home node}) = m_0
\end{eqnarray*}
where $p_{i,j}$
is the transition probability of going from node $i$ to node
$j$, and note that $j$ can be a home node. Thus a random
walk game is mapped onto a system of linear equations.
Conversely, it can be verified that given
$A \mathbf{x} = \mathbf{b}$,
where $A$ is a symmetric diagonally-dominant
M-matrix, we can always construct a random walk game that is
mathematically equivalent, in which the set of $f$ values is
equal to the solution vector $\mathbf{x}$. To find the
$i^{\rm th}$ entry of $\mathbf{x}$, one may run a number of
walks from node $i$ and take the average of the results; to
get the complete solution, one may repeat the process for
every entry of $\mathbf{x}$. We alter this normal procedure
by adding the following rule: every calculated node becomes
a new home in the game with an award amount equal to its
calculated $f$ value. Without loss of generality, suppose
the nodes are in the natural ordering $1,2,\cdots,N$, then
for walks starting from node $i$, the node set
$\{1,2,\cdots,i-1\}$ are homes where walks terminate (in
addition to homes generated from the
strictly-diagonally-dominant rows of $A$), while the node
set $\{i,i+1,\cdots,N\}$ are motels where walks pass by.


Define the operator ${\rm rev}(\cdot)$ on square matrices
such that it reverses the ordering of the rows and reverses
the ordering of the columns: ${\rm
rev}(A)_{i,j}=A_{N+1-i,N+1-j} , \quad \forall i,j \in \{
1,2,\cdots,N \}$. Let the exact LDL factorization of ${\rm
rev}(A)$ be ${\rm rev}(A) = L_{{\rm rev}(A)} D_{{\rm
rev}(A)} \left( L_{{\rm rev}(A)} \right)^{\rm T}$. Again, in
the random walk game, assume that the nodes are in the
natural ordering $1,2,\cdots,N$, and that node $i$
corresponds to the $i^{\rm th}$ row of $A$. We prove the
following relations:
\begin{eqnarray*}
\left( L_{{\rm rev}(A)} \right)_{i,j} & \approx &
- \frac{M_{N+1-j,N+1-i}}{W_{N+1-j}}, \quad\forall i>j \\
\left( D_{{\rm rev}(A)} \right)_{i,i} & \approx &
\frac{W_{N+1-i} A_{N+1-i,N+1-i}} {J_{N+1-i}}
\end{eqnarray*}
where $W_k$ is the total number of walks that are carried
out from node $k$, $M_{k_1,k_2}$ is the number of walks that
start from node $k_1$ and end at $k_2$, and $J_{k}$ is the
number of times that the $W_k$ walks from node $k$ pass node
$k$ itself. These equations show that we can approximate an
LDL factorization by collecting information from random
walks. We further prove that if $\left( L_{{\rm rev}(A)}
\right)_{i,j} = 0$ then $M_{N+1-j,N+1-i} = 0$; in other
words, the nonzero pattern of the $L$ factor produced by
random walks is a subset of nonzero pattern of the exact
$L_{{\rm rev}(A)}$. Therefore, we conclude that an
incomplete LDL factorization can be obtained from random
walks.

We argue that the obtained incomplete LDL factors
have better quality, i.e., better accuracy-size tradeoffs,
than the incomplete Cholesky factor obtained by a
traditional method based on Gaussian elimination. Our
argument is based on the fact that each row in the $L$
factor is independently calculated and has no correlation
with the computation of other rows. Therefore we avoid the
error accumulation in traditional incomplete factorization
procedure.

We also discuss, by defining a new set of game
rules, how this theory can be extended to general matrices,
given that the diagonal entries are nonzero.

To evaluate
the proposed approach, a set of benchmark matrices are
generated by Y.~Saad's SPARSKIT by finite-difference
discretization of the 3D Laplace's equation
$\nabla^2 u = 0$
with Dirichlet boundary condition. The matrices
correspond to 3D grids with sizes
$50\times 50\times 50$,
$60\times 60\times 60$, up to
$100\times 100\times 100$, and a
right-hand-side vector with all entries being 1 is used with
each of them. We compare the proposed solver, i.e., random
walk preconditioned conjugate gradient, against ICCG with
ILU(0) and ICCG with ILUT. The complexity metric is the
number of double-precision multiplications needed at the
iterative solving stage, in order to converge with an error
tolerance of $10^{-6}$. The results show up to 2.1 times
speedup over ICCG, and a trend that the larger and denser a
matrix is, the more the proposed solver outperforms ICCG.

This talk is partially based on [1], and the
implementation is available to the public [2].

[1]
H.~Qian, S.~S.~Sapatnekar, {\em A hybrid linear equation
solver and its application in quadratic placement},
IEEE/ACM International Conference on Computer Aided
Design Digest of Technical Papers (2005) 905--909.

[2] H.~Qian, S.~S.~Sapatnekar,
{\em The Hybrid Linear Equation Solver Binary Release},
available at http://www.ece.umn.edu/users/qianhf/hybridsolver



	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\begin{center} \rule{6in}{1pt} \end{center}
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{center}
{\large			% \hypertarget{Rees}
{\bf Preconditioning primal-dual interior point methods for linear programming}}

	Timothy Rees \\
	Dept.~of Computer Science \\
	University of British Columbia, Vancouver BC CANADA V6T 1Z4 \\
	{\tt trees@cs.ubc.ca} \\
			% \hspace*{9mm}\hfill
	Chen Greif
			% \hfill \hyperlink{index}{\small {\em index}} \\
\end{center}
We investigate the application of a class of preconditioners
to the problem of solving the linear systems arising from
primal-dual interior point methods in linear and quadratic
programming.  The preconditioners have the attractive
property of improved eigenvalue clustering with increased
singularity of the (1,1) block of the saddle-point matrix.
We analyze spectral properties of the preconditioned matrix
utilizing projections onto the null space of the constraint
matrix.  We then present a practical application of the
preconditioners and study their performance on LP and QP
problems from the NETLIB and QPS test suites.


	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\begin{center} \rule{6in}{1pt} \end{center}
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{center}
{\large			% \hypertarget{Reese}
{\bf Simulating non-Darcy flow through porous media using Sundance}}

	Jill Reese \\
	243 Harrelson Hall, CB 8205 \\
	NCSU, Raleigh NC 27695 \\
	{\tt jpreese@ncsu.edu} \\
			% \hspace*{9mm}\hfill
	Kevin Long, C.~T.~Kelley, William G.~Gray, Cass T.~Miller
			% \hfill \hyperlink{index}{\small {\em index}} \\
\end{center}
A non-Darcy partial differential equation (PDE) model for
flow through porous media is presented. The focus is on the
numerical implementation of the model using Sandia National
Laboratories PDE simulation framework, Sundance. In
particular, the discussion will include the finite element
discretization and how parallelism is accomplished.



	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\begin{center} \rule{6in}{1pt} \end{center}
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\newpage

\begin{center}
{\large			% \hypertarget{Renaut}
{\bf Parameter decomposition for iteratively regularized \\
	Gauss-Newton solutions in optical tomography}}

	Rosemary Renaut \\
	Dept.~of Mathematics and Statistics \\
	Arizona State University,  Tempe AZ 85287-1804 \\
	{\tt renaut@asu.edu} \\
			% \hspace*{9mm}\hfill
	Taufiquar Khan, Alexandra Smirnova
			% \hfill \hyperlink{index}{\small {\em index}} \\
\end{center}
We extend evaluation of the iteratively regularized Gauss
Newton method for the solution of the parameter estimation
problem in Optical Tomography. The general problem of
optical tomography requires the estimation of the underlying
model parameters ${\mathbf q}$, for example the coefficient
of diffusion $D$ and the coefficient of absorption $\mu_a$,
(i.e. ${\mathbf q}=(D,\mu_a)^T$) that belong to a parameter
set $Q$. The conditioning of the problem with respect to
each parameter set is different. We investigate the use of
an alternating parameter decomposition approach for solution
of the nonlinear inverse problem with regularization.
Contrary to statements on the general nonlinear least
squares problem in standard references eg Bjorck 1996 , we
find that decomposition with respect to the parameter set
allows solution of the regularized problem with the use of
appropriately chosen weighting schemes.



	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\begin{center} \rule{6in}{1pt} \end{center}
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{center}
{\large			% \hypertarget{Rodriguez}
{\bf Krylov-Secant methods for estimating subsidence parameters \\
	in hydrocarbon reservoirs}}

	Adolfo Rodriguez \\
	Center for Subsurface Modeling \\
	The University of Texas,  Austin TX 78712 \\
	{\tt adolfo@ices.utexas.edu} \\
			% \hspace*{9mm}\hfill
	Hector Klie, Mary F.~Wheeler
			% \hfill \hyperlink{index}{\small {\em index}} \\
\end{center}
It is a well known fact that under primary fluid production
conditions, pore pressures of hydrocarbon reservoirs and
aquifers tend to decline. This decline may lead to severe
deformations inside and around the reservoir. The
deformation observed at the surface is known as subsidence
and can produce negative environmental effects as well as
damage to surface facilities and infrastructures. Positively
speaking, subsidence observations can be combined with
inverse algorithms in order to assess reservoir behavior and
detect non-depleted regions that may be subject to further
exploitation. The estimation of subsidence usually requires
the performance of flow simulations coupled to mechanical
deformation. These simulations are computationally intensive
and, for this reason, they are seldom performed.

In this
work we introduce a Krylov-secant inversion framework for
estimating the deformation produced as a consequence of pore
pressure reduction in the reservoir. The formulation is
based on a solution of the equilibrium equation where
perturbations due to pore pressure reduction and elastic
modulus contrasts are introduced. The resulting equation for
the strain is given in the form of the
Lippmann-Schwinger integral, i.e.,
$$
\qquad
\qquad
\qquad
\qquad
{\bf{e}}\left( {\bf{x}} \right)
= - \int\limits_\Omega
{\Gamma \left( {{\bf{x - x'}}} \right)}
\left\{ {\Delta {\bf{Ce}}\left( {{\bf{x'}}} \right)
- {\bf{\alpha }}\Delta p} \right\}d{\bf{x'}},
\qquad
\qquad
\qquad
\qquad
(1)
$$
where
$\Gamma \left( {{\bf{x - x'}}} \right)$
is the modified half space Green's function;
$\Delta\bf{C}$ is the elastic module contrast; $\Delta p$ is
the magnitude of the pore pressure drop; and $\alpha$ is the
Biot's poroelastic constant, assumed here to be a tensor.
Both $\Delta\bf{C}$ and $\Delta p$ are zero outside the
reservoir but can be functions of $\bf{x'}$. The integration
in (1) is performed over the reservoir domain.

A Born-type approximation is implemented, where the
total field is assumed to be the incident field by
analogy to electromagnetic theory.

Based on the discretization of
(1) the resulting inverse problem can be stated as
the minimization of the following mismatch functional:
$$
\qquad
\qquad
\qquad
\qquad
\qquad
\qquad
\qquad
\phi =\frac{1}{2} \|\hat{d}-d\|_W^2,
\qquad
\qquad
\qquad
\qquad
\qquad
\qquad
\qquad
(2)
$$
where $d$ and $\hat{d}\in C^n$
are the predicted and observed data vectors
respectively, and $W$ is a diagonal weighting matrix, based
on the inverse of the covariance of the measurements that
compensates for the noise present in the data. In the
problem addressed here, the observed data are the subsidence
observations at some points, while the predicted data vector
$d$ is determined through solution of the forward model
(1).
The minimization problem (2) is large
and ill-posed, especially in the event of high
heterogeneities and few measurements. To perform the
inversion, a Newton-Krylov procedure based on
Krylov-secant updates is proposed.

The Krylov-secant framework entails
a recycling or extrapolation of the Krylov information
generated for the solution of the current Jacobian equation
to perform a sequence of secant steps restricted to the
Krylov basis. In other words, the Newton step is recursively
composed with Broyden updates constrained to the reduced
Krylov subspace. This is repeated until no further decrease
of the nonlinear residual can be delivered, in which case a
new nonlinear step yielding another Jacobian system is
performed.

The proposed framework includes dynamic
control of linear tolerances (i.e., forcing terms),
preconditioning, and regularization to achieve both
efficiency and robustness. Furthermore, this approach may
optionally accommodate the latest deflation or augmented
Krylov basis strategies for further efficiency. The
framework has been previously applied for the solution of
several nonlinear PDEs under Newton-Krylov implementations,
but the present work explores further issues with respect to
inexact Gauss-Newton methods based on Krylov iterative
solutions such as LSQR.

Numerical experiments indicate
that the current approach is a viable option for performing
fast inversion implementations. Comparisons are made against
traditional quasi-Newton and gradient-based implementations.
It is concluded that the proposed approach has the potential
for application to electromagnetic, radar, seismic and
medical technologies.



	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\begin{center} \rule{6in}{1pt} \end{center}
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{center}
{\large			% \hypertarget{Rommes}
{\bf Computing dominant poles of transfer functions}}

	Joost Rommes \\
	Mathematical Institute, Utrecht University \\
	P.O.Box 80.010, 3508 TA Utrecht, The Netherlands \\
	http://www.math.uu.nl/people/rommes \\
	{\tt rommes@math.uu.nl} \\
			% \hspace*{9mm}\hfill
	Nelson Martins
			% \hfill \hyperlink{index}{\small {\em index}} \\
\end{center}
Recent work on power system
stability, controller design and electromagnetic transients
has used several advanced model reduction techniques.
Although these techniques, such as balanced truncation,
produce good results, they impose high computational costs
and hence are only applicable to moderately sized systems.
Modal model reduction is a cost-effective alternative for
large-scale systems, when only a fraction of the system pole
spectrum is controllable-observable for the transfer
function of interest. Modal reduction produces transfer
function modal equivalents from the knowledge of the
dominant poles and their corresponding residues. In this
talk a specialized eigenvalue method will be presented that
computes the most dominant poles and corresponding residues
of a SISO transfer function.

The transfer function of a
single input single output (SISO) system is defined as
$$
\qquad
\qquad
\qquad
\qquad
H(s) = \mathbf{c}^T (sI - A)^{-1}\mathbf{b} + d,
\qquad
\qquad
\qquad
\qquad
(1)
$$
where
$A\in\Reals^{n\times n}$,
$\mathbf{b},\mathbf{c}\in\Reals^n$, $d\in\Reals$ and
$I\in\Reals^{n\times n}$ is the identity
matrix and $s\in\Cplex$.
Without loss of generality, $d=0$ in
the following.

Let the eigenvalues (poles) of $A$ and the
corresponding right and left eigenvectors be given by the
triplets $(\lambda_j,\mathbf{x}_j,\mathbf{v}_j)$,
and let the right and
left eigenvectors be scaled so that
$\mathbf{v}_j^*\mathbf{x}_j=1$.
It is
assumed that $\mathbf{v}_j^*\mathbf{x}_k=0$ for $j\neq k$.
The transfer function $H(s)$ in equation (1)
can be expressed as a
sum of residues $R_j$ over first order poles:
$$
H(s) = \sum_{j=1}^n
\frac{R_j}{s - \lambda_j},
$$
where the residues $R_j$ are
$$
R_j = (\mathbf{x}_j^T\mathbf{c})(\mathbf{v}_j^*\mathbf{b}).
$$

A \textit{dominant} pole is a pole $\lambda_j$ that
corresponds to a residue $R_j$ with large magnitude
$|R_j| / |\mbox{Re}(\lambda_j)|$ , i.e.,
a pole that is well
observable and controllable in the transfer function. This
can also be observed from the corresponding Bode magnitude
plot of $H(s)$, where peaks occur at frequencies close to
the imaginary parts of the dominant poles of $H(s)$. An
approximation of $H(s)$ that consists of $k<n$ terms with
$|R_j|/|\mbox{Re}(\lambda_j)|$ above some value, determines
the effective transfer function behavior and is called the
transfer function modal equivalent:
$$ H_k(s) = \sum_{j=1}^k \frac{R_j}{s - \lambda_j}. $$
The problem of concern can now be formulated as:
\begin{quote}
Given a SISO linear, time invariant,
dynamical system
$(A,\mathbf{b},\mathbf{c},d)$,
compute $k\ll n$ dominant
poles $\lambda_j$ and the corresponding right and left
eigenvectors $\mathbf{x}_j$ and $\mathbf{v}_j$.
\end{quote}

The algorithm to be presented, called Subspace Accelerated
Dominant Pole Algorithm (SADPA) [1],
combines a Newton
algorithm [2]
with subspace
acceleration, a clever selection strategy and deflation to
efficiently compute the dominant poles and corresponding
residues. It can easily be extended to handle MIMO systems
as well [3].
The performance of the algorithm will be illustrated by
numerical examples of large scale power systems.

[1] J.~Rommes, N.~Martins, {\em Efficient computation
of transfer function dominant poles using subspace
acceleration}, UU Preprint (2005) 1340.

[2] N.~Martins, L.T.G.~Lima, H.J.C.P.~Pinto,
{\em Computing dominant poles of power system transfer
functions}, IEEE Trans.~Power Syst. {\bf 11}(1)
(1996) 162--170.

[3] J.~Rommes, N.~Martins,
{\em Efficient computation of multivariable transfer
function dominant poles using subspace acceleration},
UU Preprint (2006) 1344.



% 	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% 	\begin{center} \rule{6in}{1pt} \end{center}
% 	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% 
% \begin{center}
% {\large			% \hypertarget{Saad}
% {\bf MIQR: a multilevel incomplete QR preconditioner
% for large sparse least-squares problems}}
% 
% 	Yousef Saad \\
% 	Dept.~of Computer Science and Engineering \\
% 	University of Minnesota, 4-196 EE/CSci Building \\
% 	200 Union Street S.E., Minneapolis, MN 55455 \\
%         {\tt saad@cs.umn.edu} \\
%         Na Li
% \end{center}
% 
% We present a Multilevel Incomplete QR (MIQR) factorization
% for solving large sparse least-squares problems. The
% algorithm builds the factorization by exploiting structural
% orthogonality in general sparse matrices. At any given step,
% the algorithm finds an independent set of columns, i.e., a
% set of columns that have orthogonal patterns. The other
% columns are then block orthogonalized against columns of the
% independent set and the process is repeated recursively for
% a certain number of levels on these remaining columns. The
% final level matrix is processed with a standard QR or
% Incomplete QR factorization. Dropping strategies are
% employed throughout the levels in order to maintain a good
% level of sparsity. A few improvements to this basic scheme
% are explored. Among these is the relaxation of the
% requirement of independent sets of columns. Numerical tests
% are proposed which compare this scheme with the standard
% incomplete QR preconditioner, the robust incomplete
% factorization (RIF) preconditioner, and ARMS (on the normal
% equations).



	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\begin{center} \rule{6in}{1pt} \end{center}
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% \pdfbookmark[1]{S}{s}
\begin{center}
{\large			% \hypertarget{Salinger}
{\bf Space-time solution of large-scale PDE applications}}

	Andrew Salinger \\
	Sandia National Labs, PO Box 5800 \\
	MS-1111, Albuquerque NM 87185 \\
	{\tt agsalin@sandia.gov} \\
			% \hspace*{9mm}\hfill
	Daniel Dunalvy, Eric Phipps
			% \hfill \hyperlink{index}{\small {\em index}} \\
\end{center}
Software and algorithms are being developed to efficiently
formulate and solve transient PDE problems as ``steady''
problems in a space-time domain. In this way, sophisticated
design and analysis tools for steady problems, such as
continuation methods, can be brought to bear on transient
(and eventually periodic) problems. This new capability is
being developed in the Trilinos solver framework, and is
designed to present a simple interface to application codes.
The software allows for parallelism over both the space and
time domains.

The main hurdle to make this approach
viable is to be able to efficiently solve the very large
Jacobian matrix for very large the space-time system, with
its characteristic structure. We will present results for a
number of preconditioners and solution methods that we have
developed for this linear system. Numerical results for a
PDE reacting flow application will be presented. These
results will shed some light on the underlying question of
whether it can pay to parallelize the time domain.



	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\begin{center} \rule{6in}{1pt} \end{center}
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{center}
{\large			% \hypertarget{Sanders}
{\bf Adaptive smoothed aggregation multigrid for non-symmetric problems}}

	Geoffrey Sanders \\
	Dept.~of Applied Mathematics, 526 UCB \\
	University of Colorado, Boulder CO 80309-0526 \\
	{\tt sandersg@colorado.edu} \\
			% \hspace*{9mm}\hfill
	T.~Manteuffel, S.~McCormick, M.~Brezina, J.~Ruge
			% \hfill \hyperlink{index}{\small {\em index}} \\
\end{center}
The performance of the adaptive smooth aggregation multigrid
($\alpha$SA) algorithm suffers for non-symmetric problems. I
will present a non-symmetric version of the algorithm that
uses Kaczmarz iteration as a relaxation step and smoothed
aggregation of local right and left singular vectors to form
a hierarchy of coarse grid operators. Testing has been done
on one and two dimensional convection dominated
convection-diffusion. I will present the current results and
struggles of these tests. Expect some whining.



	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\begin{center} \rule{6in}{1pt} \end{center}
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{center}
{\large			% \hypertarget{Schenk}
{\bf On large scale diagonalization techniques for the \\
	Anderson model of localization}}

	Olaf Schenk \\
	Dept.~of Computer Science, University of Basel \\
	Klingelbergstrasse 50, CH-4056, Basel, Switzerland \\
	{\tt olaf.schenk@unibas.ch} \\
			% \hspace*{9mm}\hfill
	Matthias Bollhoefer, Rudolf Roemer
			% \hfill \hyperlink{index}{\small {\em index}} \\
\end{center}
One of the hardest challenges in modern eigenvalue
computation is the numerical solution of large-scale
eigenvalue problems, in particular those arising from
quantum physics such as the Anderson model of localization
[4]. Typically, these problems require the computation of
some interior eigenvalues and eigenvectors for systems which
have up to several million unknowns due to their high
spatial dimensions. Furthermore, their underlying structure
involves random perturbations of matrix elements which
invalidates simple preconditioning approaches.

We propose
an efficient preconditioning algorithm for this Anderson
model of localization [6]. The model requires the
computation of a few interior eigenvalues and their
associated eigenvectors for large scale, sparse, real and
symmetric indefinite matrices. Our preconditioning approach
for the associated shift-and-invert systems is based on
maximum weighted matchings [3,5] and algebraic multilevel,
inverse-based incomplete $LDL^T$ factorizations [1,2]. Our
numerical examples indicate that recent algebraic multilevel
preconditioning solvers can accelerative the computation of
the underlying large-scale eigenvalue problem by several
orders of magnitude compared with previous approaches [4,6].

[1]
M.~Bollh\"ofer and Y.~Saad,
{\em Multilevel preconditioners
constructed from inverse-based {ILU}s},
SIAM J.~Sci. Comp.,
to appear (2006).

[2]
M.~Bollh\"ofer and O.~Schenk,
{\em {I}{L}{U}{P}{A}{C}{K} volume 2.0 ---
preconditioning software package for
symmetrically structured problems} (May 2005).

[3]
I.~S.~Duff and S.~Pralet,
{\em Strategies for scaling and pivoting for
sparse symmetric indefinite problems},
Technical Report TR/PA/04/59,
CERFACS (2004).

[4]
U.~Elsner, V.~Mehrmann,
F.~Milde, R.~A.~{R\"{o}mer}, M.~Schreiber,
{\em The {Anderson} model of localization: a challenge
for modern eigenvalue methods},
SIAM J.~Sci. Comp.
{\bf 20} (1999) 2089--2102.

[5]
M.~Hagemann, O.~Schenk,
{\em Weighted matchings for the preconditioning
of symmetric indefinite linear systems},
SIAM J.~Sci. Comp.,
to appear (2006).

[6]
O.~Schenk, M.~Bollh\"ofer, R.~R\"omer,
{\em On Large Scale Diagonalization Techniques
For The {Anderson} Model Of Localization},
SIAM J.~Sci. Comp., to appear (2006).



	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\begin{center} \rule{6in}{1pt} \end{center}
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{center}
{\large			% \hypertarget{Schmidt}
{\bf Phenomenological comparison of different AMG approaches for \\
	the finite element analysis in surgery simulations}}

	Jens G.~Schmidt \\
	C\&C Research Labs, NEC Europe Ltd. \\
	Rathausallee 10 53757, Sankt Augustin, Germany \\
			% \hspace*{9mm}\hfill
	{\tt schmidt@ccrl-nece.de}
			% \hfill \hyperlink{index}{\small {\em index}} \\
\end{center}
We are dealing with the simulation of maxillo-facial
surgeries, especially with distraction osteogenesis. During
this treatment the surgeon cuts free the upper jaw
(maxilla), which is subsequently relocated into a new
position with a distraction device in the course of several
weeks. Our simulation tool is set up to predict the
displacements of the facial tissues during and after the
pulling process and is based on individual CT images of the
patient's head before treatment. Its purpose is to support
the surgeon in optimizing the treatment plan and avoiding
additional post operative plastic surgeries.

The input
data for the simulation task is generated by adding the
suggested cuts, the geometry of the distraction device and
the suggested forces to the CT data of the patient's head.
From these data we generate a Finite Element mesh of the
head and perform a Finite Element analysis of the
distraction process. In order to achieve sufficient accuracy
we have to resolve most of the geometrical features of the
human head, which leads to a large number of unknowns,
typically several millions. In addition to that the
computational costs are significantly increased by the
finite displacements which can only be properly approximated
by non-linear modeling. The resulting systems of equations
must be solved on high performance computing resources, such
as parallel or vector machines.

Focusing on the
efficiency of the Finit Element simulation, the linear
solver used to solve the arising systems of equations plays
the most crucial role. In our case standard solvers like
Krylov methods or ILU methods fail, as we will show in our
presentation. Therefore we will focus on the use of
Multigrid solvers.

But the complex geometry of the human
head in combination with large jumps of the material
parameters -- Young's modulus jumps about 5 orders of
magnitude between bone and soft tissues -- prevents standard
multigrid approaches to converge at a sufficient rate. In
theory they can be dramatically improved by computing the
``near null space'' of the systems, consisting of the all
quasi-rigid body modes, and treat it separately. But we will
show, that for our problems a basis of this space needs
approximately 10 times the memory of the linear system
itself, which rules out this approach.

In our
presentation we will demonstrate the performance of the only
two solvers we have found to work on our problems so far,
which are BoomerAMG from LLNL's HYPRE package and ML from
Sandia's Trilinos package. We will show the results of our
intensive parameter studies and discuss the extensibility of
our performance results for elasto-mechanical Finite Element
simulations in general.



	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\begin{center} \rule{6in}{1pt} \end{center}
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{center}
{\large			% \hypertarget{Sheehan}
{\bf Spatial multigrid for transport}}

	Brendan Sheehan \\
	Dept. of Applied Mathematics \\
	Univ. of Colorado, Boulder CO 80309-0526 \\
			% \hspace*{9mm}\hfill
	{\tt ulmo22@yahoo.com}
			% \hfill \hyperlink{index}{\small {\em index}} \\
\end{center}
A spatial multigrid algorithm for isotropic neutron
transport is presented in $x$-$y$ geometry. The problem is
discretized with discrete ordinates in angle and corner
balance finite differencing in space. Spatial smoothing is
accomplished by a four color block Jacobi relaxation, where
the diagonal blocks correspond to four cell blocks on the
spatial grid. A bilinear interpolation operator and its
transpose are used for the grid transfer operators.
Encouraging preliminary results are presented for
homogeneous domains. Heterogeneous domains are also
discussed, especially the case of a vacuum region surrounded
by a diffusive region.



	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\begin{center} \rule{6in}{1pt} \end{center}
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{center}
{\large			% \hypertarget{Shen}
{\bf A new stabilized formulation for the Stokes problem}}

	Jie Shen \\
	Dept.~of Mathematics, Purdue University \\
	West Lafayette IN 47907 \\
	{\tt shen@math.purdue.edu} \\
			% \hspace*{9mm}\hfill
	Jean-Luc Guermond, Hua Lin
			% \hfill \hyperlink{index}{\small {\em index}} \\
\end{center}
I shall introduce a new formulation for the Stokes problem,
stemming from the consistent splitting scheme for the
time-dependent Navier-Stokes equations introduced by
Guermond \& Shen (JCP, 2003). I shall present ample numerical
results, using spectral and finite element methods, to show
that the new formulation leads to positive definite systems
and does not require the usual inf-sup condition between the
discrete spaces for the velocity and pressure.



% 	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% 	\begin{center} \rule{6in}{1pt} \end{center}
% 	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% 
% \begin{center}
% {\large			% \hypertarget{Shestakov}
% {\bf Solution of the nonlinear multifrequency radiation
% diffusion equation in a multiphysics,
% high energy density, AMR code}}
% 
% 	Aleksei Shestakov \\
% 	Lawrence Livermore National Laboratory, POB 808, L-38 \\
% 	Livermore CA 94551 \\
%         {\tt shestakov1@llnl.gov}
% \end{center}
% 
% We describe a scheme to
% solve the multifrequency radiation diffusion equation
% which is intended for a
% multiphysics, high energy density computer code with
% adaptive mesh refinement (AMR). In our code, AMR is
% implemented by refining in both space and time [1].
% There may be several levels of refinement,
% which, going from fine to coarse, are nested within each
% other.
% 
% We time-advance as follows. Assume there are only
% two levels, one coarse, with domain $\Omega_c$ and boundary
% $\partial \Omega_c$, and one fine $\Omega_f$ with boundary $\partial \Omega_f$. Since the
% domains are nested, $\Omega_f \subseteq \Omega_c$. At the start of the
% time cycle, the equations are first updated on $\Omega_c$ using a
% timestep $\Delta t_c$, a process defined as a {\em level solve\/}
% on $\Omega_c$. If the spatial grid on $\Omega_f$ is a twofold
% refinement of that discretizing $\Omega_c$, we need two level
% solves on $\Omega_f$, each with timestep $\Delta t_c/2$, in order to
% bring the $\Omega_f$ solution up to the advanced coarse level
% time. Boundary conditions (BC) are required on $\partial \Omega_f$. On
% parts of $\partial \Omega_f$ which do not extend to the physical
% boundary, BC are obtained by interpolating the coarse grid
% solution.
% 
% For diffusion equations, e.g., $u_t = (D u_x)_x$,
% conventionally, one supplies Dirichlet data. This ensures
% that the coarse and fine grid solution is continuous across
% $\partial \Omega_f.$ However, the flux $-D u_x$ may be discontinuous,
% which is unacceptable since this results in a loss of
% conservation. To remedy the defect, after the level solves,
% the coarse and fine grid solutions are {\em synced.}
% One solves a related, nearly homogeneous, problem for
% corrections on the union of discretizations of $\Omega_f$ and
% $\Omega_c$. The sole non-homogeneity of the system for the
% corrections is the miss-match of the fluxes on $\partial \Omega_f$. When
% the corrections are added to the result of the level solves,
% one obtains a conservative solution, continuous and with
% continuous flux.
% 
% This paper describes the AMR
% implementation for the multigroup radiation diffusion and
% matter energy balance equations,
% \begin{eqnarray*}
% \qquad \qquad \qquad \qquad
% \partial_t u_g
% & = &
% \nabla \cdot D_g \nabla u_g + \kappa_g \, ( \, B_g - u_g \, )
% \, , \;\; g = 1, \, \ldots, \, G
% \qquad \qquad \qquad \qquad (1)
% \\
% \rho \, c_v \partial_t T
% & = &
% - \sum_{k=1}^G
% \Delta_k \, \kappa_k \, ( \, B_k - u_k \, ) \, .
% \qquad \qquad \qquad \qquad (2)
% \end{eqnarray*}
% In
% equations (1-2),
% $u_g$ is the radiation energy density of the $g$th
% {\em group}.
% Groups arise by discretizing the frequency domain
% $0 \leq \nu \leq \infty$ into $G$ intervals.
% In equations (1-2),
% $D_g$ and $\kappa_g$ are the
% diffusion and coupling coefficients, $B_g$ is the Planck
% function, $\rho$ the mass density, $c_v$ the specific heat,
% and $\Delta_k = \nu_k - \nu_{k-1}$. The system is nonlinear;
% $D_g$ and $\kappa_g$, which in addition to being strong
% functions of frequency, depend on $\rho$ and $T$. For
% non-ideal gases, $c_v$ depends on $\rho$ and $T$.
% Equations (1-2)
% describe the evolution of
% the $G+1$ unknowns $\{u_k\}_{k=1}^G$ and $T$.
% 
% A single level solve of
% equations (1-2)
% is a formidable task
% in itself. For the advance, we use the procedure described
% by Shestakov [3], generalized for ``real,'' multiple
% materials whose properties ($c_v$, $k_g$, etc.) are given in
% tabular form.
% 
% For simulations using AMR, after advancing
% on two levels, $\Omega_c$ and $\Omega_f$, the solutions are synced
% using a generalization of the Howell and Greenough procedure
% (HG) [1], which may be directly applied to
% equations (1-2)
% if $G = 1$. However, if $G > 1$,
% the situation is more complicated since the energies $u_g$
% are coupled. We resolve the difficulty by applying concepts
% of the ``Partial Temperature'' scheme (PT) of Lund and
% Wilson [2]. As in PT, we cycle through the groups
% in random order. Each group is synced as in HG, but the
% correction to $T$ is only a partial change. Only after all
% the groups have been addressed, do we obtain the final
% correction.
% 
% Our AMR procedure is implemented in a
% multiphysics code. Results will be presented. We simulate
% effects of strong explosions in air and compare multigroup
% results with runs where the frequency domain is not
% discretized, so-called gray diffusion. The simulations also
% use the hydro and heat conduction modules. In addition to
% the coarse level, there are two levels of refinement.
% 
% [1]
% L.~H.~Howell and J.~A.~Greenough,
% J.~Comp. Phys. {\bf 184}(1) (2003)
% 53--78.
% 
% [2]
% C.~M.~Lund and J.~R.~Wilson,
% Lawrence Livermore Natl. Lab. report UCRL-84678,
% July 29, 1980.
% 
% [3]
% A.~I.~Shestakov,
% {\em 8th Copper Mountain Conference on Iterative Methods},
% March 2004.



	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\begin{center} \rule{6in}{1pt} \end{center}
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{center}
{\large			% \hypertarget{Shi}
{\bf A large scale nonlinear finite element solver algorithm \\
	with optimal speed and robustness}}

	Peter L.~Shi \\
	Dept of Math and Statistics \\
	Oakland University, Rochester MI 48323 \\
			% \hspace*{9mm}\hfill
	{\tt pshi@oakland.edu}
			% \hfill \hyperlink{index}{\small {\em index}} \\
\end{center}
The speaker will present a new theory, the related
algorithmic and programming architecture for solving
nonlinear boundary value problems with {\it optimal speed
and robustness} by using large numbers of finite elements.

The new methodology will achieve the desired optimality
over a singularly large spectrum of nonlinear finite element
models on bounded domains of $R^n$ with $n=2$ and $n=3$.
For example,
the algorithm will cover the Galerkin formulation
of well-posed nonlinear elliptic systems whose principle
part is Lipschitz continuous and strongly monotone in a
Sobolev space and certain problems that lack unique
solutions such as stationary Navier-Stokes equations. Large
variations of stiffness will also be permitted in both
magnitude and frequency.

The merit of the new algorithm
is not only its speed and scope, but also its mathematically
rigorous theory, the elegance in algorithmic design, and
simplicity in implementation. The approach will be based on
the proven success of the speaker's long time effort
starting from early 1990s, recently reported in [1],
which successfully establishes the corresponding
result for second order {\it quasi-linear} elliptic systems
with non-negative lower order terms.

Central to the
algorithm, the speaker will reformulate a finite element
model by generalized Wiener-Hopf equations. This will make
element-wise conditioning an inexpensive process, whereby
reducing the solution procedure to the straightforward
Banach contraction mapping principle: given $f$, $y_0$ and
$m$, compute
$$ y_{k+1} = (I-R^* T R) y_k+ R^*f,
\qquad k=0,1,2\dots m. $$
Here the operator $I- R^* T R$ is
strictly contractive with the contraction constant
independent of the number of unknowns in the system; $T$ is
a scaled direct sum of the local stiffness operators; $R$
and $R^*$ are linear operators conjugate to each other, and
$I$ is the identity mapping. Computing $Ry$ and $R^* y^*$ for
arbitrary $y$ and $y^*$ is equivalent to solving a linear
system defined by a fixed class of sparse $M$-matrices and
their close variants, which can be accomplished by algebraic
multi-grid method (AMG) in linear computational count.

For a
large class of practical problems, they can also be
accomplished by a variety of other linear solver techniques,
showing the robustness of the algorithm. From the numerical
point of view, $R$ and $R^*$ are optimal conditioners of $T$
in terms of cost, efficiency and robustness. They depend
only on a discrete function space modulo the kernel of an
appropriate linear analog of $T$. Throughout the algorithmic
design and analysis, non-traditional tools such as
topological spaces and discrete measures will be
systematically deployed for representing and handling the
data structure. This is another novelty of the speaker's
approach from the standard methodology.

The speaker's
new approach is related neither to Newton-Krylov method and
its variants, nor to FAS. At the philosophical level, it is
a natural extension of AMG to its fully nonlinear analog
without using FAS. It can also be viewed as an extreme
exercise of the {\it finite element tearing and
inter-connection} (FETI) philosophy coupled with a novel
treatment of degrees of freedom.

[1]
P.~Shi, {\em Foundation of nonlinear finite element
solvers, Part I}, Advances in Computational Mathematics,
submitted August 2005, 95 pages.


	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\begin{center} \rule{6in}{1pt} \end{center}
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{center}
{\large			% \hypertarget{Shuttleworth}
{\bf A comparison of parallel block multi-level preconditioners for \\
	the incompressible Navier-Stokes equations}}

	Robert Shuttleworth \\
	Applied Mathematics and Scientific Computing Program \\
	University of Maryland, College Park MD 20742 \\
			% \hspace*{9mm}\hfill
	{\tt rshuttle@math.umd.edu}
			% \hfill \hyperlink{index}{\small {\em index}} \\
\end{center}
Over the past several years, considerable effort has been
placed on developing efficient solution algorithms for the
incompressible Navier-Stokes equations. The effectiveness of
these methods requires that the solution techniques for the
linear subproblems generated by these algorithms exhibit
robust and rapid convergence; These methods should be
insensitive to problem parameters such as mesh size and
Reynolds number. This study concerns a preconditioner
derived from a block factorization of the coefficient matrix
generated in a Newton nonlinear iteration for the primitive
variable formulation of the system. This preconditioner is
based on the approximation of the Schur complement operator
using a technique proposed by Kay, Loghin, and Wathen [1]
and Silvester, Elman, Kay, and Wathen [2]. It is derived
using subsidiary computations (solutions of pressure Poisson
and convection-diffusion-like subproblems) that are
significantly easier to solve than the entire coupled
system, and a solver can be built using tools, such as
smooth aggregation multigrid for the subproblems.

We discuss
a computational study performed using MPSalsa, a stabilized
finite element code, in which parallel versions of these
preconditioners from the pressure convection-diffusion
preconditioners are compared with an overlapping Schwarz
domain decomposition preconditioner.  Our results show
nearly ideal convergence rates for a wide range of Reynolds
numbers on two-dimensional problems with both enclosed and
in/out flow boundary conditions on both structured and
unstructured meshes.

[1] D.~Kay, D.~Loghin, and A.~J.~Wathen,
{\em A preconditioner for the steady-state
Navier-Stokes equations},
SIAM J.~on Sci. Comp. {\bf 24} (2002) 237--256.

[2] D.~Silvester, H.~Elman, D.~Kay, A.~Wathen,
{\em Efficient preconditioning of the linearized
Navier-Stokes equations for incompressible flow},
J.~Comp. Appl. Math. {\bf 128} (2001) 261--279.


	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\begin{center} \rule{6in}{1pt} \end{center}
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{center}
{\large			% \hypertarget{Silvester}
{\bf Least squares preconditioners for stabilized mixed \\
	approximation of the Navier-Stokes equations}}

	David Silvester \\
	School of Mathematics, University of Manchester \\
	Manchester M60 1QD, UK \\
	{\tt d.silvester@manchester.ac.uk} \\
			% \hspace*{9mm}\hfill
	Howard Elman, Victoria Howle, John Shadid, Ray Tuminaro
			% \hfill \hyperlink{index}{\small {\em index}} \\
\end{center}
We consider the Navier--Stokes equations
$$
\qquad
\qquad
\qquad
\begin{array}{rcl} -\nu \nabla^2 {\bf u} + ({\bf
u} \cdot {\rm grad})\, {\bf u} + {\rm grad}\, p &= &{\bf f}
\\ -{\rm div}\, {\bf u} &= &0 \end{array}
\qquad
\qquad
\qquad
(1)
$$
on
$\Omega \subset \mathbb{R}^d$, $d=2$ or $3$.
Here, ${\bf u}$
is the $d$-dimensional velocity field, which is assumed to
satisfy suitable boundary conditions on $\partial \Omega$,
$p$ is the pressure, and $\nu$ is the kinematic viscosity,
which is inversely proportional to the Reynolds number.

Linearization and discretization of (1) by finite
elements, finite differences or finite volumes leads to a
sequence of linear systems of equations of the form
$$
\qquad
\qquad
\qquad
\left[
\begin{array}{lc} F & \ B^T \\ B & -\frac{1}{\nu}C
\end{array} \right] \begin{bmatrix} {\bf u}\\ p
\end{bmatrix} = \begin{bmatrix} {\bf f}\\ g \end{bmatrix}.
\qquad
\qquad
\qquad
(2)
$$
These systems, which are the focus of this
talk, must be solved at each step of a nonlinear (Picard or
Newton) iteration. Here, $B$ and $B^T$ are matrices
corresponding to discrete divergence and gradient operators,
respectively and $F$ operates on the discrete velocity
space. For {\em div-stable} discretizations, $C=0$. For
mixed approximation methods that do not uniformly satisfy a
discrete inf-sup condition, the matrix $C$ is a nonzero {\em
stabilization operator}. Examples of finite element methods
that require stabilization are the mixed approximations
using linear or bilinear velocities (trilinear in
three dimensions) coupled with constant pressures, as well
as any discretization in which equal order discrete
velocities and pressures are specified using a common set of
nodes.

The focus of this talk is the Least Squares
Commutator (LSC) preconditioner developed by Elman, Howle,
Shadid, Shuttleworth and Tuminaro, and unveiled at the
Copper Mountain Conference in 2004. This preconditioning
methodology is one of several choices that are effective for
Navier-Stokes equations, and it has the advantage of being
defined from strictly algebraic considerations. The
resulting preconditioning methodology is competitive with
the pressure convection-diffusion preconditioner of Kay,
Loghin and Wathen, and in some cases its performance is
superior. However, the LSC approach has so far only been
shown to be applicable to the case where $C=0$ in
(2). In this talk we show
that the least squares commutator preconditioner can be
extended to cover the case of mixed approximation that
require stabilization. This closes a gap in the derivation
of these ideas, and a version of the method can be also
formulated from algebraic considerations, which enables the
fully automated algebraic construction of effective
preconditioners for the Navier-Stokes equations by
essentially using only properties of the matrices in
(2).

Our focus in this
work is on steady flow problems although the ideas discussed
generalize in a straightforward manner to unsteady flow.


	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\begin{center} \rule{6in}{1pt} \end{center}
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{center}
{\large			% \hypertarget{Simonis}
{\bf Inexact Newton methods for underdetermined systems}}

	Joseph Simonis \\
	82 Parker Ave,  Holden MA 01520 \\
			% \hspace*{9mm}\hfill
	{\tt jpsimoni@wpi.edu}
			% \hfill \hyperlink{index}{\small {\em index}} \\
\end{center}
Extending Newton's method to solving $F(x)=0,$ where
$F:\Reals^m\rightarrow\Reals^n$ is continuously
differentiable and $m>n$, requires solving an
underdetermined linear system for the Newton step at each
iteration. When the step is the pseudo-inverse solution, the
resulting method is sometimes called the normal flow method.
Like Newton's method, it usually is easy to implement, has a
simple and useful local convergence theory and, in its pure
form, is not well suited for solving large-scale problems.
In this talk I will present variations of the normal flow
method analogous to inexact Newton methods and globalized
inexact Newton methods. These methods have been developed to
improve the robustness and efficiency of the normal flow
method on large-scale problems. Preliminary computational
results on some simple problems will be presented. This work
was done in collaboration with my advisor Homer Walker at
Worcester Polytechnic Institute.



% 	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% 	\begin{center} \rule{6in}{1pt} \end{center}
% 	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% 
% \begin{center}
% {\large			% \hypertarget{Smirnova}
% {\bf A family of generalized Gauss-Newton methods for 2D inverse \\
% 	gravimetry problem}}
% 
% 	Alexandra Smirnova \\
% 	Dept. of Mathematics and Statistics \\
% 	Georgia State University, 30 Pryor St.,  Atlanta GA 30303 \\
% 			% \hspace*{9mm}\hfill
% 	{\tt smirn@mathstat.gsu.edu}
% 			% \hfill \hyperlink{index}{\small {\em index}} \\
% \end{center}
% We consider a generalized Gauss-Newton's scheme
% $$ x_{n+1}=\xi-\theta(F^{\prime*}(x_n)F'(x_n),\alpha_n)
% F^{\prime*}(x_n)\{F(x_n)-f-F'(x_n)(x_n-\xi)\} $$ for
% solving nonlinear unstable operator equation
% $\,F(x)=f\,$ in a Hilbert space. In case of noisy data
% we propose a novel a posteriori stopping rule $$
% ||F(x_N)-f_\delta||^2\le \tau \delta <
% ||F(x_n)-f_\delta||^2,\quad 0\le n< N,\quad
% \tau >1, $$
% and
% prove a convergence theorem under a source type
% condition on the solution. As a consequence of this
% theorem we obtain convergence rates for five different
% generating functions,
% $\,\theta=\theta(\lambda,\alpha),\,$ of a spectral
% parameter $\lambda$ and $\alpha>0$.
% 
% The new algorithms are tested on the 2D inverse
% gravimetry problem reduced to a nonlinear integral
% equation of the first kind: $$ F(x):=g \,\triangle
% \sigma \int^b_a\int^d_c\left\{
% \frac{1}{[\,(\xi-t)^2+(\nu-s)^2+x^2(\xi,\nu)\,]^{1/2}}
% \right.  \\ \left.  -
% \frac{1}{[\,(\xi-t)^2+(\nu-s)^2+h^2\,]^{1/2}}
% \right\}\,d\xi\,d\nu = f(t,s), $$ where $g$ is the
% gravitational constant, $\triangle \sigma$ is the
% density jump on the interface, and $f(t,s)$ is the
% gravitational strength anomaly.  The results of
% numerical simulations are presented and some practical
% recommendations on the choice of parameters are given.



	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\begin{center} \rule{6in}{1pt} \end{center}
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{center}
{\large			% \hypertarget{Sosonkina}
{\bf Iterative solution techniques for flexible approximation schemes \\
	in multiparticle simulations}}

	Masha Sosonkina \\
	Ames Laboratory DOE, 236 Wilhelm Hall \\
	Ames IA 50011 \\
	{\tt masha@scl.ameslab.gov} \\
			% \hspace*{9mm}\hfill
	Igor Tsukerman, Elena Ivanova, Sergey Voskoboynikov
			% \hfill \hyperlink{index}{\small {\em index}} \\
\end{center}
The paper examines various parallel iterative solvers
for the new Flexible Local Approximation MEthod (FLAME)
[5,6] applied to colloidal
systems. The electrostatic potential in such  systems
can be described, at least for monovalent salts in the
solvent, by the Poisson-Boltzmann equation
(see, e.g., [2]).
Classical Finite-Difference (FD)
schemes would require unreasonably fine meshes to
represent the boundaries of multiple spherical
particles at arbitrary locations with sufficient
accuracy. In the Finite Element Method, mesh generation
for a large number of particles becomes impractical.
The Fast Multipole Method works well only if the
particle sizes are neglected and the Poisson-Boltzmann
equation is linearized [1].  Classical
FD schemes rely on Taylor expansions that break down
near material interfaces (such as particle boundaries)
due to the lack of smoothness  of the field. In FLAME,
Taylor expansions in the vicinity of the particles  are
replaced with much more accurate approximations.
Namely, the local FLAME bases are constructed by
matching (via the boundary conditions) the spherical
harmonics for the electrostatic potential inside and
outside the particle;
see [5,6] for details.

The system matrices of FLAME and classical FD have the
same sparsity structure for the same grid stencil on a
regular Cartesian grid; for example, the standard
seven-point stencil leads to a seven-diagonal matrix.
However, the FLAME matrix is generally nonsymmetric.
Several parallel iterative solution techniques have
been tested with an emphasis on suitable parallel
preconditioning for the nonsymmetric system matrix. In
particular, flexible GMRES [3]
preconditioned with the distributed Schur Complement
[4] has been considered and
compared with Additive Schwarz and global incomplete
ILU(0) preconditionings.  It has been observed that
Schur Complement preconditioning with a small amount of
fill and a few inner iterations scales well and
exhibits good solution times while attaining almost
linear speedup. The number of iterations and the
computational time depends only mildly on the Debye
parameter of the electrolyte.

[1]
L.~F.~Greengard, J.~Huang,
{\em A new version of the {Fast Multipole Method}
for screened {Coulomb} interactions in three
dimensions}, J.~Comput. Phys. {\bf 180}(23)
(2002) 642--658.

[2]
A.~Yu.~Grosberg, T.~T.~Nguyen, B.~I.~Shklovskii,
{\em Colloquium: The physics of charge inversion
in chemical and biological systems},
Reviews of Modern Physics {\bf 74}(2)
(2002) 329--345.

[3]
Y.~Saad, {\em Iterative Methods for Sparse Linear
Systems, 2nd edition}, SIAM (2002) Philadelphia PA.

[4]
Y.~Saad, M.~Sosonkina, {\em Distributed
{Schur Complement} techniques for general sparse
linear systems}, SIAM J.~Sci. Comp. {\bf 21}(4)
(1999) 1337--1356.

[5]
I.~Tsukerman, {\em Electromagnetic applications
of a new finite-difference calculus},
IEEE Trans. Magn. {\bf 41}(7) (2005) 2206--2225.

[6]
I.~Tsukerman, {\em A class of difference schemes with
flexible local approximation}, J.~Comp. Phys.
{\bf 211}(2) (2006) 659--699.



	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\begin{center} \rule{6in}{1pt} \end{center}
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\begin{center}
{\large			% \hypertarget{Stathopoulos}
{\bf PRIMME: PReconditioned Iterative MultiMethod Eigensolver; \\
	a robust, efficient and flexible Hermitian eigenvalue software}}

	Andreas Stathopoulos \\
	Dept.~of Computer Science, College of William and Mary \\
	Williamsburg VA 23187-8795 \\
	{\tt andreas@cs.wm.edu} \\
			% \hspace*{9mm}\hfill
	James McCombs
			% \hfill \hyperlink{index}{\small {\em index}} \\
\end{center}
The numerical solution of large, sparse, hermitian
eigenvalue problems continues to be one of the most
computationally intensive tasks. Iterative eigensolvers are
routinely called to solve for a large number of eigenvalues
of matrices with dimension of excess of a million. As with
linear systems of equations, large dimensions almost always
necessitate the use of preconditioning. In addition,
eigensolvers must also deal with the issue of storing and
orthogonalizing an increasingly large set of eigenvectors.

In recent years, many preconditioned eigensolvers have
emerged that perform well in many, but not all applications.
Notable examples are the many variants of the
Jacobi-Davidson method (JDQR, JDCG, JDQMR), the
Generalized-Davidson+1 method, and the LOBPCG method, while
variations of the traditional RQI and Inverse Iteration
methods are still in use. Until recently, however, general
purpose software that implements these methods both
efficiently and robustly has been very scarce. As a result,
application developers could not compare the various
algorithms to find the most suitable for their application
and computing environment. Often, they would develop
in-house implementations of algorithms specifically tuned
for their application. Such in-house approaches, however,
cannot benefit from current advances in eigenvalue research.
Such flexibility in choosing from a variety of methods is
missing in todays software.

In some cases of existing
software, robustness has taken a secondary role behind
efficiency. Ideally, an eigensolver should find all the
required eigenvalues, in the shortest possible time, and
produce an orthonormal basis for their invariant space. It
is well known, that iterative eigensolvers cannot guarantee
that eigenvalues are not missed. However, certain
algorithmic techniques can increase the confidence in the
computed results, albeit at a higher computational cost.
This increased confidence is sometimes needed in
applications.

Although some of the above eigenvalue
methods have been shown to provide nearly optimal
convergence for one eigenvalue in terms of matrix-vector
operations, the question of efficiency is a much more
complex issue. Actual execution times depend on the
computing platform (hardware, compiler, libraries), on the
number of eigenvalues required, on the quality of the
preconditioner, and often on the problem solved. Block
methods have become a prerequisite for good cache
performance, yet maintaining good convergence with a large
block size is not straightforward. In addition, there is a
multitude of techniques for restarting, locking, stopping
inner-outer iterations, that when properly implemented can
significantly improve the efficiency of the eigensolvers.


In view of the above, our group has developed a robust,
efficient multi-method software called PRIMME. PRIMME is
based on a Davidson-type main iteration, but it implements
various techniques such block, locking, various projections
for preconditioning (e.g., Olsen's, Jacobi-Davidson, etc),
CG-type restarting (giving rise to JD+1, and LOBPCG-type
methods), and adaptive inner-outer iterations (allowing for
JDQMR/JDCG or inexact Inverse Iteration type methods). The
implementation of all these techniques on top of a common
platform, allows PRIMME to transform to any of the above
state-of-the-art eigenvalue methods, as well as to hybrids
representing arbitrary combinations of techniques.

More
than thirty features are controllable and tunable by the
user. However, this flexibility is not at the expense of
usability. A complete set of defaults is provided, and the
user can simply select from a list of twelve predefined
methods. Alternatively, a method selection can be further
tuned by resetting particular features. Such a multi-layer
transparency addresses the different levels of expertise of
potential users, from end-users to eigenvalue experts.


Robustness decisions are prevalent in various implementation
details of PRIMME, such as multiple levels of convergence
checking, validation processes, out of order convergence of
required eigenvalues, especially interior eigenvalues, and
consideration of numerical error. In cases where a choice
between robustness and efficiency has to be made, PRIMME
favors robustness by default, but it still implements the
efficient approach as a user-defined alternative.

Finally, the software runs both on parallel and sequential
machines and can use the optimized BLAS and LAPACK libraries
of the target machines. Additionally, the structure of
PRIMME allows for a runtime capability of sensing both the
computing environment and the problem solved, and adapting
the choice of parameters accordingly. The potential of such
a fully dynamic multi-method is a particular focus of our
current research.

In this talk, we present an overview of
PRIMME and its interface, and show some sample numerical
results that demonstrate its robustness and efficiency. In
particular, we show that JDQMR and GD+1, two of the
supported methods, provide minimal execution time and number
of iterations respectively to a number of applications. The
hope is that the choice between the two can be fully
automated within PRIMME. Finally, we show a surprising
result that for cases where a preconditioner is not
available, block JDQMR can be substantially better than
ARPACK, even for large numbers of eigenvalues. 

The software is freely available under the
lesser GPL license at
\verb8http://www.cs.wm.edu/~andreas/software/8.



	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\begin{center} \rule{6in}{1pt} \end{center}
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\newpage

\begin{center}
{\large			% \hypertarget{Sturler}
{\bf The convergence of Krylov subspaces methods with recycling}}

	Eric de Sturler \\
	Department of Mathematics, 460 McBryde \\
	Virginia Tech, Blacksburg VA 24061-0123 \\
	{\tt sturler@vt.edu} \\
			% \hspace*{9mm}\hfill
	Michael L.~Parks
			% \hfill \hyperlink{index}{\small {\em index}} \\
\end{center}
Many problems in science and engineering require the
solution of a long sequence of linear systems, with small
changes from one matrix to the next but substantial changes
over multiple systems.  We are particularly interested in
cases where both the matrix and the right hand side change
and systems are not available simultaneously.  Such
sequences arise in time-dependent iterations, nonlinear
systems of equations and optimization, (distributed)
parameter identification and inverse problems, and many
other problems.

In recent papers [1,2,3] we have proposed methods to
recycle selected subspaces from the Krylov spaces generated
for previous linear systems to improve the convergence of
subsequent linear systems.  In this presentation, we
discuss several important convergence issues:
\begin{itemize}
\item the convergence of Krylov methods
that recycle approximate solution spaces, approximate
invariant subspaces, and other relevant spaces,
\item the relevant perturbation theory for the spaces
mentioned above for sequences of matrices arising in a
range of applications,
\item how fast our proposed methods learn to adapt to a
changing problem.
\end{itemize}
We provide experimental
results for a range of problems from tomography, nonlinear
mechanics, large-scale design optimization, and statistical
mechanics.

[1] Michael L. Parks, Eric de Sturler, Greg Mackey, Duane
D. Johnson, and Spandan Maiti,
{\em Recycling Krylov Subspaces for Sequences of Linear
Systems}, SIAM Journal on Scientific Computing
(accepted with minor revisions), 2006, available as
Tech. Report UIUCDCS-R-2004-2421, March 2004, from
\verb9http://www-faculty.cs.uiuc.edu/~sturler9.

[2]
Misha Kilmer and Eric de Sturler,
{\em Recycling Subspace Information for Diffuse Optical Tomography},
SIAM Journal on Scientific Computing (accepted for publication),
2006, available from
\verb9http://www-faculty.cs.uiuc.edu/~sturler9.

[3]
Shun Wang, Eric de Sturler, and Glaucio H. Paulino,
{\em Large-Scale Topology Optimization using Preconditioned
Krylov Subspace Methods with Recycling},
International Journal for Numerical Methods in
Engineering (submitted), 2006,
available as Technical Report UIUCDCS-R-2006-2678
from
\verb9http://www-faculty.cs.uiuc.edu/~sturler9.


	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\begin{center} \rule{6in}{1pt} \end{center}
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{center}
{\large			% \hypertarget{Szyld}
{\bf Optimal additive Schwarz preconditioning for minimal residual \\
	methods with Euclidean and energy norms}}

	Daniel B Szyld \\
	Dept.~of Mathematics (038-16) \\
	Temple University, 1805 N Broad Street \\
	Philadelphia PA 19122-6094 \\
	{\tt szyd@temple.edu} \\
			% \hspace*{9mm}\hfill
	Marcus Sarkis
			% \hfill \hyperlink{index}{\small {\em index}} \\
\end{center}
For the solution of non-symmetric or indefinite linear
systems arising from discretizations of elliptic problems,
two-level additive Schwarz preconditioners are known to be
optimal in the sense that convergence bounds for the
preconditioned problem are independent of the mesh and the
number of subdomains. These bounds are based on some kind of
{\em energy norm}. However, in practice, iterative methods
which minimize the Euclidean norm of the residual are used,
despite the fact that the usual bounds are non-optimal,
i.e., the quantities appearing in the bounds may depend on
the mesh size; see [1].
In this paper,
iterative methods are presented which minimize the same
energy norm in which the optimal Schwarz bounds are derived,
thus maintaining the Schwarz optimality. As a consequence,
bounds for the Euclidean norm minimization are also derived,
thus providing a theoretical justification for the practical
use of Euclidean norm minimization methods preconditioned
with additive Schwarz. Both left and right preconditioners
are considered, and relations between them are derived.
Numerical experiments illustrate the theoretical
developments.

[1] X.-C.~Cai, J.~Zou,
Numer. Linear Algebra Appl. {\bf 9} (2002) 379--397.



	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\begin{center} \rule{6in}{1pt} \end{center}
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% \pdfbookmark[1]{T-V}{t-v}
\begin{center}
{\large			% \hypertarget{Tang}
{\bf A novel deflation method to solve the 3-D discontinuous \\
	and singular Poisson equation}}

	Jok M.~Tang \\
	Dept.~of Applied Mathematical Analysis \\
	Delft University of Technology \\
	Mekelweg 4, 2628 CD Delft, The Netherlands \\ 
			% \hspace*{9mm}\hfill
	{\tt j.m.tang@ewi.tudelft.nl}
			% \hfill \hyperlink{index}{\small {\em index}} \\
\end{center}
Recently, simulating bubbly flows is a very popular topic in
CFD. These bubbly flows are governed by the Navier-Stokes
equations. In many popular operator splitting formulations
for these equations, solving the linear system coming from
the discontinuous Poisson equation takes the most
computational time, despite of its elliptic origins. ICCG is
widely used for this purpose, but for complex bubbly flows
this method shows slow convergence.

Moreover, new insights are given into the properties of
invertible and singular deflated and preconditioned linear
systems, where the coefficient matrices are symmetric and
positive (semi-) definite. These linear systems can be
derived from a discretization of the Poisson equation with
Neumann boundary conditions. Sometimes these linear systems
are forced to be invertible leading to a worse (effective)
condition number. If ICCG is used to solve this problem, the
convergence is significantly slower than for the case of the
original singular problem.

We show that applying the deflation technique, which leads
to the DICCG method, remedies the worse condition number and
the worse convergence of ICCG. Moreover, some useful
equalities are derived from the deflated variants of the
singular and invertible matrices, which are also generalized
to preconditioned methods. It appears that solving the
invertible and singular linear systems with DICCG leads to
exactly the same convergence results.

This new method DICCG incorporates the eigenmodes
corresponding to the components which caused the slow
convergence of ICCG. Coarse linear systems have to be solved
within DICCG. We discuss some methods to do this efficiently
which results in two approaches DICCG1 and DICCG2.

Thereafter we show with numerical experiments that both DICCG
approaches are very efficient and they emphasize also the
theoretical results. Compared to ICCG, DICCG decreases
significantly the number of iterations and the computational
time as well which are required for solving Poisson equation
in applications of 2-D and 3-D bubbly flows.



	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\begin{center} \rule{6in}{1pt} \end{center}
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{center}
{\large			% \hypertarget{Thornquist}
{\bf Fixed-polynomial approximate spectral transformations for \\
	preconditioning the eigenvalue problem}}

	Heidi K.~Thornquist \\
	Sandia National Laboratories, P.O.~Box 5800, MS 0316 \\
	Albuquerque NM 87185-0316 \\
	{\tt hkthorn@sandia.gov} \\
			% \hspace*{9mm}\hfill
	Danny C.~Sorensen
			% \hfill \hyperlink{index}{\small {\em index}} \\
\end{center}
Arnoldi's method is often used to compute a few eigenvalues
and eigenvectors of large, sparse matrices. When the
eigenvalues of interest are not dominant or well-separated,
this method may suffer from slow convergence. Spectral
transformations are a common acceleration technique that
address this issue by introducing a modified eigenvalue
problem that is easier to solve than the original. This
modified problem accentuates the eigenvalues of interest,
but requires solving a linear system, which is
computationally expensive for large-scale eigenvalue
problems.

In this talk we will show how this expense can
be reduced through a preconditioning scheme that uses a
fixed-polynomial operator to approximate the spectral
transformation. Three different constructions for a
fixed-polynomial operator are derived from some common
iterative methods for non-Hermitian linear systems. The
implementation details and numerical behavior of these three
operators are compared. Numerical experiments will be
presented demonstrating that this preconditioning scheme is
a competitive approach for solving large-scale eigenvalue
problems. The results illustrate the effectiveness of this
technique using several practical eigenvalue problems from
science and engineering ranging from hundreds to more than a
million unknowns.



	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\begin{center} \rule{6in}{1pt} \end{center}
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{center}
{\large			% \hypertarget{Toivanen}
{\bf A fast iterative solver for acoustic scattering by objects \\
	in layered media}}

	Jari Toivanen \\
	Center for Research in Scientific Computation \\
	Box 8205, North Carolina State University, Raleigh NC 27695-8205 \\
	{\tt jatoivan@ncsu.edu} \\
			% \hspace*{9mm}\hfill
	Kazufumi Ito
			% \hfill \hyperlink{index}{\small {\em index}} \\
\end{center}
We consider the computation of time-harmonic acoustic
scattering by objects in layered media. An example of such
problem is the scattering by a mine buried in sediment. The
computational domain can be tens or hundreds of meters long
while the target requires modeling of details smaller than
one centimeter. A discretized problem can have several
billion degrees of freedom.

We decompose the
computational domain into far-field and near-field domains
and then we perform a finite element discretization. For the
vastly larger far-field domain we use an orthogonal mesh and
a preconditioner based on a fast direct solver. For the
near-field domain a more standard preconditioner can be
used. The combination of these two defines a preconditioner
for the GMRES method. An essential implementation detail is
the reduction of iterations into a small sparse subspace.
Due to this the memory usage is essentially reduced and the
GMRES method can be used without restarts.

We present
numerical results with two-dimensional and three-dimensional
problems demonstrating the efficiency of the proposed
approach. For example, we show that it is possible to solve
problems with more than a billion degrees of freedom on a
modern PC.



	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\begin{center} \rule{6in}{1pt} \end{center}
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{center}
{\large			% \hypertarget{Ucar}
{\bf Partitioning sparse matrices for parallel preconditioned \\
	iterative methods}}

	Bora Ucar \\
	Dept. of Mathematics and Computer Science, Emory University \\
	Suite W401, 400 Dowman Drive, Atlanta GA 30322 \\
	{\tt ubora@mathcs.emory.edu} \\
			% \hspace*{9mm}\hfill
	Cevdet Aykanat
			% \hfill \hyperlink{index}{\small {\em index}} \\
\end{center}
We will discuss parallelization techniques for the
preconditioned iterative methods that use explicit
preconditioners such as approximate inverses or factored
approximate inverses. Applications of these preconditioners
require sparse matrix-vector multiplication (SpMxV)
operations. Roughly speaking, the problem reduces to
partitioning two or more matrices together in order to
efficiently parallelize the computations of the form $y\gets
ABCx$. Note that the computations $y\gets ABCx$ are
performed as successive SpMxV operations, and hence there
are dependencies among the input and output vectors of these
SpMxV operations. Additional dependencies are imposed by the
linear vector operations that take part in a full step of
the chosen iterative method. We will first discuss how to
analyze the preconditioned iterative methods to determine
the dependencies between the inputs and outputs of the SpMxV
operations. We will give a short account of such
dependencies for a number of widely used methods including
BiCGStab, preconditioned conjugate gradients, and GMRES.
Next, we will develop hypergraph models which capture the
dependencies among the input and output vectors of the SpMxV
operations with different matrices. We will show that
partitioning a single hypergraph amounts to simultaneous
partitioning of the matrices in $y\gets ABCx$ computations
in such a way that the total volume of communication is
minimized and an appropriate balance criterion among the
processor loads is maintained. We will present experimental
results obtained using a parallel implementation of the
right preconditioned BiCGStab method on a PC cluster.

This is a joint work with Prof C.~Aykanat of Bilkent
University, Ankara, Turkey.



	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\begin{center} \rule{6in}{1pt} \end{center}
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{center}
{\large			% \hypertarget{Vandereycken}
{\bf Multigrid for large scale time-dependent Sylvester equations}}

	Bart Vandereycken \\
	Katholieke Universiteit Leuven, Computer Science Department \\
	Celestijnenlaan 200A, B-3001 Leuven, Belgium \\
	{\tt bart.vandereycken@cs.kuleuven.be} \\
			% \hspace*{9mm}\hfill
	Stefan Vandewalle
			% \hfill \hyperlink{index}{\small {\em index}} \\
\end{center}
We will discuss a multigrid solver for the numerical
solution of the time-dependent Sylvester equation
\begin{equation*} \frac{dX}{dt} = A X + X B + F, \qquad
\text{with $X \in \mathbf{R}^{N\times N}$}, \end{equation*}
where $A$ and $B$ are discretisations of an elliptic PDE
operator. This type of equation occurs in optimal control
problems and in uncertainty propagation algorithms for
partial differential equations with random parameters.
Common to these applications is the large number of unknowns
even for problems with a reasonable mesh width.

 Our
multigrid solver is built on a recently developed algorithm
for the stationary Sylvester equation [1]
$A X + X B + F = 0$.
We exploit the fact that the iterates can be well compressed
when the right hand side $F$ has a low-rank structure. If
this compression is used throughout the multigrid cycle, a
significant reduction in time and memory can be achieved for
large scale problems. This is accomplished by approximating
the unknown $X$ by a low-rank matrix
$$
X \simeq UV^T,
\qquad \mbox{with} \qquad
U,V \in \Reals^{N\times k}.
$$
For a certain precision, this low-rank
multigrid typically requires
$\mathcal{O}(Nk^2) = \mathcal{O}(N\log^2(N))$
work whereas standard multigrid
would require $\mathcal{O}(N^2)$. An adaptive strategy that
gradually enlarges the rank to get better precision is
explored.

[1]
L.~Grasedyck, W.~Hackbusch,
{\em A Multigrid Method to Solve Large Scale Sylvester
Equations}, Technical Report~48 (2004),
Max Planck Institute for Mathematics in the Sciences.



	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\begin{center} \rule{6in}{1pt} \end{center}
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{center}
{\large			% \hypertarget{Verhoeven}
{\bf Error analysis of BDF Compound-Fast multirate method for \\
	differential-algebraic equations}}

	Arie A.~Verhoeven \\
	HG 8.47 (Technische Universiteit Eindhoven) \\
	Den Dolech 2, 5600 MB Eindhoven, The Netherlands \\
	{\tt averhoev@win.tue.nl} \\
	Jan ter Maten, Bob Mattheij, Theo Beelen, \\
			% \hspace*{9mm}\hfill
	Ahmed El Guennouni, Bratislav Tasi\'c
			% \hfill \hyperlink{index}{\small {\em index}} \\
\end{center}
Analogue electrical circuits are usually modeled by
differential-algebraic equations (DAE) of type:
$$
\qquad \qquad \qquad
\frac{d}{dt}\left[
\mathbf{q}(t,\mathbf{x})\right]+
\mathbf{j}(t,\mathbf{x})=\mathbf{0},
\qquad \qquad \qquad (1)
$$
where $\mathbf{x} \in \Reals^d$ represents the state of
the circuit. A common analysis is the transient analysis,
which computes the solution $\mathbf{x}(t)$ of this
non-linear DAE along the time interval $[0,T]$ for a given
initial state. Often, parts of electrical circuits have
latency or multirate behaviour.

For a multirate method it
is necessary to partition the variables and equations into
an active (A) and a latent (L) part. The active and latent
parts can be expressed by $\mathbf{x}_A = \mathbf{B}_A
\mathbf{x},\mathbf{x}_L = \mathbf{B}_L \mathbf{x}$ where
$\mathbf{B}_A,\mathbf{B}_L$ are permutation matrices. Then
equation (1) is written as the following
partitioned system:
$$
\begin{array}{c} \frac{d}{dt}\left
[\mathbf{q}_{A}(t,\mathbf{x}_A,\mathbf{x}_L)\right
]+\mathbf{j}_{A}(t,\mathbf{x}_A,\mathbf{x}_L)=\mathbf{0},\\
\frac{d}{dt}\left
[\mathbf{q}_{L}(t,\mathbf{x}_A,\mathbf{x}_L)\right
]+\mathbf{j}_{L}(t,\mathbf{x}_A,\mathbf{x}_L)=\mathbf{0}.
\end{array}
$$
In contradiction to classical
integration methods, multirate methods integrate both parts
with different stepsizes. Besides the coarse time-grid
$\{T_n,0\leq n \leq N\}$ with stepsizes $H_n = T_n -
T_{n-1}$, also a refined time-grid $\{t_{n-1,m},1\leq n \leq
N, 0 \leq m \leq q_n\}$ is used with stepsizes $h_{n,m} =
t_{n,m} - t_{n,m-1}$ and multirate factors $q_n$. If the two
time-grids are synchronized, $T_n= t_{n,0} = t_{n-1,q_n}$
holds for all $n$. There are a lot of multirate approaches
for partitioned systems but we will consider the
Compound-Fast version of the BDF methods. This method
performs the following four steps:
\begin{enumerate}
\item
The complete system is integrated at the coarse time-grid.
\item The latent interface variables are interpolated at the
refined time-grid. \item The active part is integrated at
the refined time-grid, using the interpolated values at the
latent interface. \item The active solution at the coarse
time-grid is updated.
\end{enumerate}

The local
discretization error $\delta^n$ of the compound phase still
has the same behaviour $\delta^n = O(H_n^{K+1})$. Let
$\bar{\mathbf{P}}^n,\bar{\mathbf{Q}}^n$ be the Nordsieck
vectors which correspond to the predictor and corrector
polynomials of $\mathbf{q}$. Then the error $\delta^n$ can
be estimated by $\hat{\delta}^n$:
$$
\hat{\delta}^n = \frac{-H_n}{T_n - T_{n-K-1}} \left
[\bar{\mathbf{Q}}_{1}^{n}-\bar{\mathbf{P}}_{1}^{n} \right ].
$$
Now $\hat r_C^n = \|\mathbf{B}_L
\hat{\delta}^n\| + \tau\|\mathbf{B}_A \hat{\delta}^n\| $ is
the used weighted error norm, which must satisfy $\hat r_C^n
<$ TOL$_C$.\\ The local discretization error $\delta^{n,m}$
is defined as the residue after inserting the exact solution
in the refinement BDF scheme. During the refinement instead
of $\delta^{n,m}$ the perturbed local error
$\tilde{\delta}^{n,m}$ is estimated. A tedious analysis
yields the following asymptotic behaviour:
$$
\mathbf{B}_A\delta^{n-1,m} \doteq
\mathbf{B}_A\tilde{\delta}^{n-1,m} + \frac{1}{4}h
\mathbf{K}_{n-1,m}\mathbf{B}_L\rho^{n-1,m}.
$$
Here $\rho^{n-1,m}$ is the interpolation error at the 
refined grid and $\mathbf{K}_{n-1,m}$ is the coupling
matrix. The perturbed local discretization error
$\mathbf{B}_A\tilde{\delta}^{n,m}$ behaves as
$O(h_{n-1,m}^{k+1})$ and can be estimated in a similar way
as $\delta^n$. Thus the active error estimate
$\mathbf{B}_A\hat\delta^{n-1,m}$ satisfies
$\mathbf{B}_A\hat\delta^{n-1,m} \doteq 
\mathbf{B}_A\hat{\tilde{\delta}}^{n-1,m} + \frac{1}{4}h
\hat{\mathbf{K}}_{n-1,m}\mathbf{B}_L\hat\rho^{n-1,m}$. Let
$L$ be the interpolation order, then it can be shown that
$\frac{1}{4}\|\hat{\mathbf{K}}_{n}\mathbf{B}_L\rho^{n-1,m}\|$
is less than
$$
\hat{r}_I^{n} =
\frac{1}{4}\frac{H_n}{T_n - T_{n-L-1}}
\|\hat{\mathbf{K}}_{n}\mathbf{B}_L
\left[\bar{\mathbf{X}}_{1}^n
-\bar{\mathbf{Y}}_{1}^n\right] \|.
$$
Here
$\bar{\mathbf{Y}}^n,\bar{\mathbf{X}}^n$ are the Nordsieck
vectors which correspond to the predictor and corrector
polynomials of $\mathbf{x}$. This error estimate
$\hat{r}_I^n$ has the asymptotic behaviour $\hat{r}_I^{n} =
O(H_n^{L+1})$. It follows that
$\|\mathbf{B}_A\hat{\delta}^{n,m}\|$ satisfies:
$$
\begin{array}{rcl}
\|\mathbf{B}_A\hat{\delta}^{n-1,m}\| &\leq&
\hat{\tilde{r}}_A^{n-1,m} + h\hat{r}_I^{n} =:
\hat{r}_A^{n-1,m}. \end{array}
$$
If $\hat{r}_I^{n} \leq $ TOL$_I = \sigma$TOL$_A$ and
$\hat{\tilde{r}}_A^{n-1,m} \leq \tilde{\mbox{TOL}}_A =
(1-\sigma h)$TOL$_A$ then $\hat{r}_A^{n-1,m} \leq
\tilde{\mbox{TOL}}_A + h$TOL$_I =$ TOL$_A$.

We tested a
circuit with $5 \times 10$ inverters. The location of the
active part is controlled by the connecting elements and the
voltage sources. The connecting elements were chosen such
that the active part consists of 3 inverters. We did an
Euler Backward Compound-Fast multirate simulation on
$[0,10^{-8}]$ with $\sigma = 0.5,\tau = 0$. We get accurate
results combined with a speedup factor 13. 



	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\begin{center} \rule{6in}{1pt} \end{center}
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{center}
{\large			% \hypertarget{Virnick}
{\bf An algebraic multigrid preconditioner for a class of \\
	singular M-matrices}}

	Elena Virnick \\
	Institut f\:ur Mathematik \\
	Technische Universit\:at Berlin \\
			% \hspace*{9mm}\hfill
	{\tt virnik@math.tu-berlin.de}
			% \hfill \hyperlink{index}{\small {\em index}} \\
\end{center}
We will consider the problem of the computation of stationary
distributions of Markov chains which arises in many different
application areas. These range from the distribution of drugs
in the blood circulation systems to the Page Rank computed by
Google. The task is to compute the left eigenvector
corresponding to the largest eigenvalue of the transition
matrix $T$ or alternatively solve the linear system
$$(I-T^T)x=0,$$
where the matrix $(I-T^T)$ is a singular $M$-matrix.
In applications, these matrices are large and sparse.
Therefore, iterative methods such as GMRES are applied.
However, the applicability of GMRES depends on whether
it is possible to find a suitable preconditioner.
For non-singular, symmetric positive definite M-matrices
that are obtained from discretisations of boundary
value problems the algebraic multigrid is well known
to be a good preconditioner. We show how it is possible
to apply the algebraic multigrid method to our special
case of singular non-symmetric $M$-matrices and show
numerical examples that illustrate that this leads to
significant acceleration of the convergence speed.


	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\begin{center} \rule{6in}{1pt} \end{center}
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{center}
{\large			% \hypertarget{Vuik}
{\bf Complex shifted-Laplace preconditioners for the Helmholtz equation}}

	Kees Vuik \\
	Delft University of Technology \\
	Faculty of Electrical Engineering, Mathematics and Computer Science \\
	Delft Inst. of Applied Mathematics \\
	Mekelweg 4, 2628 CD Delft, The Netherlands \\
	{\tt c.vuik@tudelft.nl} \\
			% \hspace*{9mm}\hfill
	Yogi Erlangga, Kees Oosterlee, Martin Van Gijzen
			% \hfill \hyperlink{index}{\small {\em index}} \\
\end{center}
In this paper, the time-harmonic
wave equation in heterogeneous media is solved numerically.
The underlying equation governs wave propagations and
scattering phenomena arising in many area's, e.g., in
aeronautics, geophysics, and optical problems. In
particular, we look for efficient iterative solution
techniques for the Helmholtz equation discretized by finite
difference discretizations. Since the number of grid points
per wavelength should be sufficiently large for accurate
solutions, for very high wavenumbers the discrete problem
becomes extremely large, thus prohibiting the use of direct
solvers. However, since the coefficient matrix is sparse,
iterative solvers are an interesting alternative.

In many
geophysical applications that are of our interest, an
unbounded domain is used. In our model we approximate such a
domain by a bounded domain, where appropriate boundary
conditions are used to prevent spurious reflections. As
boundary conditions we compare the following possibilities:
Dirichlet, Neumann, Sommerfeld, Absorbing Layer and Perfect
Matched Layer. Due to the boundary conditions and damping in
the heterogeneous medium, the coefficient matrix is
complex-valued.

It appears that standard iterative
solvers (ILU preconditioned Krylov solver, Multigrid, etc.)
fail for the Helmholtz equation, if the wavenumber becomes
sufficiently high. In this paper we present a Bi-CGSTAB
solution method combined with a novel preconditioner for
high wavenumbers. The preconditioner is based on the inverse
of an Helmholtz operator, where an artificial damping term
is added to the operator. This preconditioner can be
approximated by multigrid. This is somewhat surprising as
multigrid, without enhancements, has convergence troubles
for the original Helmholtz operator at high wavenumbers.


Currently, we are investigating the best choice of the
damping term. If the damping term is small Bi-CGSTAB
converges fast, but it is difficult to use multigrid for the
preconditioner. On the other hand, if the damping term is
large the multigrid approximation is very good, but the
convergence of Bi-CGSTAB is slow. So a compromise is
required to obtain an efficient solver. To find a good value
of the damping term we study the spectral properties of the
preconditioned matrix. It appears that an eigenvalue 
analysis of this matrix can be used to predict the
convergence of GMRES. In practice it appears that these
insights can also be used for the convergence of Bi-CGSTAB.
We conclude that Bi-CGSTAB combined with the novel
preconditioner converges satisfactorily for all choices of
the boundary conditions.



	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\begin{center} \rule{6in}{1pt} \end{center}
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% \pdfbookmark[1]{W-Z}{w-z}
\begin{center}
{\large			% \hypertarget{Waisman}
{\bf A space-time multigrid approach for acceleration of \\
	molecular dynamics simulations}}

	Haim Waisman \\
	Scientific Computation Research Center (SCOREC) \\
	Rensselaer Polytechnic Institute,  Troy NY 12180-3590 \\
	{\tt waismh@rpi.edu} \\
			% \hspace*{9mm}\hfill
	Jacob Fish
			% \hfill \hyperlink{index}{\small {\em index}} \\
\end{center}
We present a novel space-time multigrid method for molecular
dynamics simulations. It is aimed at bridging discrete
scales with either coarse grained discrete or continuum
scales. The method consists of the waveform relaxation
scheme aimed at capturing the high frequency response of
atomistic vibrations and a coarse scale solution in space
and time aimed at resolving smooth features of the discrete
medium. The formulation of the coarse grained model is based
on the variational approach derived from Hamilton's
principle. The time integration is performed in windows
using the Newmark predictor-corrector method. The method is
implicit, possesses superior stability properties and
consequently enables larger time steps governed by accuracy
considerations of coarse scale quantities of interest.
Performance studies on polymer melts have shown significant
speed-up compared to the classical explicit methods, in
particular on parallel machines.



	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\begin{center} \rule{6in}{1pt} \end{center}
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{center}
{\large			% \hypertarget{Walker}
{\bf Approximate finite-differences in matrix-free Newton-Krylov methods}}

	Homer Walker \\
	Mathematical Sciences Department, Worcester Polytechnic Institute \\
	100 Institute Road, Worcester MA 01609-2280 \\
	{\tt walker@wpi.edu} \\
			% \hspace*{9mm}\hfill
	Peter N.~Brown, Rebecca D.~Wasyk, Carol S.~Woodward
			% \hfill \hyperlink{index}{\small {\em index}} \\
\end{center}
Newton-Krylov methods are often implemented in
``matrix-free'' form, in which the Jacobian-vector products
required by the Krylov solver are approximated by finite
differences. We consider using approximate function values
in these finite differences. We first formulate a
finite-difference Arnoldi process that uses approximate
function values and give backward-error results for it. We
then outline a Newton--Krylov method that uses an
implementation of the GMRES or Arnoldi method based on this
process and develop a local convergence analysis for it,
giving sufficient conditions on the approximate function
values for desirable local convergence properties to hold.
We conclude with numerical experiments involving particular
function-value approximations suitable for nonlinear
diffusion problems. For this case, conditions are given for
meeting the convergence assumptions for both lagging and
linearizing the nonlinearity in the function evaluation.



	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\begin{center} \rule{6in}{1pt} \end{center}
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{center}
{\large			% \hypertarget{Wathen11}
{\bf Constaint preconditioning and Schilders factorization \\
	for saddle-point systems}}

	Andy Wathen \\
	Oxford University Computing Laboratory, Wolfson Building \\
	Parks Road, Oxford OX1 3QD UK \\
			% \hspace*{9mm}\hfill
	{\tt wathen@comlab.ox.ac.uk}
			% \hfill \hyperlink{index}{\small {\em index}} \\
\end{center}
Saddle-point systems arise widely because they generally
result from any problem with constraints. Hence in Fluid
Mechanics incompressibility is a constraint on the
Navier-Stokes equations, in Optimization algebraic and/or
bound constraints are often applied and in PDE constrained
optimization the PDEs themselves provide the constraints.


This talk is about preconditioned iterative approaches to
the solution of large-scale saddle-point problems based on
preconditioners which preserve the constraints: so-called
constraint preconditioners. We will briefly review the
attractive feature of such preconditioners and then explain
how these preconditioners can effectively be realized
through a block factorization due to Wil Schilders. This
reveals a range of possible approaches where the balance
between faster convergence though better preconditioning and
the cost of the preconditioner varies.

This is joint
work with Sue Dollar, Nick Gould and Wil Schilders


	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\begin{center} \rule{6in}{1pt} \end{center}
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{center}
{\large			% \hypertarget{Wathen12}
{\bf Converging in the right norm}}

	Andy Wathen \\
	Oxford University Computing Laboratory, Wolfson Building \\
	Parks Road, Oxford OX1 3QD UK \\
			% \hspace*{9mm}\hfill
	{\tt wathen@comlab.ox.ac.uk}
			% \hfill \hyperlink{index}{\small {\em index}} \\
\end{center}
For PDE problems, Numerical Analysts would always wish to
establish error estimates in `natural' norms for a given
problem. In the context of iterative solution methods there
is similarly the issue of the right norm for convergence:
discrete norms are equivalent, but measuring a convergence
tolerance in a norm in which half of the variables are
scaled by $h^{-5}$ or $h^5$ is definitely not the right
thing to do in general! 

In particular this issue arises
when preconditioning with minimum residual methods because
then monotonic residual reduction occurs in a norm based on
the preconditioner. (For SPD problems and Conjugate
Gradients it is well known that any SPD preconditioning does
not affect the relevant norm). 

In this talk we will
discuss this issue in the context of models of
incompressible flow --- Poisson, Stokes, Advection-Diffusion
and Navier-Stokes problems --- and show how the optimal block
preconditioners developed by Silvester and the author for
the Stokes problem give convergence in the right norm;
comments will also be made regarding Navier-Stokes
preconditioning.

This is joint work with Howard Elman
and David Silvester



	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\begin{center} \rule{6in}{1pt} \end{center}
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{center}
{\large			% \hypertarget{Westphal}
{\bf A least-squares finite element method for viscoelastic flow}}

	Chad Westphal \\
	Dept.~of Mathematics, Wabash College \\
	300 W.~Wabash Ave., Crawfordsville IN 47933 \\
			% \hspace*{9mm}\hfill
	{\tt westphac@wabash.edu}
			% \hfill \hyperlink{index}{\small {\em index}} \\
\end{center}
The equations describing viscoelastic fluid flow are
inherently nonlinear and pose a continuing challenge to most
numerical approximation methods. Even the addition of a
small component of elastic behavior to Newtonian fluid can
introduce instabilities. In this talk we present progress
toward a multilevel least-squares finite element method for
steady viscoelastic fluid flow of Oldroyd-B type. Our
approach is to combine an outer iteration consisting of
linearization steps on a nested sequence of grids with an
inner iteration of a least-squares finite element
discretization and algebraic multigrid linear solver. One of
the challenges arising from this system is in treating the
convective nature of the constitutive equation. We discuss
an analogous, but simplified, problem that illustrates the
difficulties, and suggest a strategy for least-squares
discretizations to treat equations with strong convective
terms.



	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\begin{center} \rule{6in}{1pt} \end{center}
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{center}
{\large			% \hypertarget{Wong}
{\bf An embedding method for simulation of immobilized enzyme kinetics \\
	and transport in sessile hydrogel drops}}

	Chao-Jen Wong \\
	School of Mathematical Sciences, Claremont Graduate University \\
	710 N.~College Ave., Claremont CA 91711 \\
	{\tt wongc@cgu.edu} \\
			% \hspace*{9mm}\hfill
	Ali Nadim
			% \hfill \hyperlink{index}{\small {\em index}} \\
\end{center}
We
present a new numerical method, termed the embedding method,
to solve a system of nonlinear PDEs for multi-phase problems
in asymmetric 3-D domains. The main feature of this method
is its ability to perform interface calculation and account
for conditions relating solution properties across phase
interface using a finite difference / volume-fraction-based
front-capturing hybrid technique.

The approach begins by
considering the computational domain as physically separated
phases. A finite difference method with a Cartesian grid is
employed on the whole domain while modifications are applied
to correct boundary conditions at the interfaces. The
volume-fraction-based front-capturing algorithm is used to
capture each interface in terms of the volume fraction in
each cell. The major aspect of this method is its
implementation simplicity, which results in code generation
that can be highly optimized. To highlight this method, an
application is presented for simulation and investigation of
enzyme reactions within a sessile hydrogel drop, where the
Michaelis-Menten kinetics is used to model the reaction
mechanism.



	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\begin{center} \rule{6in}{1pt} \end{center}
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{center}
{\large			% \hypertarget{Wachter}
{\bf An algorithmic framework for convex mixed integer nonlinear programs}}

	Andreas W\"achter \\
	Dept.~of Mathematical Sciences, IBM T.J.~Watson Research Center \\
	P.O.~Box 218, Yorktown Heights NY 10598 \\
	{\tt andreasw@watson.ibm.com} \\
	Pierre Bonami, Lorenz T.~Biegler, Andrew R.~Conn, \\
	G\'erard Cornu\'ejols, Ignacio E.~Grossmann, Carl D.~Laird, \\
			% \hspace*{9mm}\hfill
	Jon Lee, Andrea Lodi, Fran\c{c}ois Margot, Nicolas Sawaya
			% \hfill \hyperlink{index}{\small {\em index}} \\
\end{center}
We present a hybrid framework for convex mixed-integer
nonlinear programming. In one extreme case, the method
becomes the branch-and-bound approach, where a nonlinear
optimization problem is solved in each node of the
enumeration tree, and in the other extreme it reduces to the
polyhedral outer approximation algorithm, which alternates
between the solution of a nonlinear optimization problem and
a mixed-integer linear program.

Numerical results are
presented, using an open source software implementation
available on http://www.coin-or.org.

This work results
from an on-going research collaboration between IBM and CMU.



	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\begin{center} \rule{6in}{1pt} \end{center}
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\newpage

\begin{center}
{\large			% \hypertarget{Xu}
{\bf Optimal solvers for H(curl) and H(div) systems in terms \\
	of Poisson solvers}}

	Jinchao Xu \\
	Dept.~of Mathematics \\
	Center for Computational Mathematics and Applications \\
	The Pennsylvania State University \\
			% \hspace*{9mm}\hfill
	{\tt xu@math.psu.edu}
			% \hfill \hyperlink{index}{\small {\em index}} \\
\end{center}
A new class of optimal solvers
will be presented for H (curl) and H(div) systems in terms of
Poisson Solvers. As a direct application, optimal AMG solvers can
be obtained for H(curl) and H (div) systems whenever optimal AMG
solvers are available for Poisson equations. Both theoretical and
numerical examples will be given. This work is in joint with Ralf
Hiptmair.



	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\begin{center} \rule{6in}{1pt} \end{center}
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{center}
{\large			% \hypertarget{Xue}
{\bf A multilevel Newton's method for a two phase mixture model with \\
	nonlinear discontinuous degenerate diffusion coefficient}}

	Guangio Xue \\
	Dept.~of Mathematics \\
	Center for Computational Mathematics and Applications \\
	The Pennsylvania State University \\
	{\tt xue@math.psu.edu} \\
			% \hspace*{9mm}\hfill
	Jinchao Xu, Chao-Yang Wang, Robert Falgout
			% \hfill \hyperlink{index}{\small {\em index}} \\
\end{center}
The traditional Newton's method requires certain smoothness of
the coefficients of partial differential equations to get local
convergence. In this paper, a multilevel Newton's method is
developed for a two phase model with nonlinear discontinuous
degenerate diffusion coefficient arising in fuel cell
applications. A major finding is that the discrete algebraic
function after using linear finite element method is
Lipschitz continuous.
Numerical example shows the robustness of this method.


	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\begin{center} \rule{6in}{1pt} \end{center}
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{center}
{\large			% \hypertarget{Yang11}
{\bf A constrained minimization algorithm for solving nonlinear \\
	eigenvalue problems in electronic structure calculation}}

	Chao Yang \\
	Lawerence Berkeley National Laboratory \\
	1 Cyclotron Rd, MS-50F, Berkeley CA 94720 \\
	{\tt cyang@lbl.gov} \\
			% \hspace*{9mm}\hfill
	Juan Meza, Ling-wang Wang
			% \hfill \hyperlink{index}{\small {\em index}} \\
\end{center}
One of the fundamental problems in electronic structure
calculation is to determine electron orbitals associated
with the minimum total energy of large atomistic systems.
The total energy minimization problem is often formulated as
a nonlinear eigenvalue problem and solved by an iterative
scheme called Self Consistent Field (SCF) iteration. In this
talk, a new direct constrained optimization algorithm for
minimizing the Kohn-Sham (KS) total energy functional is
presented.

The key ingredients of this algorithm involve
projecting the total energy functional into a sequences of
subspaces of small dimensions and seeking the minimizer of
total energy functional within each subspace. The minimizer
of the projected energy functional not only provides a
search direction along which the KS total energy functional
decreases but also gives an optimal ``step-length'' to move
along this search direction. Due to the small dimension of
the projected problem, the minimizer of the projected energy
functional can be computed by several different methods.
These methods will be examined and compared in this talk.
Numerical examples will be provided to demonstrate that this
new direct constrained optimization algorithm can be more
efficient and robust than the SCF iteration.



	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\begin{center} \rule{6in}{1pt} \end{center}
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{center}
{\large			% \hypertarget{Yang21}
{\bf On parallel algebraic multigrid preconditioners for systems of PDEs}}

	Ulrike Meier Yang \\
	Center for Applied Scientific Computing \\
	Lawrence Livermore National Laboratory \\
	Box 808, L-560, Livermore CA 94551 \\
			% \hspace*{9mm}\hfill
	{\tt umyang@llnl.gov}
			% \hfill \hyperlink{index}{\small {\em index}} \\
\end{center}
Algebraic multigrid (AMG) is a very efficient, scalable
algorithm for solving large linear systems on unstructured
grids. When solving linear systems derived from systems of
partial differential equations (PDEs) often a different
approach is required than for those derived from a scalar
PDE. There are mainly two approaches, the function approach
(also known as the ``unknown'' approach), and the nodal or
``point'' approach. The function approach defines coarsening
and interpolation separately for each function. The nodal
approach uses AMG in a block manner, where all variables
that correspond to the same grid node are coarsened,
interpolated and relaxed together. While the function
approach is much easier to implement and often more
efficient, there are problems for which this approach is not
sufficient and the more expensive nodal approach is needed.


Several parallel implementations of both approaches using
various coarsening schemes and interpolation operators are
investigated. Advantages and disadvantages of both
approaches are discussed, and numerical results are
presented.



	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\begin{center} \rule{6in}{1pt} \end{center}
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{center}
{\large			% \hypertarget{Yavneh}
{\bf New algorithms for vector quantization}}

	Irad Yavneh \\
	Dept.~of Computer Science \\
	Technion - Israel Institute of Technology, Haifa 32000, Israel \\
	{\tt irad@cs.technion.ac.il} \\
			% \hspace*{9mm}\hfill
	Yair Koren
			% \hfill \hyperlink{index}{\small {\em index}} \\
\end{center}
Vector quantization is the classical problem of representing
continuum with only a finite number of representatives or
representing an initially rich amount of discrete data with
a lesser amount of representatives. This problem has
numerous applications. The objective of achieving a
quantization with minimal distortion leads to a hard
non-convex optimization problem, typically with many local
minima. The main problem is thus to find an initial
approximation that is close to a ``good'' local minimum.
Once such an approximation is found, the well-known
Lloyd-Max iterative algorithm may be used to converge to the
nearby a local minimum. In this talk we will describe the
problem and present two new approaches to its approximate
solution.



	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\begin{center} \rule{6in}{1pt} \end{center}
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{center}
{\large			% \hypertarget{Zaslavsky}
{\bf Finite-difference solution of the 3D EM problem
using integral equation type preconditioners}}

	Mikhail Zaslavsky \\
	320 Bent St., Cambridge MA 02141 \\
	{\tt mzaslavsky@ridgefield.oilfield.slb.com} \\
			% \hspace*{9mm}\hfill
	S Davydychdeva, V Druskin,
	L.~Knizhnerman, A.~Abubakar, T.~Habashy
			% \hfill \hyperlink{index}{\small {\em index}} \\
\end{center}
The electromagnetic prospecting problem requires fine
gridding to account for sea bottom and to model complicated
targets. This results in large computational costs using
conventional finite-difference solvers. To circumvent these
problems, we employ a volume integral equation approach for
preconditioning and to eliminate the background, thus
significantly reducing the condition number and
dimensionality of the problem. Since the problem should be
solved in unbounded domain we use so-called optimal grids to
truncate error of approximation at infinity. Special
averaging procedure is proposed to account for
inhomogenuity. Theory and numerical results will be
presented.


	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\begin{center} \rule{6in}{1pt} \end{center}
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{center}
{\large			% \hypertarget{Zikatanov}
{\bf On multigrid methods for generalized finite element methods \\
	on unstructured grids}}

	Ludmil Zikatanov \\
	Dept. of Mathematics \\
	The Pennsylvania State University, University Park PA 16802 \\
	{\tt ludmil@psu.edu} \\
			% \hspace*{9mm}\hfill
	Durkbin Cho
			% \hfill \hyperlink{index}{\small {\em index}} \\
\end{center}
We consider the symmetric positive semi-definite problems
arising from generalized finite element discretizations on
unstructured grids. The focus will be on a simple two level
approach, in which the coarse grid problem corresponds to
the space spanned by the partition of unity functions. We
characterize the kernel components of the stiffness matrix
for GFEM discretizations in two and three spatial
dimensions. With this characterization in hand, we can
derive a stable decomposition of the underlying GFEM space,
using as an auxiliary coarse space the piece-wise linear and
continuous functions and prove a uniform convergence result
for the resulting two level method.



	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\begin{center} \rule{6in}{1pt} \end{center}
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\end{document}

